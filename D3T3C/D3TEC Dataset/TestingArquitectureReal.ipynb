{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KR37uGe3lqIt",
    "outputId": "7e46a98e-7d1e-43e7-b7d3-0ddb166976c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codificación real de Conv2D: [0, 16, 0, 0]\n",
      "Decodificación Conv2D: {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Dropout: [3, 1, 0, 0]\n",
      "Decodificación Dropout: {'type': 'Dropout', 'rate': 0.3}\n",
      "\n",
      "Codificación real de Dense: [4, 128, 0, 0]\n",
      "Decodificación Dense: {'type': 'Dense', 'units': 128, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Repetition: [8, 3, 5, 0]\n",
      "Decodificación Repetition: {'type': 'Repetition', 'repetition_layers': 3, 'repetition_count': 5}\n"
     ]
    }
   ],
   "source": [
    "# Opciones de decodificación para otros parámetros\n",
    "layer_type_options = {\n",
    "    0: 'Conv2D',\n",
    "    1: 'BatchNorm',\n",
    "    2: 'MaxPooling',\n",
    "    3: 'Dropout',\n",
    "    4: 'Dense',\n",
    "    5: 'Flatten',\n",
    "    6: 'DepthwiseConv2D',\n",
    "    7: 'DontCare',\n",
    "    8: 'Repetition'\n",
    "}\n",
    "stride_options = {0: 1, 1: 2}\n",
    "dropout_options = {0: 0.2, 1: 0.3, 2: 0.4, 3: 0.5}\n",
    "activation_options = {0: 'relu', 1: 'leaky_relu', 2: 'sigmoid', 3: 'tanh'}\n",
    "\n",
    "# Función para codificar los parámetros de la capa\n",
    "def encode_layer_params(layer_type_idx, param1=0, param2=0, param3=0):\n",
    "    \"\"\"\n",
    "    Codifica una capa en una lista en función del tipo de capa y sus parámetros.\n",
    "\n",
    "    layer_type_idx : int : índice del tipo de capa según layer_type_options.\n",
    "    param1         : int/float : filtros, neuronas, capas de repetición, etc.\n",
    "    param2         : int : stride, número de repeticiones, etc.\n",
    "    param3         : int : índice de activación o tasa de dropout.\n",
    "    \"\"\"\n",
    "    return [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "# Función para decodificar los parámetros de la capa\n",
    "def decode_layer_params(encoded_params):\n",
    "    \"\"\"\n",
    "    Decodifica una capa desde su representación codificada en parámetros interpretables.\n",
    "\n",
    "    encoded_params : list : [tipo de capa, param1, param2, param3].\n",
    "    \"\"\"\n",
    "    layer_type_idx = encoded_params[0]\n",
    "    layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "\n",
    "    # Decodificar en función del tipo de capa\n",
    "    if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "        filters = max(4, min(encoded_params[1], 32))  # Limitar filtros entre 4 y 32\n",
    "        strides = stride_options.get(encoded_params[2], 1)\n",
    "        activation = activation_options.get(encoded_params[3], 'relu')\n",
    "        return {\n",
    "            'type': layer_type,\n",
    "            'filters': filters,\n",
    "            'strides': strides,\n",
    "            'activation': activation\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {'type': 'BatchNorm'}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        strides = stride_options.get(encoded_params[1], 1)\n",
    "        return {'type': 'MaxPooling', 'strides': strides}\n",
    "    elif layer_type == 'Dropout':\n",
    "        rate = dropout_options.get(encoded_params[1], 0.2)\n",
    "        return {'type': 'Dropout', 'rate': rate}\n",
    "    elif layer_type == 'Dense':\n",
    "        units = max(1, min(encoded_params[1], 512))  # Limitar unidades entre 1 y 512\n",
    "        activation = activation_options.get(encoded_params[2], 'relu')\n",
    "        return {'type': 'Dense', 'units': units, 'activation': activation}\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {'type': 'Flatten'}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            'type': 'Repetition',\n",
    "            'repetition_layers': int(encoded_params[1]),\n",
    "            'repetition_count': int(encoded_params[2])\n",
    "        }\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {'type': \"DontCare\"}\n",
    "\n",
    "    return None\n",
    "\n",
    "# Ejemplos de codificación y decodificación\n",
    "encoded_conv2d = encode_layer_params(0, 16, 0, 0)  # Conv2D con 16 filtros, stride 1 y activación ReLU\n",
    "decoded_conv2d = decode_layer_params(encoded_conv2d)\n",
    "print(f\"\\nCodificación real de Conv2D: {encoded_conv2d}\")\n",
    "print(f\"Decodificación Conv2D: {decoded_conv2d}\")\n",
    "\n",
    "encoded_dropout = encode_layer_params(3, 1)  # Dropout con tasa de 0.3\n",
    "decoded_dropout = decode_layer_params(encoded_dropout)\n",
    "print(f\"\\nCodificación real de Dropout: {encoded_dropout}\")\n",
    "print(f\"Decodificación Dropout: {decoded_dropout}\")\n",
    "\n",
    "encoded_dense = encode_layer_params(4, 128, 0)  # Dense con 128 neuronas y activación ReLU\n",
    "decoded_dense = decode_layer_params(encoded_dense)\n",
    "print(f\"\\nCodificación real de Dense: {encoded_dense}\")\n",
    "print(f\"Decodificación Dense: {decoded_dense}\")\n",
    "\n",
    "encoded_repetition = encode_layer_params(8, 3, 5)  # Repetition para repetir las últimas 3 capas 5 veces\n",
    "decoded_repetition = decode_layer_params(encoded_repetition)\n",
    "print(f\"\\nCodificación real de Repetition: {encoded_repetition}\")\n",
    "print(f\"Decodificación Repetition: {decoded_repetition}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SMmKhGcf4NGU"
   },
   "outputs": [],
   "source": [
    "def int_to_real_dom(num, domain):\n",
    "  min_i, max_i = domain\n",
    "  r = (num - min_i) / (max_i - min_i)\n",
    "  return r\n",
    "\n",
    "def real_to_int_dom(num, domain):\n",
    "  min_i, max_i = domain\n",
    "  value = min_i + num * (max_i - min_i)\n",
    "  if isinstance(min_i, int) and isinstance(max_i, int):\n",
    "      value = int(round(value))\n",
    "  return value\n",
    "\n",
    "def convert_individual(ind, to_real=True):\n",
    "    real_rep = []\n",
    "    N = max(layer_type_options.keys())\n",
    "    for i in range(0, len(ind), 4):\n",
    "        layer_type_idx = ind[i]\n",
    "        domain_layer_type = [0, N]\n",
    "        if to_real:\n",
    "            real_rep.append(int_to_real_dom(layer_type_idx, domain_layer_type))\n",
    "            layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "        else:\n",
    "            real_rep.append(real_to_int_dom(layer_type_idx, domain_layer_type))\n",
    "            layer_type = layer_type_options.get(real_rep[i], 'DontCare')\n",
    "\n",
    "        # Decode based on layer type\n",
    "        if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [4, 32]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [0, 1]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 3], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [4, 32]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [0, 1]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 3], [0, 3]))\n",
    "        elif layer_type == 'BatchNorm':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "        elif layer_type == 'MaxPooling':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [0, 1]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [0, 1]))\n",
    "            real_rep.extend([0, 0])\n",
    "        elif layer_type == 'Dropout':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [0, 3]))\n",
    "            real_rep.extend([0, 0])\n",
    "        elif layer_type == 'Dense':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [1, 512]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [1, 512]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [0, 3]))\n",
    "            real_rep.append(0)\n",
    "        elif layer_type == 'Flatten':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "        elif layer_type == 'Repetition':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [1, 4]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [1, 32]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [1, 4]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [1, 32]))\n",
    "            real_rep.append(0)\n",
    "        elif layer_type == 'DontCare':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "    return real_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecnYEmcw8aLv",
    "outputId": "f815a803-ff1e-4905-e4da-3fb4c84bc24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 6, 5, 0, 2, 8, 1, 1, 0, 4, 17, 3, 0, 4, 22, 0, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 3, 1, 0, 0, 4, 63, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
      "[0.125, 0, 0, 0, 0.75, 0.03571428571428571, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0, 0.5, 0.03131115459882583, 1.0, 0, 0.5, 0.0410958904109589, 0.0, 0, 0.875, 0, 0, 0, 0.0, 0.25, 1.0, 1.0, 0.375, 0.0, 0, 0, 0.375, 0.3333333333333333, 0, 0, 0.5, 0.12133072407045009, 1.0, 0, 0.125, 0, 0, 0, 0.625, 0, 0, 0]\n",
      "[1, 0, 0, 0, 6, 5, 0, 2, 8, 1, 1, 0, 4, 17, 3, 0, 4, 22, 0, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 3, 1, 0, 0, 4, 63, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 0, 0, 0, 6, 5, 0, 2, 8, 1, 1, 0, 4, 17, 3, 0, 4, 22, 0, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 3, 1, 0, 0, 4, 63, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
    "print(x)\n",
    "y = convert_individual(x)\n",
    "print(y)\n",
    "z = convert_individual(y, to_real=False)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8UHDkV27ltyD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Clase para capas neutrales 'DontCare'\n",
    "class DontCareLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(DontCareLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g0eLaXdQluzl"
   },
   "outputs": [],
   "source": [
    "def encode_model_architecture(model_dict, max_alleles=48):\n",
    "    \"\"\"\n",
    "    Codifica la arquitectura del modelo en una lista de valores con un máximo de `max_alleles`.\n",
    "    Cada capa se codifica en función de sus parámetros.\n",
    "    \"\"\"\n",
    "    encoded_layers = []\n",
    "    total_alleles = 0\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Repetition':  # Codificar capa de repetición\n",
    "            encoded_layer = encode_layer_params(\n",
    "                layer_type_idx=8,  # índice para 'Repetition'\n",
    "                param1=layer.get('repetition_layers', 0),\n",
    "                param2=layer.get('repetition_count', 1)\n",
    "            )\n",
    "        else:\n",
    "            layer_type_idx = next(\n",
    "                key for key, value in layer_type_options.items() if value == layer['type']\n",
    "            )\n",
    "\n",
    "            # Codificar parámetros específicos de cada tipo de capa\n",
    "            if layer['type'] in ['Conv2D', 'DepthwiseConv2D']:\n",
    "                # Limitar filtros dentro del rango [4, 32]\n",
    "                param1 = max(4, min(layer.get('filters', 8), 32))\n",
    "                param2 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                param3 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "            elif layer['type'] == 'Dense':\n",
    "                # Limitar neuronas dentro del rango [1, 512]\n",
    "                param1 = max(1, min(layer.get('units', 1), 512))\n",
    "                param2 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, 0]\n",
    "\n",
    "            elif layer['type'] == 'MaxPooling':\n",
    "                param1 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Dropout':\n",
    "                param1 = next((key for key, value in dropout_options.items() if value == layer.get('rate', 0.2)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'BatchNorm':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Flatten':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'DontCare':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "        # Añadir la codificación de la capa a la lista de alelos\n",
    "        encoded_layers.extend(encoded_layer)\n",
    "        total_alleles += len(encoded_layer)\n",
    "\n",
    "    # Rellenar con 'DontCare' si el total de alelos es menor que `max_alleles`\n",
    "    while total_alleles < max_alleles:\n",
    "        dont_care_encoding = encode_layer_params(7)  # índice de 'DontCare'\n",
    "        encoded_layers.extend(dont_care_encoding)\n",
    "        total_alleles += len(dont_care_encoding)\n",
    "\n",
    "    # Recortar si excede `max_alleles`\n",
    "    final_encoding = encoded_layers[:max_alleles]\n",
    "    #print(f\"Final Encoded Model: {final_encoding}\")\n",
    "\n",
    "    return final_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tDFQVy0Tlwpx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fixArch(encoded_model, verbose=False):\n",
    "    \"\"\"\n",
    "    Corrige la arquitectura codificada del modelo, asegurando que:\n",
    "    - Se evite la presencia de capas incompatibles después de una capa Flatten.\n",
    "    - En caso de una capa de Repetition, se ajuste el alcance de repetición si no hay suficientes capas anteriores.\n",
    "\n",
    "    Parameters:\n",
    "        encoded_model (list): Lista codificada de la arquitectura del modelo.\n",
    "        verbose (bool): Si es True, muestra las correcciones realizadas.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista con la arquitectura corregida, truncada a un máximo de 48 alelos.\n",
    "    \"\"\"\n",
    "\n",
    "    fixed_layers = []  # Lista que almacenará la arquitectura corregida\n",
    "    input_is_flattened = False  # Indicador para saber si ya hay una capa Flatten en el modelo\n",
    "    index = 0  # Índice para recorrer el modelo codificado\n",
    "\n",
    "    # Procesar cada capa en el modelo sin forzar la primera capa a ser específica\n",
    "    while index < len(encoded_model) and len(fixed_layers) < 48:\n",
    "        layer_type = int(encoded_model[index])  # Obtener el tipo de capa actual\n",
    "\n",
    "        # Procesar la capa de Repetition\n",
    "        if layer_type == 8:\n",
    "            repetition_layers = int(encoded_model[index + 1])  # Número de capas a repetir\n",
    "            repetition_count = min(max(int(encoded_model[index + 2]), 0), 32)  # Cantidad de repeticiones\n",
    "\n",
    "            # Verificar si hay suficientes capas para la repetición solicitada\n",
    "            actual_layers_to_repeat = min(repetition_layers, len(fixed_layers) // 4)\n",
    "\n",
    "            if actual_layers_to_repeat != repetition_layers:\n",
    "                if verbose:\n",
    "                    print(f\"Ajustando alcance de repetición de {repetition_layers} a {actual_layers_to_repeat} debido a falta de capas.\")\n",
    "                repetition_layers = actual_layers_to_repeat\n",
    "\n",
    "            # Añadir la capa de repetición sin modificar su estructura\n",
    "            fixed_layers.extend([layer_type, repetition_layers, repetition_count, 0])\n",
    "            index += 4\n",
    "            continue\n",
    "\n",
    "        # Procesar cada tipo de capa normal con sus restricciones\n",
    "        if layer_type == 0:  # Conv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "\n",
    "        elif layer_type == 6:  # DepthwiseConv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "\n",
    "        elif layer_type == 2:  # MaxPooling\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                stride_idx = min(max(int(encoded_model[index + 1]), 0), 1)\n",
    "                fixed_layers.extend([layer_type, stride_idx, 0, 0])\n",
    "\n",
    "        elif layer_type == 3:  # Dropout\n",
    "            rate_idx = min(max(int(encoded_model[index + 1]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, rate_idx, 0, 0])\n",
    "\n",
    "        elif layer_type == 4:  # Dense\n",
    "            # Limitar el número de neuronas entre 1 y 512\n",
    "            neurons = min(max(int(encoded_model[index + 1]), 1), 512)\n",
    "            activation_idx = min(max(int(encoded_model[index + 2]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, neurons, activation_idx, 0])\n",
    "\n",
    "        elif layer_type == 1:  # BatchNorm\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        elif layer_type == 5:  # Flatten\n",
    "            if len(fixed_layers) < 16:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            elif input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "                input_is_flattened = True  # Marcar que ya hay un Flatten\n",
    "\n",
    "        elif layer_type == 7:  # DontCare\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        else: # DontCare\n",
    "          fixed_layers.extend([7, 0, 0, 0])\n",
    "\n",
    "        index += 4  # Avanzar al siguiente grupo de parámetros\n",
    "\n",
    "    return fixed_layers[:48]  # Limitar a 48 alelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MOTScfWjl5FP"
   },
   "outputs": [],
   "source": [
    "def decode_model_architecture(encoded_model):\n",
    "    \"\"\"\n",
    "    Decodifica la arquitectura del modelo a partir de la lista codificada de valores (índices),\n",
    "    aplicando las reglas de repetición y asegurando la inclusión de una capa convolucional inicial.\n",
    "    \"\"\"\n",
    "    model_dict = {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}]}  # Inserta Conv2D inicial\n",
    "    index = 0\n",
    "\n",
    "    while index < len(encoded_model):\n",
    "        layer_type = int(encoded_model[index])\n",
    "        param1 = encoded_model[index + 1]\n",
    "        param2 = encoded_model[index + 2]\n",
    "        param3 = encoded_model[index + 3]\n",
    "\n",
    "        if layer_type == 8:  # Capa de Repetition\n",
    "            repetition_layers = int(param1)\n",
    "            repetition_count = int(param2)\n",
    "            # Selecciona solo el grupo válido de capas para la repetición\n",
    "            layers_to_repeat = select_group_for_repetition(model_dict['layers'], repetition_layers)\n",
    "\n",
    "            if len(layers_to_repeat) > 0:\n",
    "                for _ in range(repetition_count):\n",
    "                    model_dict['layers'].extend(layers_to_repeat)\n",
    "\n",
    "        else:\n",
    "            decoded_layer = {}\n",
    "\n",
    "            if layer_type == 0:  # Conv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'Conv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 6:  # DepthwiseConv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'DepthwiseConv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 2:  # MaxPooling\n",
    "                decoded_layer = {\n",
    "                    'type': 'MaxPooling',\n",
    "                    'strides': stride_options.get(param1, 1)\n",
    "                }\n",
    "            elif layer_type == 3:  # Dropout\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dropout',\n",
    "                    'rate': dropout_options.get(param1, 0.2)\n",
    "                }\n",
    "            elif layer_type == 4:  # Dense\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dense',\n",
    "                    'units': max(1, min(param1, 512)),  # Limita `units` entre 1 y 512\n",
    "                    'activation': activation_options.get(param2, 'relu')\n",
    "                }\n",
    "            elif layer_type == 1:  # BatchNorm\n",
    "                decoded_layer = {'type': 'BatchNorm'}\n",
    "            elif layer_type == 5:  # Flatten\n",
    "                decoded_layer = {'type': 'Flatten'}\n",
    "            elif layer_type == 7:  # DontCare\n",
    "                decoded_layer = {'type': 'DontCare'}\n",
    "\n",
    "            model_dict['layers'].append(decoded_layer)\n",
    "\n",
    "        index += 4\n",
    "\n",
    "    # Asegura que haya una capa Flatten antes de la capa Dense final, si no ya existe una Flatten\n",
    "    if model_dict['layers'][-1]['type'] != 'Flatten':\n",
    "        model_dict['layers'].append({'type': 'Flatten'})\n",
    "\n",
    "    # Añade la capa Dense final obligatoria\n",
    "    model_dict['layers'].append({'type': 'Dense', 'units': 1, 'activation': 'sigmoid'})\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "def select_group_for_repetition(layers, repetition_layers):\n",
    "    \"\"\"\n",
    "    Selecciona el primer grupo válido para repetición en función de las reglas de compatibilidad.\n",
    "\n",
    "    Parameters:\n",
    "        layers (list): Lista de capas ya procesadas, donde cada capa es un diccionario.\n",
    "        repetition_layers (int): Número de capas hacia atrás para considerar en la repetición.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de capas compatibles para repetición.\n",
    "    \"\"\"\n",
    "    valid_layers = []\n",
    "    group_type = None\n",
    "\n",
    "    # Retrocede desde el final de `layers` para encontrar el grupo válido\n",
    "    for layer in reversed(layers[-repetition_layers:]):\n",
    "        if group_type is None:\n",
    "            # Determina el tipo de grupo\n",
    "            if layer['type'] in ['Flatten', 'Dense']:\n",
    "                group_type = 'dense'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling']:\n",
    "                group_type = 'convolutional'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['BatchNorm', 'DontCare']:  # BatchNorm y DontCare son compatibles con ambos grupos\n",
    "                valid_layers.insert(0, layer)\n",
    "        else:\n",
    "            # Agrega solo capas compatibles con el grupo seleccionado\n",
    "            if group_type == 'dense' and layer['type'] in ['Flatten', 'Dense', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif group_type == 'convolutional' and layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "\n",
    "    return valid_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IKKUOYNQl7N7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, DepthwiseConv2D\n",
    "\n",
    "\n",
    "\n",
    "def build_tf_model_from_dict(model_dict, input_shape=(28, 28, 3)):\n",
    "    \"\"\"\n",
    "    Construye un modelo de TensorFlow a partir de un diccionario JSON expandido.\n",
    "    \"\"\"\n",
    "    print(\"\\nConstruyendo el modelo en TensorFlow desde el JSON expandido...\")\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Conv2D':\n",
    "            model.add(Conv2D(filters=layer['filters'], kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "\n",
    "        elif layer['type'] == 'DepthwiseConv2D':\n",
    "            model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "\n",
    "        elif layer['type'] == 'BatchNorm':\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        elif layer['type'] == 'MaxPooling':\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=int(layer['strides']), padding='same'))\n",
    "\n",
    "        elif layer['type'] == 'Flatten':\n",
    "            model.add(Flatten())\n",
    "\n",
    "        elif layer['type'] == 'Dense':\n",
    "            model.add(Dense(units=int(layer['units']), activation=layer['activation']))\n",
    "\n",
    "        elif layer['type'] == 'Dropout':\n",
    "            model.add(Dropout(rate=layer['rate']))\n",
    "\n",
    "        elif layer['type'] == 'DontCare':\n",
    "            model.add(DontCareLayer())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yxJFgciUmBGz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_random_architecture():\n",
    "    num_layers = 12\n",
    "    layers = []\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        layer_type = random.choice([\n",
    "            'Conv2D', 'DepthwiseConv2D', 'BatchNorm', 'MaxPooling', 'Dropout',\n",
    "            'Dense', 'Flatten', 'DontCare', 'Repetition'\n",
    "        ])\n",
    "        layers.append(generate_layer(layer_type))\n",
    "    return {\"layers\": layers}\n",
    "\n",
    "def generate_layer(layer_type):\n",
    "    if layer_type == 'Conv2D':\n",
    "        return {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'DepthwiseConv2D':\n",
    "        return {\n",
    "            \"type\": \"DepthwiseConv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {\"type\": \"BatchNorm\"}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        return {\n",
    "            \"type\": \"MaxPooling\",\n",
    "            \"strides\": random.choice([1, 2])\n",
    "        }\n",
    "    elif layer_type == 'Dropout':\n",
    "        return {\n",
    "            \"type\": \"Dropout\",\n",
    "            \"rate\": random.choice([0.2, 0.3, 0.4, 0.5])\n",
    "        }\n",
    "    elif layer_type == 'Dense':\n",
    "        return {\n",
    "            \"type\": \"Dense\",\n",
    "            \"units\": random.randint(1, 128),  # Rango reducido para unidades\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {\"type\": \"Flatten\"}\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {\"type\": \"DontCare\"}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            \"type\": \"Repetition\",\n",
    "            \"repetition_layers\": random.randint(1, 3),  # Limitar el número de capas para repetir\n",
    "            \"repetition_count\": random.randint(1, 2)  # Limitar el conteo de repeticiones\n",
    "        }\n",
    "    return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torchaudio\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Resizing, Conv2D, Dropout, BatchNormalization, MaxPooling2D, MaxPool2D, Flatten, Dense, Input, LeakyReLU\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Importar funciones previamente definidas para codificar, decodificar y reparar arquitecturas\n",
    "# Y otras dependencias específicas como `build_tf_model_from_dict`, `generate_random_architecture`, etc.\n",
    "predefined_architectures = [\n",
    "    [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0],\n",
    "    [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0],\n",
    "    [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
    "]\n",
    "# Configuración de parámetros\n",
    "class Config:\n",
    "    def __init__(self, architecture='random', epochs=50, sample_rate=None, time=5, n_splits=5, window_size=5):\n",
    "        self.architecture = architecture\n",
    "        self.epochs = epochs\n",
    "        self.sample_rate = sample_rate\n",
    "        self.time = time\n",
    "        self.n_splits = n_splits\n",
    "        self.window_size = window_size\n",
    "\n",
    "# Cargar datos de audio\n",
    "def load_audio_data(directory, window_size, sample_rate):\n",
    "    audio_dict = {}\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            waveform, sr = torchaudio.load(os.path.join(directory, file_name))\n",
    "            if sample_rate is None:\n",
    "                sample_rate = sr\n",
    "            num_windows = int(waveform.shape[1] / (window_size * sample_rate))\n",
    "            for i in range(num_windows):\n",
    "                start = i * window_size * sample_rate\n",
    "                end = (i + 1) * window_size * sample_rate\n",
    "                audio_dict[f\"{file_name}_{i}\"] = waveform[:, start:end].numpy()\n",
    "    return audio_dict, sample_rate\n",
    "\n",
    "# Preprocesar datos de audio\n",
    "def preprocess_audio(audio_dict, sample_rate):\n",
    "    audio_dict = copy.deepcopy(audio_dict)\n",
    "    n_mels = 128\n",
    "    n_fft = int(sample_rate * 0.029)\n",
    "    hop_length = int(sample_rate * 0.010)\n",
    "    win_length = int(sample_rate * 0.025)\n",
    "\n",
    "    for filename, waveform in tqdm(audio_dict.items(), desc='MELSPECTROGRAM'):\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mels, hop_length=hop_length, win_length=win_length)(waveform)\n",
    "        spec = torchaudio.transforms.AmplitudeToDB()(spec)\n",
    "        spec = spec.numpy()\n",
    "        spec = (spec - spec.min()) / (spec.max() - spec.min())\n",
    "        audio_dict[filename] = spec\n",
    "    return audio_dict\n",
    "\n",
    "# Padding de los espectrogramas\n",
    "def pad_and_crop_spectrograms(spectrograms, target_shape=(128, 128)):\n",
    "    padded_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        if spec.shape[0] > target_shape[0]:\n",
    "            spec = spec[:target_shape[0], :]\n",
    "        if spec.shape[1] > target_shape[1]:\n",
    "            spec = spec[:, :target_shape[1]]\n",
    "        \n",
    "        pad_width = [(0, max(0, target_shape[0] - spec.shape[0])), \n",
    "                     (0, max(0, target_shape[1] - spec.shape[1]))]\n",
    "        \n",
    "        padded_spec = np.pad(spec, pad_width, mode='constant')\n",
    "        padded_spectrograms.append(padded_spec)\n",
    "    return np.array(padded_spectrograms)\n",
    "\n",
    "# Split de audio en train y test\n",
    "def train_test_split_audio(audio_dict):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID', 'PHQ-9 Score'], dtype={1: str})\n",
    "    df['labels'] = np.zeros([len(df),], dtype=int)\n",
    "    df.loc[df['PHQ-9 Score'] < 10, 'labels'] = 0\n",
    "    df.loc[df['PHQ-9 Score'] >= 10, 'labels'] = 1\n",
    "\n",
    "    labels = df.set_index('Participant_ID').to_dict()['labels']\n",
    "\n",
    "    X, Y = [], []\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        if ID in labels:\n",
    "            dep = 0 if labels[ID] == 0 else 1\n",
    "            [X.append(x) for x in data]\n",
    "            [Y.append(dep) for x in data]\n",
    "\n",
    "    X = pad_and_crop_spectrograms(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = X[..., np.newaxis]\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# Función de especificidad\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Entrenamiento y evaluación de cada arquitectura decodificada\n",
    "def train_and_evaluate_model(model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config):\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\", 'Precision', 'Recall'])\n",
    "    model.fit(X_train, Y_train, epochs=config.epochs, validation_data=(X_val, Y_val), verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    # Obtener predicciones para métricas adicionales\n",
    "    Y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = results[1]\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    specificity = specificity_score(Y_test, Y_pred)\n",
    "\n",
    "    return [results[0], accuracy, precision, recall, f1, specificity]\n",
    "\n",
    "\n",
    "# Asumimos que las funciones y clases como `build_tf_model_from_dict`, `generate_random_architecture`, \n",
    "# `encode_model_architecture`, `fixArch`, `decode_model_architecture`, y `train_and_evaluate_model` ya están definidas.\n",
    "\n",
    "\n",
    "# Función principal para generar y entrenar modelos (predefinidos y aleatorios)\n",
    "def generate_and_train_models(predefined_architectures, num_random_models=250, directory='./SM-27', target_shape=(128, 128, 1), use_kfold=True):\n",
    "    results_data = []\n",
    "    config = Config(epochs=50)\n",
    "\n",
    "    # Cargar y preprocesar datos de audio\n",
    "    print(\"Cargando y preprocesando datos de audio...\")\n",
    "    audio_dict, sample_rate = load_audio_data(directory, config.window_size, config.sample_rate)\n",
    "    audio_dict = preprocess_audio(audio_dict, sample_rate)\n",
    "    X, Y = train_test_split_audio(audio_dict)\n",
    "    X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if use_kfold:\n",
    "        kfold = KFold(n_splits=config.n_splits, shuffle=True)\n",
    "\n",
    "    # Entrenar y evaluar arquitecturas predefinidas\n",
    "    for i, architecture in enumerate(predefined_architectures):\n",
    "        print(f\"\\nEvaluando arquitectura predefinida {i + 1}/{len(predefined_architectures)}...\")\n",
    "        evaluate_and_store_model(architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, kfold, target_shape, results_data)\n",
    "\n",
    "    # Generar, entrenar y evaluar arquitecturas aleatorias\n",
    "    for i in range(num_random_models):\n",
    "        print(f\"\\nGenerando y evaluando modelo aleatorio {i + 1}/{num_random_models}...\")\n",
    "        random_architecture = generate_random_architecture()\n",
    "        encoded_architecture = encode_model_architecture(random_architecture, max_alleles=48)\n",
    "        repaired_architecture = fixArch(encoded_architecture)\n",
    "        evaluate_and_store_model(repaired_architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, kfold, target_shape, results_data)\n",
    "\n",
    "    # Guardar resultados en CSV\n",
    "    columns = [\"Encoded Architecture\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\"]\n",
    "    results_df = pd.DataFrame(results_data, columns=columns)\n",
    "    results_df.to_csv(\"./model_results_combined_50_epochs.csv\", index=False)\n",
    "    print(\"Resultados guardados en 'model_results_combined.csv'\")\n",
    "\n",
    "# Función para evaluar y almacenar los resultados de un modelo\n",
    "def evaluate_and_store_model(architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, kfold, target_shape, results_data):\n",
    "    repaired_architecture = fixArch(architecture)\n",
    "    decoded_model_dict = decode_model_architecture(repaired_architecture)\n",
    "    model_results = [repaired_architecture]\n",
    "\n",
    "    if use_kfold:\n",
    "        fold_results = []\n",
    "        for fold, (train_index, val_index) in enumerate(kfold.split(X_train_val)):\n",
    "            print(f\"Entrenando fold {fold + 1}/{config.n_splits}...\")\n",
    "            X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "            Y_train, Y_val = Y_train_val[train_index], Y_train_val[val_index]\n",
    "            tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "            fold_results.append(train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config))\n",
    "            print(f\"Fold {fold + 1} completado.\")\n",
    "\n",
    "        avg_results = np.mean(fold_results, axis=0)\n",
    "        model_results.extend(avg_results)\n",
    "\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=42)\n",
    "        tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "        single_run_results = train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config)\n",
    "        model_results.extend(single_run_results)\n",
    "        print(\"Modelo evaluado sin K-Fold Cross Validation.\")\n",
    "\n",
    "    results_data.append(model_results)\n",
    "\n",
    "# Ejecutar la generación y entrenamiento de modelos, incluyendo arquitecturas predefinidas y modelos aleatorios\n",
    "#generate_and_train_models(predefined_architectures, num_random_models=270, target_shape=(128, 128, 1), use_kfold=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "F1 = tfa.metrics.F1Score(num_classes=1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MELSPECTROGRAM: 100%|██████████| 5890/5890 [00:16<00:00, 348.34it/s]\n",
      "LABEL: 100%|██████████| 5890/5890 [00:00<00:00, 571650.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5890, 128, 128, 1), Y shape: (5890,)\n",
      "Testing model: exp2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp2:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 1 results for exp2: Loss=0.684, Accuracy=0.559, Precision=0.529, Recall=0.657, F1-Score=0.586, Specificity=0.472\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Fold 2 results for exp2: Loss=0.672, Accuracy=0.593, Precision=0.554, Recall=0.728, F1-Score=0.630, Specificity=0.472\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Fold 3 results for exp2: Loss=0.661, Accuracy=0.605, Precision=0.567, Recall=0.714, F1-Score=0.632, Specificity=0.507\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Fold 4 results for exp2: Loss=0.649, Accuracy=0.609, Precision=0.575, Recall=0.669, F1-Score=0.619, Specificity=0.554\n",
      "37/37 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp2: 100%|██████████| 1/1 [07:42<00:00, 462.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for exp2: Loss=0.640, Accuracy=0.612, Precision=0.582, Recall=0.648, F1-Score=0.613, Specificity=0.580\n",
      "Testing model: exp1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 1 results for exp1: Loss=0.683, Accuracy=0.555, Precision=0.518, Recall=0.911, F1-Score=0.660, Specificity=0.234\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 2 results for exp1: Loss=0.655, Accuracy=0.629, Precision=0.650, Recall=0.472, F1-Score=0.547, Specificity=0.771\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 3 results for exp1: Loss=0.650, Accuracy=0.597, Precision=0.747, Recall=0.227, F1-Score=0.348, Specificity=0.931\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 4 results for exp1: Loss=0.691, Accuracy=0.543, Precision=0.862, Recall=0.045, F1-Score=0.085, Specificity=0.994\n",
      "37/37 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp1: 100%|██████████| 1/1 [14:31<00:00, 871.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for exp1: Loss=0.712, Accuracy=0.536, Precision=0.833, Recall=0.027, F1-Score=0.052, Specificity=0.995\n",
      "Testing model: CNN_LF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for CNN_LF:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 1 results for CNN_LF: Loss=0.654, Accuracy=0.527, Precision=1.000, Recall=0.004, F1-Score=0.007, Specificity=1.000\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 2 results for CNN_LF: Loss=0.642, Accuracy=0.555, Precision=0.889, Recall=0.072, F1-Score=0.132, Specificity=0.992\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 3 results for CNN_LF: Loss=0.636, Accuracy=0.577, Precision=0.843, Recall=0.134, F1-Score=0.231, Specificity=0.977\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Fold 4 results for CNN_LF: Loss=0.628, Accuracy=0.600, Precision=0.849, Recall=0.191, F1-Score=0.312, Specificity=0.969\n",
      "37/37 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for CNN_LF: 100%|██████████| 1/1 [19:08<00:00, 1148.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for CNN_LF: Loss=0.622, Accuracy=0.610, Precision=0.868, Recall=0.211, F1-Score=0.340, Specificity=0.971\n",
      "Testing model: SPECTRO_CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for SPECTRO_CNN:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 1 results for SPECTRO_CNN: Loss=0.646, Accuracy=0.570, Precision=0.919, Recall=0.102, F1-Score=0.184, Specificity=0.992\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Fold 2 results for SPECTRO_CNN: Loss=0.637, Accuracy=0.644, Precision=0.885, Recall=0.288, F1-Score=0.435, Specificity=0.966\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 3 results for SPECTRO_CNN: Loss=0.637, Accuracy=0.666, Precision=0.851, Recall=0.358, F1-Score=0.504, Specificity=0.943\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 4 results for SPECTRO_CNN: Loss=0.637, Accuracy=0.674, Precision=0.838, Recall=0.388, F1-Score=0.531, Specificity=0.932\n",
      "37/37 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for SPECTRO_CNN: 100%|██████████| 1/1 [17:09<00:00, 1029.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for SPECTRO_CNN: Loss=0.634, Accuracy=0.680, Precision=0.797, Recall=0.436, F1-Score=0.564, Specificity=0.900\n",
      "\n",
      "Summary per architecture:\n",
      "exp2 - Loss: 0.661, Accuracy: 0.596, Precision: 0.561, Recall: 0.683, F1-Score: 0.616, Specificity: 0.517\n",
      "exp1 - Loss: 0.678, Accuracy: 0.572, Precision: 0.722, Recall: 0.336, F1-Score: 0.339, Specificity: 0.785\n",
      "CNN_LF - Loss: 0.637, Accuracy: 0.574, Precision: 0.890, Recall: 0.122, F1-Score: 0.205, Specificity: 0.982\n",
      "SPECTRO_CNN - Loss: 0.638, Accuracy: 0.647, Precision: 0.858, Recall: 0.314, F1-Score: 0.443, Specificity: 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "# Diccionario de arquitecturas\n",
    "arqs_to_test = {\n",
    "    \"exp2\": [\n",
    "        [7, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 4, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
    "    ],\n",
    "    \"exp1\": [\n",
    "        [6, 9, 0, 1, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n",
    "    ],\n",
    "    \"CNN_LF\": [\n",
    "        [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
    "    ],\n",
    "    \"SPECTRO_CNN\": [\n",
    "        [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Configuración de parámetros globales\n",
    "config = Config(epochs=50)\n",
    "# Cargar y procesar datos de audio\n",
    "audio_dict, sample_rate = load_audio_data('./SM-27', config.window_size, config.sample_rate)\n",
    "audio_dict = preprocess_audio(audio_dict, sample_rate)\n",
    "\n",
    "# División inicial en conjuntos de datos\n",
    "X, Y = train_test_split_audio(audio_dict)\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resultados por arquitectura\n",
    "results = {key: [] for key in arqs_to_test.keys()}\n",
    "\n",
    "# Configuración de parámetros globales\n",
    "config = Config(epochs=50)\n",
    "\n",
    "# Resultados por arquitectura\n",
    "all_fold_results = []  # Para almacenar resultados de cada fold\n",
    "results = {key: [] for key in arqs_to_test.keys()}  # Resumen por arquitectura\n",
    "\n",
    "# Loop para cada arquitectura en el diccionario\n",
    "for model_name, architectures in arqs_to_test.items():\n",
    "    print(f\"Testing model: {model_name}\")\n",
    "    for arq in tqdm(architectures, desc=f\"Testing architectures for {model_name}\"):\n",
    "        # Ajustar la arquitectura\n",
    "        fixed_arch = fixArch(arq, verbose=True)\n",
    "        model_dict = decode_model_architecture(fixed_arch)\n",
    "        \n",
    "        # Crear el modelo\n",
    "        model = build_tf_model_from_dict(model_dict, input_shape=(128, 128, 1))\n",
    "        \n",
    "        # Aplicar K-Fold\n",
    "        kfold = KFold(n_splits=config.n_splits, shuffle=True)\n",
    "        fold_metrics = []\n",
    "        \n",
    "        for fold, (train_index, val_index) in enumerate(kfold.split(X_train_val), 1):\n",
    "            X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "            Y_train, Y_val = Y_train_val[train_index], Y_train_val[val_index]\n",
    "            \n",
    "            # Compilar y entrenar el modelo\n",
    "            model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\", 'Precision', 'Recall', F1])\n",
    "            model.fit(X_train, Y_train, epochs=config.epochs, validation_data=(X_val, Y_val), verbose=0)\n",
    "            \n",
    "            # Evaluar el modelo\n",
    "            results_fold = model.evaluate(X_test, Y_test, verbose=0)\n",
    "            Y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "            \n",
    "            # Calcular métricas adicionales\n",
    "            precision = precision_score(Y_test, Y_pred)\n",
    "            recall = recall_score(Y_test, Y_pred)\n",
    "            f1 = f1_score(Y_test, Y_pred)\n",
    "            specificity = specificity_score(Y_test, Y_pred)\n",
    "            \n",
    "            # Guardar resultados de cada fold\n",
    "            fold_result = {\n",
    "                \"Architecture\": model_name,\n",
    "                \"Fold\": fold,\n",
    "                \"Loss\": results_fold[0],\n",
    "                \"Accuracy\": results_fold[1],\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1-Score\": f1,\n",
    "                \"Specificity\": specificity\n",
    "            }\n",
    "            all_fold_results.append(fold_result)\n",
    "            fold_metrics.append([results_fold[0], results_fold[1], precision, recall, f1, specificity])\n",
    "            \n",
    "            # Mostrar progreso de cada fold\n",
    "            print(f\"Fold {fold} results for {model_name}: Loss={results_fold[0]:.3f}, \"\n",
    "                  f\"Accuracy={results_fold[1]:.3f}, Precision={precision:.3f}, \"\n",
    "                  f\"Recall={recall:.3f}, F1-Score={f1:.3f}, Specificity={specificity:.3f}\")\n",
    "        \n",
    "        # Promediar métricas por fold\n",
    "        avg_metrics = np.mean(fold_metrics, axis=0)\n",
    "        results[model_name].append(avg_metrics)\n",
    "\n",
    "# Crear un DataFrame con los resultados de todos los folds\n",
    "df_results = pd.DataFrame(all_fold_results)\n",
    "\n",
    "# Ajustar decimales a 3 dígitos (puedes cambiarlo según sea necesario)\n",
    "df_results = df_results.round(3)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "df_results.to_csv(\"./ga_model_comparison_results.csv\", index=False)\n",
    "\n",
    "# Mostrar el resumen por arquitectura\n",
    "print(\"\\nSummary per architecture:\")\n",
    "for model_name, metrics in results.items():\n",
    "    avg_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"{model_name} - Loss: {avg_metrics[0]:.3f}, Accuracy: {avg_metrics[1]:.3f}, \"\n",
    "          f\"Precision: {avg_metrics[2]:.3f}, Recall: {avg_metrics[3]:.3f}, \"\n",
    "          f\"F1-Score: {avg_metrics[4]:.3f}, Specificity: {avg_metrics[5]:.3f}\")\n",
    "\n",
    "# Crear gráfico de barras\n",
    "metrics_names = [\"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Specificity\"]\n",
    "x_labels = list(results.keys())\n",
    "averaged_metrics = np.array([np.mean(metrics, axis=0) for metrics in results.values()])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "bar_width = 0.15\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    ax.bar(x + i * bar_width, averaged_metrics[:, i], bar_width, label=metric)\n",
    "\n",
    "ax.set_xlabel(\"Model Architectures\")\n",
    "ax.set_ylabel(\"Metric Scores\")\n",
    "ax.set_title(\"Comparison of Metrics Across Architectures\")\n",
    "ax.set_xticks(x + (bar_width * (len(metrics_names) - 1)) / 2)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Architecture</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN_LF</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.5738</td>\n",
       "      <td>0.8898</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPECTRO_CNN</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6382</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.8580</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>0.9466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.3384</td>\n",
       "      <td>0.7850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.5956</td>\n",
       "      <td>0.5614</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.6160</td>\n",
       "      <td>0.5170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fold    Loss  Accuracy  Precision  Recall  F1-Score  Specificity\n",
       "Architecture                                                                  \n",
       "CNN_LF         3.0  0.6364    0.5738     0.8898  0.1224    0.2044       0.9818\n",
       "SPECTRO_CNN    3.0  0.6382    0.6468     0.8580  0.3144    0.4436       0.9466\n",
       "exp1           3.0  0.6782    0.5720     0.7220  0.3364    0.3384       0.7850\n",
       "exp2           3.0  0.6612    0.5956     0.5614  0.6832    0.6160       0.5170"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby('Architecture').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-Wn8zMQSpva",
    "outputId": "a483f55b-1869-445c-c1c5-0560babd8122"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086797843097632"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = max(best_models, key=lambda x: x['fitness'])\n",
    "best_model['fitness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAVZIg3-bbII",
    "outputId": "1ae23da3-61bf-494f-e982-78c403e5c7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 0, 1, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(best_model['individual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wGVVEFTS844",
    "outputId": "249d7596-ce36-4bee-ac0a-76b799ca1168"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'type': 'Conv2D',\n",
       "   'filters': 32,\n",
       "   'strides': 1,\n",
       "   'activation': 'relu'},\n",
       "  {'type': 'DepthwiseConv2D',\n",
       "   'filters': 9,\n",
       "   'strides': 1,\n",
       "   'activation': 'leaky_relu'},\n",
       "  {'type': 'Dropout', 'rate': 0.5},\n",
       "  {'type': 'MaxPooling', 'strides': 2},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'Flatten'},\n",
       "  {'type': 'Dropout', 'rate': 0.4},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'BatchNorm'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'Flatten'},\n",
       "  {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = decode_model_architecture(best_model['individual'])\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5AVvAx2S-5Q",
    "outputId": "edc1d9b4-e9b4-4b58-d0bd-0cebdf300549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = build_tf_model_from_dict(model_dict)\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en2Yo7OtTAay",
    "outputId": "f3cd2e93-fa33-4f24-f7c4-95727a0fad37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "cnn.save('/drive/MyDrive/NAS/EC_Project/best_model_mu100_gens1000_F0p5_5000mu_autoadapt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ieouY-Z7TBuV"
   },
   "outputs": [],
   "source": [
    "cnn.save('/drive/MyDrive/NAS/EC_Project/best_model_mu100_gens1000_F0p5_5000mu_autoadapt.keras')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
