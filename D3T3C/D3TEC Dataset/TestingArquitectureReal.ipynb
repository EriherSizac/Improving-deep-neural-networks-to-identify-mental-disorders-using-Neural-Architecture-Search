{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KR37uGe3lqIt",
    "outputId": "7e46a98e-7d1e-43e7-b7d3-0ddb166976c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codificación real de Conv2D: [0, 16, 0, 0]\n",
      "Decodificación Conv2D: {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Dropout: [3, 1, 0, 0]\n",
      "Decodificación Dropout: {'type': 'Dropout', 'rate': 0.3}\n",
      "\n",
      "Codificación real de Dense: [4, 128, 0, 0]\n",
      "Decodificación Dense: {'type': 'Dense', 'units': 128, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Repetition: [8, 3, 5, 0]\n",
      "Decodificación Repetition: {'type': 'Repetition', 'repetition_layers': 3, 'repetition_count': 5}\n"
     ]
    }
   ],
   "source": [
    "# Opciones de decodificación para otros parámetros\n",
    "layer_type_options = {\n",
    "    0: 'Conv2D',\n",
    "    1: 'BatchNorm',\n",
    "    2: 'MaxPooling',\n",
    "    3: 'Dropout',\n",
    "    4: 'Dense',\n",
    "    5: 'Flatten',\n",
    "    6: 'DepthwiseConv2D',\n",
    "    7: 'DontCare',\n",
    "    8: 'Repetition'\n",
    "}\n",
    "stride_options = {0: 1, 1: 2}\n",
    "dropout_options = {0: 0.2, 1: 0.3, 2: 0.4, 3: 0.5}\n",
    "activation_options = {0: 'relu', 1: 'leaky_relu', 2: 'sigmoid', 3: 'tanh'}\n",
    "\n",
    "# Función para codificar los parámetros de la capa\n",
    "def encode_layer_params(layer_type_idx, param1=0, param2=0, param3=0):\n",
    "    \"\"\"\n",
    "    Codifica una capa en una lista en función del tipo de capa y sus parámetros.\n",
    "\n",
    "    layer_type_idx : int : índice del tipo de capa según layer_type_options.\n",
    "    param1         : int/float : filtros, neuronas, capas de repetición, etc.\n",
    "    param2         : int : stride, número de repeticiones, etc.\n",
    "    param3         : int : índice de activación o tasa de dropout.\n",
    "    \"\"\"\n",
    "    return [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "# Función para decodificar los parámetros de la capa\n",
    "def decode_layer_params(encoded_params):\n",
    "    \"\"\"\n",
    "    Decodifica una capa desde su representación codificada en parámetros interpretables.\n",
    "\n",
    "    encoded_params : list : [tipo de capa, param1, param2, param3].\n",
    "    \"\"\"\n",
    "    layer_type_idx = encoded_params[0]\n",
    "    layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "\n",
    "    # Decodificar en función del tipo de capa\n",
    "    if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "        filters = max(4, min(encoded_params[1], 32))  # Limitar filtros entre 4 y 32\n",
    "        strides = stride_options.get(encoded_params[2], 1)\n",
    "        activation = activation_options.get(encoded_params[3], 'relu')\n",
    "        return {\n",
    "            'type': layer_type,\n",
    "            'filters': filters,\n",
    "            'strides': strides,\n",
    "            'activation': activation\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {'type': 'BatchNorm'}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        strides = stride_options.get(encoded_params[1], 1)\n",
    "        return {'type': 'MaxPooling', 'strides': strides}\n",
    "    elif layer_type == 'Dropout':\n",
    "        rate = dropout_options.get(encoded_params[1], 0.2)\n",
    "        return {'type': 'Dropout', 'rate': rate}\n",
    "    elif layer_type == 'Dense':\n",
    "        units = max(1, min(encoded_params[1], 512))  # Limitar unidades entre 1 y 512\n",
    "        activation = activation_options.get(encoded_params[2], 'relu')\n",
    "        return {'type': 'Dense', 'units': units, 'activation': activation}\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {'type': 'Flatten'}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            'type': 'Repetition',\n",
    "            'repetition_layers': int(encoded_params[1]),\n",
    "            'repetition_count': int(encoded_params[2])\n",
    "        }\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {'type': \"DontCare\"}\n",
    "\n",
    "    return None\n",
    "\n",
    "# Ejemplos de codificación y decodificación\n",
    "encoded_conv2d = encode_layer_params(0, 16, 0, 0)  # Conv2D con 16 filtros, stride 1 y activación ReLU\n",
    "decoded_conv2d = decode_layer_params(encoded_conv2d)\n",
    "print(f\"\\nCodificación real de Conv2D: {encoded_conv2d}\")\n",
    "print(f\"Decodificación Conv2D: {decoded_conv2d}\")\n",
    "\n",
    "encoded_dropout = encode_layer_params(3, 1)  # Dropout con tasa de 0.3\n",
    "decoded_dropout = decode_layer_params(encoded_dropout)\n",
    "print(f\"\\nCodificación real de Dropout: {encoded_dropout}\")\n",
    "print(f\"Decodificación Dropout: {decoded_dropout}\")\n",
    "\n",
    "encoded_dense = encode_layer_params(4, 128, 0)  # Dense con 128 neuronas y activación ReLU\n",
    "decoded_dense = decode_layer_params(encoded_dense)\n",
    "print(f\"\\nCodificación real de Dense: {encoded_dense}\")\n",
    "print(f\"Decodificación Dense: {decoded_dense}\")\n",
    "\n",
    "encoded_repetition = encode_layer_params(8, 3, 5)  # Repetition para repetir las últimas 3 capas 5 veces\n",
    "decoded_repetition = decode_layer_params(encoded_repetition)\n",
    "print(f\"\\nCodificación real de Repetition: {encoded_repetition}\")\n",
    "print(f\"Decodificación Repetition: {decoded_repetition}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SMmKhGcf4NGU"
   },
   "outputs": [],
   "source": [
    "def int_to_real_dom(num, domain):\n",
    "  min_i, max_i = domain\n",
    "  r = (num - min_i) / (max_i - min_i)\n",
    "  return r\n",
    "\n",
    "def real_to_int_dom(num, domain):\n",
    "  min_i, max_i = domain\n",
    "  value = min_i + num * (max_i - min_i)\n",
    "  if isinstance(min_i, int) and isinstance(max_i, int):\n",
    "      value = int(round(value))\n",
    "  return value\n",
    "\n",
    "def convert_individual(ind, to_real=True):\n",
    "    real_rep = []\n",
    "    N = max(layer_type_options.keys())\n",
    "    for i in range(0, len(ind), 4):\n",
    "        layer_type_idx = ind[i]\n",
    "        domain_layer_type = [0, N]\n",
    "        if to_real:\n",
    "            real_rep.append(int_to_real_dom(layer_type_idx, domain_layer_type))\n",
    "            layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "        else:\n",
    "            real_rep.append(real_to_int_dom(layer_type_idx, domain_layer_type))\n",
    "            layer_type = layer_type_options.get(real_rep[i], 'DontCare')\n",
    "\n",
    "        # Decode based on layer type\n",
    "        if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [4, 32]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [0, 1]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 3], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [4, 32]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [0, 1]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 3], [0, 3]))\n",
    "        elif layer_type == 'BatchNorm':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "        elif layer_type == 'MaxPooling':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [0, 1]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [0, 1]))\n",
    "            real_rep.extend([0, 0])\n",
    "        elif layer_type == 'Dropout':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [0, 3]))\n",
    "            real_rep.extend([0, 0])\n",
    "        elif layer_type == 'Dense':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [1, 512]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [1, 512]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [0, 3]))\n",
    "            real_rep.append(0)\n",
    "        elif layer_type == 'Flatten':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "        elif layer_type == 'Repetition':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [1, 4]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [1, 32]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [1, 4]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [1, 32]))\n",
    "            real_rep.append(0)\n",
    "        elif layer_type == 'DontCare':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "    return real_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecnYEmcw8aLv",
    "outputId": "f815a803-ff1e-4905-e4da-3fb4c84bc24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 6, 5, 0, 2, 8, 1, 1, 0, 4, 17, 3, 0, 4, 22, 0, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 3, 1, 0, 0, 4, 63, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
      "[0.125, 0, 0, 0, 0.75, 0.03571428571428571, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0, 0.5, 0.03131115459882583, 1.0, 0, 0.5, 0.0410958904109589, 0.0, 0, 0.875, 0, 0, 0, 0.0, 0.25, 1.0, 1.0, 0.375, 0.0, 0, 0, 0.375, 0.3333333333333333, 0, 0, 0.5, 0.12133072407045009, 1.0, 0, 0.125, 0, 0, 0, 0.625, 0, 0, 0]\n",
      "[1, 0, 0, 0, 6, 5, 0, 2, 8, 1, 1, 0, 4, 17, 3, 0, 4, 22, 0, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 3, 1, 0, 0, 4, 63, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 0, 0, 0, 6, 5, 0, 2, 8, 1, 1, 0, 4, 17, 3, 0, 4, 22, 0, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 3, 1, 0, 0, 4, 63, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
    "print(x)\n",
    "y = convert_individual(x)\n",
    "print(y)\n",
    "z = convert_individual(y, to_real=False)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8UHDkV27ltyD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Clase para capas neutrales 'DontCare'\n",
    "class DontCareLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(DontCareLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g0eLaXdQluzl"
   },
   "outputs": [],
   "source": [
    "def encode_model_architecture(model_dict, max_alleles=48):\n",
    "    \"\"\"\n",
    "    Codifica la arquitectura del modelo en una lista de valores con un máximo de `max_alleles`.\n",
    "    Cada capa se codifica en función de sus parámetros.\n",
    "    \"\"\"\n",
    "    encoded_layers = []\n",
    "    total_alleles = 0\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Repetition':  # Codificar capa de repetición\n",
    "            encoded_layer = encode_layer_params(\n",
    "                layer_type_idx=8,  # índice para 'Repetition'\n",
    "                param1=layer.get('repetition_layers', 0),\n",
    "                param2=layer.get('repetition_count', 1)\n",
    "            )\n",
    "        else:\n",
    "            layer_type_idx = next(\n",
    "                key for key, value in layer_type_options.items() if value == layer['type']\n",
    "            )\n",
    "\n",
    "            # Codificar parámetros específicos de cada tipo de capa\n",
    "            if layer['type'] in ['Conv2D', 'DepthwiseConv2D']:\n",
    "                # Limitar filtros dentro del rango [4, 32]\n",
    "                param1 = max(4, min(layer.get('filters', 8), 32))\n",
    "                param2 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                param3 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "            elif layer['type'] == 'Dense':\n",
    "                # Limitar neuronas dentro del rango [1, 512]\n",
    "                param1 = max(1, min(layer.get('units', 1), 512))\n",
    "                param2 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, 0]\n",
    "\n",
    "            elif layer['type'] == 'MaxPooling':\n",
    "                param1 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Dropout':\n",
    "                param1 = next((key for key, value in dropout_options.items() if value == layer.get('rate', 0.2)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'BatchNorm':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Flatten':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'DontCare':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "        # Añadir la codificación de la capa a la lista de alelos\n",
    "        encoded_layers.extend(encoded_layer)\n",
    "        total_alleles += len(encoded_layer)\n",
    "\n",
    "    # Rellenar con 'DontCare' si el total de alelos es menor que `max_alleles`\n",
    "    while total_alleles < max_alleles:\n",
    "        dont_care_encoding = encode_layer_params(7)  # índice de 'DontCare'\n",
    "        encoded_layers.extend(dont_care_encoding)\n",
    "        total_alleles += len(dont_care_encoding)\n",
    "\n",
    "    # Recortar si excede `max_alleles`\n",
    "    final_encoding = encoded_layers[:max_alleles]\n",
    "    #print(f\"Final Encoded Model: {final_encoding}\")\n",
    "\n",
    "    return final_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tDFQVy0Tlwpx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fixArch(encoded_model, verbose=False):\n",
    "    \"\"\"\n",
    "    Corrige la arquitectura codificada del modelo, asegurando que:\n",
    "    - Se evite la presencia de capas incompatibles después de una capa Flatten.\n",
    "    - En caso de una capa de Repetition, se ajuste el alcance de repetición si no hay suficientes capas anteriores.\n",
    "\n",
    "    Parameters:\n",
    "        encoded_model (list): Lista codificada de la arquitectura del modelo.\n",
    "        verbose (bool): Si es True, muestra las correcciones realizadas.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista con la arquitectura corregida, truncada a un máximo de 48 alelos.\n",
    "    \"\"\"\n",
    "\n",
    "    fixed_layers = []  # Lista que almacenará la arquitectura corregida\n",
    "    input_is_flattened = False  # Indicador para saber si ya hay una capa Flatten en el modelo\n",
    "    index = 0  # Índice para recorrer el modelo codificado\n",
    "\n",
    "    # Procesar cada capa en el modelo sin forzar la primera capa a ser específica\n",
    "    while index < len(encoded_model) and len(fixed_layers) < 48:\n",
    "        layer_type = int(encoded_model[index])  # Obtener el tipo de capa actual\n",
    "\n",
    "        # Procesar la capa de Repetition\n",
    "        if layer_type == 8:\n",
    "            repetition_layers = int(encoded_model[index + 1])  # Número de capas a repetir\n",
    "            repetition_count = min(max(int(encoded_model[index + 2]), 0), 32)  # Cantidad de repeticiones\n",
    "\n",
    "            # Verificar si hay suficientes capas para la repetición solicitada\n",
    "            actual_layers_to_repeat = min(repetition_layers, len(fixed_layers) // 4)\n",
    "\n",
    "            if actual_layers_to_repeat != repetition_layers:\n",
    "                if verbose:\n",
    "                    print(f\"Ajustando alcance de repetición de {repetition_layers} a {actual_layers_to_repeat} debido a falta de capas.\")\n",
    "                repetition_layers = actual_layers_to_repeat\n",
    "\n",
    "            # Añadir la capa de repetición sin modificar su estructura\n",
    "            fixed_layers.extend([layer_type, repetition_layers, repetition_count, 0])\n",
    "            index += 4\n",
    "            continue\n",
    "\n",
    "        # Procesar cada tipo de capa normal con sus restricciones\n",
    "        if layer_type == 0:  # Conv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "\n",
    "        elif layer_type == 6:  # DepthwiseConv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "\n",
    "        elif layer_type == 2:  # MaxPooling\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                stride_idx = min(max(int(encoded_model[index + 1]), 0), 1)\n",
    "                fixed_layers.extend([layer_type, stride_idx, 0, 0])\n",
    "\n",
    "        elif layer_type == 3:  # Dropout\n",
    "            rate_idx = min(max(int(encoded_model[index + 1]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, rate_idx, 0, 0])\n",
    "\n",
    "        elif layer_type == 4:  # Dense\n",
    "            # Limitar el número de neuronas entre 1 y 512\n",
    "            neurons = min(max(int(encoded_model[index + 1]), 1), 512)\n",
    "            activation_idx = min(max(int(encoded_model[index + 2]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, neurons, activation_idx, 0])\n",
    "\n",
    "        elif layer_type == 1:  # BatchNorm\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        elif layer_type == 5:  # Flatten\n",
    "            if len(fixed_layers) < 16:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            elif input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "                input_is_flattened = True  # Marcar que ya hay un Flatten\n",
    "\n",
    "        elif layer_type == 7:  # DontCare\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        else: # DontCare\n",
    "          fixed_layers.extend([7, 0, 0, 0])\n",
    "\n",
    "        index += 4  # Avanzar al siguiente grupo de parámetros\n",
    "\n",
    "    return fixed_layers[:48]  # Limitar a 48 alelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MOTScfWjl5FP"
   },
   "outputs": [],
   "source": [
    "def decode_model_architecture(encoded_model):\n",
    "    \"\"\"\n",
    "    Decodifica la arquitectura del modelo a partir de la lista codificada de valores (índices),\n",
    "    aplicando las reglas de repetición y asegurando la inclusión de una capa convolucional inicial.\n",
    "    \"\"\"\n",
    "    model_dict = {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}]}  # Inserta Conv2D inicial\n",
    "    index = 0\n",
    "\n",
    "    while index < len(encoded_model):\n",
    "        layer_type = int(encoded_model[index])\n",
    "        param1 = encoded_model[index + 1]\n",
    "        param2 = encoded_model[index + 2]\n",
    "        param3 = encoded_model[index + 3]\n",
    "\n",
    "        if layer_type == 8:  # Capa de Repetition\n",
    "            repetition_layers = int(param1)\n",
    "            repetition_count = int(param2)\n",
    "            # Selecciona solo el grupo válido de capas para la repetición\n",
    "            layers_to_repeat = select_group_for_repetition(model_dict['layers'], repetition_layers)\n",
    "\n",
    "            if len(layers_to_repeat) > 0:\n",
    "                for _ in range(repetition_count):\n",
    "                    model_dict['layers'].extend(layers_to_repeat)\n",
    "\n",
    "        else:\n",
    "            decoded_layer = {}\n",
    "\n",
    "            if layer_type == 0:  # Conv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'Conv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 6:  # DepthwiseConv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'DepthwiseConv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 2:  # MaxPooling\n",
    "                decoded_layer = {\n",
    "                    'type': 'MaxPooling',\n",
    "                    'strides': stride_options.get(param1, 1)\n",
    "                }\n",
    "            elif layer_type == 3:  # Dropout\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dropout',\n",
    "                    'rate': dropout_options.get(param1, 0.2)\n",
    "                }\n",
    "            elif layer_type == 4:  # Dense\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dense',\n",
    "                    'units': max(1, min(param1, 512)),  # Limita `units` entre 1 y 512\n",
    "                    'activation': activation_options.get(param2, 'relu')\n",
    "                }\n",
    "            elif layer_type == 1:  # BatchNorm\n",
    "                decoded_layer = {'type': 'BatchNorm'}\n",
    "            elif layer_type == 5:  # Flatten\n",
    "                decoded_layer = {'type': 'Flatten'}\n",
    "            elif layer_type == 7:  # DontCare\n",
    "                decoded_layer = {'type': 'DontCare'}\n",
    "\n",
    "            model_dict['layers'].append(decoded_layer)\n",
    "\n",
    "        index += 4\n",
    "\n",
    "    # Asegura que haya una capa Flatten antes de la capa Dense final, si no ya existe una Flatten\n",
    "    if model_dict['layers'][-1]['type'] != 'Flatten':\n",
    "        model_dict['layers'].append({'type': 'Flatten'})\n",
    "\n",
    "    # Añade la capa Dense final obligatoria\n",
    "    model_dict['layers'].append({'type': 'Dense', 'units': 1, 'activation': 'sigmoid'})\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "def select_group_for_repetition(layers, repetition_layers):\n",
    "    \"\"\"\n",
    "    Selecciona el primer grupo válido para repetición en función de las reglas de compatibilidad.\n",
    "\n",
    "    Parameters:\n",
    "        layers (list): Lista de capas ya procesadas, donde cada capa es un diccionario.\n",
    "        repetition_layers (int): Número de capas hacia atrás para considerar en la repetición.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de capas compatibles para repetición.\n",
    "    \"\"\"\n",
    "    valid_layers = []\n",
    "    group_type = None\n",
    "\n",
    "    # Retrocede desde el final de `layers` para encontrar el grupo válido\n",
    "    for layer in reversed(layers[-repetition_layers:]):\n",
    "        if group_type is None:\n",
    "            # Determina el tipo de grupo\n",
    "            if layer['type'] in ['Flatten', 'Dense']:\n",
    "                group_type = 'dense'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling']:\n",
    "                group_type = 'convolutional'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['BatchNorm', 'DontCare']:  # BatchNorm y DontCare son compatibles con ambos grupos\n",
    "                valid_layers.insert(0, layer)\n",
    "        else:\n",
    "            # Agrega solo capas compatibles con el grupo seleccionado\n",
    "            if group_type == 'dense' and layer['type'] in ['Flatten', 'Dense', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif group_type == 'convolutional' and layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "\n",
    "    return valid_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IKKUOYNQl7N7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, DepthwiseConv2D\n",
    "\n",
    "\n",
    "\n",
    "def build_tf_model_from_dict(model_dict, input_shape=(28, 28, 3)):\n",
    "    \"\"\"\n",
    "    Construye un modelo de TensorFlow a partir de un diccionario JSON expandido.\n",
    "    \"\"\"\n",
    "    print(\"\\nConstruyendo el modelo en TensorFlow desde el JSON expandido...\")\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Conv2D':\n",
    "            model.add(Conv2D(filters=layer['filters'], kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "\n",
    "        elif layer['type'] == 'DepthwiseConv2D':\n",
    "            model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "\n",
    "        elif layer['type'] == 'BatchNorm':\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        elif layer['type'] == 'MaxPooling':\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=int(layer['strides']), padding='same'))\n",
    "\n",
    "        elif layer['type'] == 'Flatten':\n",
    "            model.add(Flatten())\n",
    "\n",
    "        elif layer['type'] == 'Dense':\n",
    "            model.add(Dense(units=int(layer['units']), activation=layer['activation']))\n",
    "\n",
    "        elif layer['type'] == 'Dropout':\n",
    "            model.add(Dropout(rate=layer['rate']))\n",
    "\n",
    "        elif layer['type'] == 'DontCare':\n",
    "            model.add(DontCareLayer())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yxJFgciUmBGz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_random_architecture():\n",
    "    num_layers = 12\n",
    "    layers = []\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        layer_type = random.choice([\n",
    "            'Conv2D', 'DepthwiseConv2D', 'BatchNorm', 'MaxPooling', 'Dropout',\n",
    "            'Dense', 'Flatten', 'DontCare', 'Repetition'\n",
    "        ])\n",
    "        layers.append(generate_layer(layer_type))\n",
    "    return {\"layers\": layers}\n",
    "\n",
    "def generate_layer(layer_type):\n",
    "    if layer_type == 'Conv2D':\n",
    "        return {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'DepthwiseConv2D':\n",
    "        return {\n",
    "            \"type\": \"DepthwiseConv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {\"type\": \"BatchNorm\"}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        return {\n",
    "            \"type\": \"MaxPooling\",\n",
    "            \"strides\": random.choice([1, 2])\n",
    "        }\n",
    "    elif layer_type == 'Dropout':\n",
    "        return {\n",
    "            \"type\": \"Dropout\",\n",
    "            \"rate\": random.choice([0.2, 0.3, 0.4, 0.5])\n",
    "        }\n",
    "    elif layer_type == 'Dense':\n",
    "        return {\n",
    "            \"type\": \"Dense\",\n",
    "            \"units\": random.randint(1, 128),  # Rango reducido para unidades\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {\"type\": \"Flatten\"}\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {\"type\": \"DontCare\"}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            \"type\": \"Repetition\",\n",
    "            \"repetition_layers\": random.randint(1, 3),  # Limitar el número de capas para repetir\n",
    "            \"repetition_count\": random.randint(1, 2)  # Limitar el conteo de repeticiones\n",
    "        }\n",
    "    return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torchaudio\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Resizing, Conv2D, Dropout, BatchNormalization, MaxPooling2D, MaxPool2D, Flatten, Dense, Input, LeakyReLU\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Importar funciones previamente definidas para codificar, decodificar y reparar arquitecturas\n",
    "# Y otras dependencias específicas como `build_tf_model_from_dict`, `generate_random_architecture`, etc.\n",
    "predefined_architectures = [\n",
    "    [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0],\n",
    "    [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0],\n",
    "    [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
    "]\n",
    "# Configuración de parámetros\n",
    "class Config:\n",
    "    def __init__(self, architecture='random', epochs=50, sample_rate=None, time=5, n_splits=5, window_size=5):\n",
    "        self.architecture = architecture\n",
    "        self.epochs = epochs\n",
    "        self.sample_rate = sample_rate\n",
    "        self.time = time\n",
    "        self.n_splits = n_splits\n",
    "        self.window_size = window_size\n",
    "\n",
    "# Cargar datos de audio\n",
    "def load_audio_data(directory, window_size, sample_rate):\n",
    "    audio_dict = {}\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            waveform, sr = torchaudio.load(os.path.join(directory, file_name))\n",
    "            if sample_rate is None:\n",
    "                sample_rate = sr\n",
    "            num_windows = int(waveform.shape[1] / (window_size * sample_rate))\n",
    "            for i in range(num_windows):\n",
    "                start = i * window_size * sample_rate\n",
    "                end = (i + 1) * window_size * sample_rate\n",
    "                audio_dict[f\"{file_name}_{i}\"] = waveform[:, start:end].numpy()\n",
    "    return audio_dict, sample_rate\n",
    "\n",
    "# Preprocesar datos de audio\n",
    "def preprocess_audio(audio_dict, sample_rate):\n",
    "    audio_dict = copy.deepcopy(audio_dict)\n",
    "    n_mels = 128\n",
    "    n_fft = int(sample_rate * 0.029)\n",
    "    hop_length = int(sample_rate * 0.010)\n",
    "    win_length = int(sample_rate * 0.025)\n",
    "\n",
    "    for filename, waveform in tqdm(audio_dict.items(), desc='MELSPECTROGRAM'):\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mels, hop_length=hop_length, win_length=win_length)(waveform)\n",
    "        spec = torchaudio.transforms.AmplitudeToDB()(spec)\n",
    "        spec = spec.numpy()\n",
    "        spec = (spec - spec.min()) / (spec.max() - spec.min())\n",
    "        audio_dict[filename] = spec\n",
    "    return audio_dict\n",
    "\n",
    "# Padding de los espectrogramas\n",
    "def pad_and_crop_spectrograms(spectrograms, target_shape=(128, 128)):\n",
    "    padded_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        if spec.shape[0] > target_shape[0]:\n",
    "            spec = spec[:target_shape[0], :]\n",
    "        if spec.shape[1] > target_shape[1]:\n",
    "            spec = spec[:, :target_shape[1]]\n",
    "        \n",
    "        pad_width = [(0, max(0, target_shape[0] - spec.shape[0])), \n",
    "                     (0, max(0, target_shape[1] - spec.shape[1]))]\n",
    "        \n",
    "        padded_spec = np.pad(spec, pad_width, mode='constant')\n",
    "        padded_spectrograms.append(padded_spec)\n",
    "    return np.array(padded_spectrograms)\n",
    "\n",
    "# Split de audio en train y test\n",
    "def train_test_split_audio(audio_dict):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID', 'PHQ-9 Score'], dtype={1: str})\n",
    "    df['labels'] = np.zeros([len(df),], dtype=int)\n",
    "    df.loc[df['PHQ-9 Score'] < 10, 'labels'] = 0\n",
    "    df.loc[df['PHQ-9 Score'] >= 10, 'labels'] = 1\n",
    "\n",
    "    labels = df.set_index('Participant_ID').to_dict()['labels']\n",
    "\n",
    "    X, Y = [], []\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        if ID in labels:\n",
    "            dep = 0 if labels[ID] == 0 else 1\n",
    "            [X.append(x) for x in data]\n",
    "            [Y.append(dep) for x in data]\n",
    "\n",
    "    X = pad_and_crop_spectrograms(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = X[..., np.newaxis]\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# Función de especificidad\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Entrenamiento y evaluación de cada arquitectura decodificada\n",
    "def train_and_evaluate_model(model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config):\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\", 'Precision', 'Recall'])\n",
    "    model.fit(X_train, Y_train, epochs=config.epochs, validation_data=(X_val, Y_val), verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    # Obtener predicciones para métricas adicionales\n",
    "    Y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = results[1]\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    specificity = specificity_score(Y_test, Y_pred)\n",
    "\n",
    "    return [results[0], accuracy, precision, recall, f1, specificity]\n",
    "\n",
    "\n",
    "# Asumimos que las funciones y clases como `build_tf_model_from_dict`, `generate_random_architecture`, \n",
    "# `encode_model_architecture`, `fixArch`, `decode_model_architecture`, y `train_and_evaluate_model` ya están definidas.\n",
    "\n",
    "\n",
    "# Función principal para generar y entrenar modelos (predefinidos y aleatorios)\n",
    "def generate_and_train_models(predefined_architectures, num_random_models=250, directory='./SM-27', target_shape=(128, 128, 1), use_kfold=True):\n",
    "    results_data = []\n",
    "    config = Config(epochs=50)\n",
    "\n",
    "    # Cargar y preprocesar datos de audio\n",
    "    print(\"Cargando y preprocesando datos de audio...\")\n",
    "    audio_dict, sample_rate = load_audio_data(directory, config.window_size, config.sample_rate)\n",
    "    audio_dict = preprocess_audio(audio_dict, sample_rate)\n",
    "    X, Y = train_test_split_audio(audio_dict)\n",
    "    X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if use_kfold:\n",
    "        kfold = KFold(n_splits=config.n_splits, shuffle=True)\n",
    "\n",
    "    # Entrenar y evaluar arquitecturas predefinidas\n",
    "    for i, architecture in enumerate(predefined_architectures):\n",
    "        print(f\"\\nEvaluando arquitectura predefinida {i + 1}/{len(predefined_architectures)}...\")\n",
    "        evaluate_and_store_model(architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, kfold, target_shape, results_data)\n",
    "\n",
    "    # Generar, entrenar y evaluar arquitecturas aleatorias\n",
    "    for i in range(num_random_models):\n",
    "        print(f\"\\nGenerando y evaluando modelo aleatorio {i + 1}/{num_random_models}...\")\n",
    "        random_architecture = generate_random_architecture()\n",
    "        encoded_architecture = encode_model_architecture(random_architecture, max_alleles=48)\n",
    "        repaired_architecture = fixArch(encoded_architecture)\n",
    "        evaluate_and_store_model(repaired_architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, kfold, target_shape, results_data)\n",
    "\n",
    "    # Guardar resultados en CSV\n",
    "    columns = [\"Encoded Architecture\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\"]\n",
    "    results_df = pd.DataFrame(results_data, columns=columns)\n",
    "    results_df.to_csv(\"./model_results_combined_50_epochs.csv\", index=False)\n",
    "    print(\"Resultados guardados en 'model_results_combined.csv'\")\n",
    "\n",
    "# Función para evaluar y almacenar los resultados de un modelo\n",
    "def evaluate_and_store_model(architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, kfold, target_shape, results_data):\n",
    "    repaired_architecture = fixArch(architecture)\n",
    "    decoded_model_dict = decode_model_architecture(repaired_architecture)\n",
    "    model_results = [repaired_architecture]\n",
    "\n",
    "    if use_kfold:\n",
    "        fold_results = []\n",
    "        for fold, (train_index, val_index) in enumerate(kfold.split(X_train_val)):\n",
    "            print(f\"Entrenando fold {fold + 1}/{config.n_splits}...\")\n",
    "            X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "            Y_train, Y_val = Y_train_val[train_index], Y_train_val[val_index]\n",
    "            tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "            fold_results.append(train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config))\n",
    "            print(f\"Fold {fold + 1} completado.\")\n",
    "\n",
    "        avg_results = np.mean(fold_results, axis=0)\n",
    "        model_results.extend(avg_results)\n",
    "\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=42)\n",
    "        tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "        single_run_results = train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config)\n",
    "        model_results.extend(single_run_results)\n",
    "        print(\"Modelo evaluado sin K-Fold Cross Validation.\")\n",
    "\n",
    "    results_data.append(model_results)\n",
    "\n",
    "# Ejecutar la generación y entrenamiento de modelos, incluyendo arquitecturas predefinidas y modelos aleatorios\n",
    "#generate_and_train_models(predefined_architectures, num_random_models=270, target_shape=(128, 128, 1), use_kfold=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "F1 = tfa.metrics.F1Score(num_classes=1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MELSPECTROGRAM: 100%|██████████| 5890/5890 [00:16<00:00, 365.25it/s]\n",
      "LABEL: 100%|██████████| 5890/5890 [00:00<00:00, 654214.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5890, 128, 128, 1), Y shape: (5890,)\n",
      "Testing model: exp2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp2:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Fold 1 results for exp2: Loss=0.702, Accuracy=0.525, Precision=0.500, Recall=0.506, F1-Score=0.503, Specificity=0.543\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Fold 2 results for exp2: Loss=0.674, Accuracy=0.580, Precision=0.557, Recall=0.562, F1-Score=0.559, Specificity=0.596\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Fold 3 results for exp2: Loss=0.655, Accuracy=0.612, Precision=0.586, Recall=0.624, F1-Score=0.604, Specificity=0.601\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 4 results for exp2: Loss=0.645, Accuracy=0.621, Precision=0.590, Recall=0.658, F1-Score=0.622, Specificity=0.586\n",
      "37/37 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp2: 100%|██████████| 1/1 [07:12<00:00, 432.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for exp2: Loss=0.638, Accuracy=0.632, Precision=0.599, Recall=0.683, F1-Score=0.638, Specificity=0.586\n",
      "Testing model: exp1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Fold 1 results for exp1: Loss=0.713, Accuracy=0.478, Precision=0.476, Recall=0.998, F1-Score=0.645, Specificity=0.008\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 2 results for exp1: Loss=0.658, Accuracy=0.617, Precision=0.574, Recall=0.748, F1-Score=0.650, Specificity=0.499\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 3 results for exp1: Loss=0.649, Accuracy=0.607, Precision=0.755, Recall=0.254, F1-Score=0.380, Specificity=0.926\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 4 results for exp1: Loss=0.664, Accuracy=0.565, Precision=0.862, Recall=0.100, F1-Score=0.179, Specificity=0.985\n",
      "37/37 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for exp1: 100%|██████████| 1/1 [14:50<00:00, 890.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for exp1: Loss=0.689, Accuracy=0.552, Precision=0.919, Recall=0.061, F1-Score=0.114, Specificity=0.995\n",
      "Testing model: CNN_LF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for CNN_LF:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Fold 1 results for CNN_LF: Loss=0.688, Accuracy=0.475, Precision=0.475, Recall=1.000, F1-Score=0.644, Specificity=0.000\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Fold 2 results for CNN_LF: Loss=0.681, Accuracy=0.483, Precision=0.478, Recall=0.991, F1-Score=0.645, Specificity=0.024\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Fold 3 results for CNN_LF: Loss=0.676, Accuracy=0.532, Precision=0.504, Recall=0.964, F1-Score=0.662, Specificity=0.142\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 4 results for CNN_LF: Loss=0.673, Accuracy=0.577, Precision=0.532, Recall=0.911, F1-Score=0.672, Specificity=0.276\n",
      "37/37 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for CNN_LF: 100%|██████████| 1/1 [17:40<00:00, 1060.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for CNN_LF: Loss=0.671, Accuracy=0.607, Precision=0.554, Recall=0.880, F1-Score=0.680, Specificity=0.360\n",
      "Testing model: SPECTRO_CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for SPECTRO_CNN:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 1 results for SPECTRO_CNN: Loss=0.627, Accuracy=0.574, Precision=0.890, Recall=0.116, F1-Score=0.206, Specificity=0.987\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 2 results for SPECTRO_CNN: Loss=0.622, Accuracy=0.646, Precision=0.866, Recall=0.301, F1-Score=0.446, Specificity=0.958\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 3 results for SPECTRO_CNN: Loss=0.618, Accuracy=0.692, Precision=0.853, Recall=0.424, F1-Score=0.566, Specificity=0.934\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 4 results for SPECTRO_CNN: Loss=0.617, Accuracy=0.690, Precision=0.823, Recall=0.442, F1-Score=0.575, Specificity=0.914\n",
      "37/37 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing architectures for SPECTRO_CNN: 100%|██████████| 1/1 [15:39<00:00, 939.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 results for SPECTRO_CNN: Loss=0.615, Accuracy=0.704, Precision=0.811, Recall=0.490, F1-Score=0.611, Specificity=0.897\n",
      "\n",
      "Summary per architecture:\n",
      "exp2 - Loss: 0.663, Accuracy: 0.594, Precision: 0.566, Recall: 0.607, F1-Score: 0.585, Specificity: 0.583\n",
      "exp1 - Loss: 0.675, Accuracy: 0.564, Precision: 0.717, Recall: 0.432, F1-Score: 0.394, Specificity: 0.683\n",
      "CNN_LF - Loss: 0.678, Accuracy: 0.535, Precision: 0.509, Recall: 0.949, F1-Score: 0.660, Specificity: 0.161\n",
      "SPECTRO_CNN - Loss: 0.620, Accuracy: 0.661, Precision: 0.849, Recall: 0.355, F1-Score: 0.481, Specificity: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAKyCAYAAAAEvm1SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8BUlEQVR4nOzdd3gUVd/G8XvTNo0khBYCMaETekdEiHSkifSiJNRHBEUpCooEUEGRqlTpKl1EERBQiiIC0oKIoRoE6UVCkwSSef/wYl/WJJBgMgvL93Ndez3smTMzv5ndHR9uzpyxGIZhCAAAAAAAADCRi6MLAAAAAAAAwKOHUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAACdnsVg0dOhQR5fxn3366acqXry43N3dFRAQ4OhyMmzo0KGyWCyOLgP/0caNG2WxWPT555/fs29UVJTCwsKyvigAAB5ShFIAAKd35MgR/e9//1PBggXl6ekpPz8/Va9eXRMmTNDff//t6PKQDvv371dUVJQKFSqk6dOn6+OPP06z7+3wx8XFRcePH0+x/PLly/Ly8pLFYlHv3r3vq54RI0boyy+/vK91HaFKlSqyWCyaMmWKo0vJcrGxsbJYLPL09NSlS5ccXY6d69eva+jQodq4cWOW7ufkyZMaOnSoYmJisnQ/AAD8V4RSAACntnLlSpUuXVqLFy9W06ZN9dFHH2nkyJF67LHHNGDAAPXp08fRJWa5v//+W4MHD3Z0Gf/Jxo0blZycrAkTJigqKkpt2rS55zpWq1ULFixI0f7FF1/853ruJ5QaPHiwQ0LQQ4cOafv27QoLC9O8efNM37/ZPvvsMwUFBUlSukYzZaXp06frwIEDtvfXr1/XsGHDTAmlhg0bRigFAHjgEUoBAJxWXFyc2rVrp9DQUP3222+aMGGCunfvrl69emnBggX67bffVLJkSUeXmSWSk5N148YNSZKnp6fc3NwcXNF/c/bsWUnK0G17jRo1SjWUmj9/vho3bpxZpd3TtWvXJElubm7y9PQ0bb+3ffbZZ8qdO7fGjBmjn376SUePHs20bd8+tgeFYRiaP3++OnTooEaNGqU7hDMMI0sCQ3d3d1mt1kzfrqPcuHFDycnJji4DAOBECKUAAE5r1KhRunr1qmbOnKm8efOmWF64cGG7kVK3bt3S22+/rUKFCslqtSosLExvvPGGEhIS7NYLCwtTkyZNtHHjRlWqVEleXl4qXbq0bfTDF198odKlS8vT01MVK1bU7t277daPioqSr6+vfv/9dzVo0EA+Pj4KDg7W8OHDZRiGXd/Ro0friSeeUI4cOeTl5aWKFSumOvrj9q1o8+bNU8mSJWW1WrV69WrbsjvnlLpy5YpeeeUVhYWFyWq1Knfu3KpXr5527dplt80lS5aoYsWK8vLyUs6cOfXcc8/pxIkTqR7LiRMn1Lx5c/n6+ipXrlzq37+/kpKS0vhk7E2ePNlWc3BwsHr16mV321VYWJiio6MlSbly5Ur3HFkdOnRQTEyM9u/fb2s7ffq01q9frw4dOqS6TkJCgqKjo1W4cGFZrVaFhITotddes/sOWCwWXbt2TXPnzpXFYpHFYlFUVJSk/7918LffflOHDh2UPXt2Pfnkk3bL/u2zzz5TlSpV5O3trezZs6tmzZpau3atbfmOHTvUoEED5cyZU15eXipQoIC6dOlyz+O/bf78+WrVqpWaNGkif39/zZ8/P9V+27ZtU6NGjZQ9e3b5+PioTJkymjBhgm357c/6yJEjatSokbJly6aOHTtK+iec6tevn0JCQmS1WlWsWDGNHj06xff522+/1ZNPPqmAgAD5+vqqWLFieuONN+z6fPTRRypZsqTtfFSqVCnNmv9t8+bNOnr0qNq1a6d27drphx9+0J9//pmi3+3f8Jo1a2y/4WnTpkmSLl26pFdffdX2+8ifP786deqk8+fP220jOTlZ7777rvLnzy9PT0/VqVNHhw8ftutz55xSR48eVa5cuSRJw4YNs3137vwu79+/X61atVJgYKA8PT1VqVIlLV++PEX9d6tx48aNqly5siSpc+fOtv3MmTPHduy3v693euqpp/TUU0/Z3t+eO2vhwoUaPHiw8uXLJ29vb12+fFnSP9+Xhg0byt/fX97e3oqIiNDmzZvttpneaw0A4NH1cP+zKQAAd/H111+rYMGCeuKJJ9LVv1u3bpo7d65atWqlfv36adu2bRo5cqRiY2O1bNkyu76HDx9Whw4d9L///U/PPfecRo8eraZNm2rq1Kl644039OKLL0qSRo4cqTZt2ujAgQNycfn/fwtKSkpSw4YN9fjjj2vUqFFavXq1oqOjdevWLQ0fPtzWb8KECWrWrJk6duyoxMRELVy4UK1bt9aKFStSjPZZv369Fi9erN69eytnzpxpTrD8wgsv6PPPP1fv3r1VokQJXbhwQT/++KNiY2NVoUIFSdKcOXPUuXNnVa5cWSNHjtSZM2c0YcIEbd68Wbt377YbsZSUlKQGDRqoatWqGj16tL777juNGTNGhQoVUs+ePe96zocOHaphw4apbt266tmzpw4cOKApU6Zo+/bt2rx5s9zd3TV+/Hh98sknWrZsmaZMmSJfX1+VKVPmnp9nzZo1lT9/fs2fP992ThctWiRfX99UR0olJyerWbNm+vHHH9WjRw+Fh4dr7969GjdunA4ePGi7Xe/TTz9Vt27dVKVKFfXo0UOSVKhQIbtttW7dWkWKFNGIESNSBDN3GjZsmIYOHaonnnhCw4cPl4eHh7Zt26b169erfv36Onv2rOrXr69cuXJp4MCBCggI0NGjR9N9C+K2bdt0+PBhzZ49Wx4eHmrRooXmzZuXIgj69ttv1aRJE+XNm1d9+vRRUFCQYmNjtWLFihTBbYMGDfTkk09q9OjR8vb2lmEYatasmTZs2KCuXbuqXLlyWrNmjQYMGKATJ05o3LhxkqR9+/apSZMmKlOmjIYPHy6r1arDhw/bBRnTp0/Xyy+/rFatWqlPnz66ceOGfvnlF23bti3NIPFO8+bNU6FChVS5cmWVKlVK3t7eWrBggQYMGJCi74EDB9S+fXv973//U/fu3VWsWDFdvXpVNWrUUGxsrLp06aIKFSro/PnzWr58uf7880/lzJnTtv57770nFxcX9e/fX/Hx8Ro1apQ6duyobdu2pVpbrly5NGXKFPXs2VPPPvusWrRoIUm27/K+fftUvXp15cuXTwMHDpSPj48WL16s5s2ba+nSpXr22Wcl6Z41hoeHa/jw4RoyZIh69OihGjVqSFK6r4P/9vbbb8vDw0P9+/dXQkKCPDw8tH79ej399NOqWLGioqOj5eLiotmzZ6t27dratGmTqlSpIil91xoAwCPOAADACcXHxxuSjGeeeSZd/WNiYgxJRrdu3eza+/fvb0gy1q9fb2sLDQ01JBk//fSTrW3NmjWGJMPLy8v4448/bO3Tpk0zJBkbNmywtUVGRhqSjJdeesnWlpycbDRu3Njw8PAwzp07Z2u/fv26XT2JiYlGqVKljNq1a9u1SzJcXFyMffv2pTg2SUZ0dLTtvb+/v9GrV680z0ViYqKRO3duo1SpUsbff/9ta1+xYoUhyRgyZEiKYxk+fLjdNsqXL29UrFgxzX0YhmGcPXvW8PDwMOrXr28kJSXZ2idOnGhIMmbNmmVri46ONiTZnZu03Nm3f//+RuHChW3LKleubHTu3NkwjH/Oy53n4dNPPzVcXFyMTZs22W1v6tSphiRj8+bNtjYfHx8jMjIyzX23b98+zWW3HTp0yHBxcTGeffZZu+M3jH++D4ZhGMuWLTMkGdu3b7/ncaemd+/eRkhIiG17a9euNSQZu3fvtvW5deuWUaBAASM0NNT466+/Uq3DMP7/sx44cKBdny+//NKQZLzzzjt27a1atTIsFotx+PBhwzAMY9y4cff8DJ955hmjZMmS93OoRmJiopEjRw7jzTfftLV16NDBKFu2bIq+t3/Dq1evtmsfMmSIIcn44osvUqxz+1xs2LDBkGSEh4cbCQkJtuUTJkwwJBl79+61tUVGRhqhoaG29+fOnUvxe7ytTp06RunSpY0bN27Y7fOJJ54wihQpkqEat2/fbkgyZs+eneqxp/bdjYiIMCIiImzvbx9nwYIF7a5DycnJRpEiRYwGDRrYfT+uX79uFChQwKhXr56t7V7XGgAAuH0PAOCUbt9iki1btnT1X7VqlSSpb9++du39+vWT9M+E6XcqUaKEqlWrZntftWpVSVLt2rX12GOPpWj//fffU+zzzie/3b79LjExUd99952t3cvLy/bnv/76S/Hx8apRo0aqt79ERESoRIkS9zjSf+Zl2rZtm06ePJnq8h07dujs2bN68cUX7eZAaty4sYoXL57iXEj/jIi4U40aNVI95jt99913SkxM1CuvvGI3iqx79+7y8/NLdT8Z1aFDBx0+fFjbt2+3/W9aI26WLFmi8PBwFS9eXOfPn7e9ateuLUnasGFDuvf77/ORmi+//FLJyckaMmSI3fFLst3md3tE2ooVK3Tz5s1071/6Z1TTokWL1LZtW9v2ateurdy5c9vNtbR7927FxcXplVdeSTFnV2q3G/579NuqVavk6uqql19+2a69X79+MgxD33zzjd2xfPXVV2nOSxQQEKA///xT27dvz9CxStI333yjCxcuqH379ra29u3ba8+ePdq3b1+K/gUKFFCDBg3s2pYuXaqyZcvaRiXd6d/nonPnzvLw8LC9vz0i6V7f+9RcvHhR69evV5s2bXTlyhXbd+/ChQtq0KCBDh06ZLt1NiM1ZobIyEi761BMTIwOHTqkDh066MKFC7Zar127pjp16uiHH36wfb73utYAAEAoBQBwSn5+fpL+mdMkPf744w+5uLiocOHCdu1BQUEKCAjQH3/8Ydd+Z/AkSf7+/pKkkJCQVNv/+usvu3YXFxcVLFjQrq1o0aKSZDcR9YoVK/T444/L09NTgYGBtluA4uPjUxxDgQIF7nWYkv6Za+vXX39VSEiIqlSpoqFDh9r9Rfr2sRYrVizFusWLF09xLjw9PW1z5dyWPXv2FMf8b2ntx8PDQwULFkyxn/tRvnx5FS9eXPPnz9e8efMUFBRkC5n+7dChQ9q3b59y5cpl97r9udyebD090vNZHDlyRC4uLncNEiMiItSyZUsNGzZMOXPm1DPPPKPZs2enmOcsNWvXrtW5c+dUpUoVHT58WIcPH1ZcXJxq1aqlBQsW2IKDI0eOSJJKlSp1z226ubkpf/78dm1//PGHgoODUwTA4eHhtuWS1LZtW1WvXl3dunVTnjx51K5dOy1evNguoHr99dfl6+urKlWqqEiRIurVq1eKeYrS8tlnn6lAgQK22wIPHz6sQoUKydvbO9UJz1P7jI4cOZKu8yClvAZkz55dUsrfenocPnxYhmHorbfeSvH9uz2f2u3vX0ZqzAz/Pk+HDh2S9E9Y9e9aZ8yYoYSEBNv16V7XGgAAmFMKAOCU/Pz8FBwcrF9//TVD66V3pIGrq2uG2o27zCuUlk2bNqlZs2aqWbOmJk+erLx588rd3V2zZ89OdeLnO0cz3E2bNm1Uo0YNLVu2TGvXrtUHH3yg999/X1988YWefvrpDNeZ1jE/KDp06KApU6YoW7Zsatu2bYpRSbclJyerdOnSGjt2bKrL/x043k16P4t7sVgs+vzzz7V161Z9/fXXWrNmjbp06aIxY8Zo69at8vX1TXPd20FMmzZtUl3+/fffq1atWhmqx2q1pnn+7sXLy0s//PCDNmzYoJUrV2r16tVatGiRateurbVr18rV1VXh4eE6cOCAVqxYodWrV2vp0qWaPHmyhgwZomHDhqW57cuXL+vrr7/WjRs3VKRIkRTL58+fr3fffdfu9/1fP6PM/K3fDub69++fYvTWbf8OzO9XWte4pKSkVI/p3+fpdq0ffPCBypUrl+q2bn8vM/taAwBwPoRSAACn1aRJE3388cfasmWL3a12qQkNDVVycrIOHTpkG+EhSWfOnNGlS5cUGhqaqbUlJyfr999/t43CkaSDBw9Kkm2C8qVLl8rT01Nr1qyxe6z87Nmz//P+8+bNqxdffFEvvviizp49qwoVKujdd9/V008/bTvWAwcOpBhVdODAgUw7F3fu585RY4mJiYqLi1PdunUzZT8dOnTQkCFDdOrUKX366adp9itUqJD27NmjOnXq3DOczIzbpAoVKqTk5GT99ttvaf7l/rbHH39cjz/+uN59913Nnz9fHTt21MKFC9WtW7dU+1+7dk1fffWV2rZtq1atWqVY/vLLL2vevHmqVauWbZL2X3/99b7OeWhoqL777jtduXLFbrTU7ace3vl9cXFxUZ06dVSnTh2NHTtWI0aM0JtvvqkNGzbY9u3j46O2bduqbdu2SkxMVIsWLfTuu+9q0KBBdreT3umLL77QjRs3NGXKFLvJyKV/vl+DBw/W5s2bbU9CTEuhQoUyHGRnRFrfm9vff3d393t+Bump8W7fz+zZs9s93fK2P/74I8XozbT2L/0T/Kfn+3K3aw0AANy+BwBwWq+99pp8fHzUrVs3nTlzJsXyI0eO2B5536hRI0nS+PHj7frcHjWT2tPa/quJEyfa/mwYhiZOnCh3d3fVqVNH0j8jMSwWi5KSkmz9jh49ansK3P1ISkpKcetf7ty5FRwcbLslrFKlSsqdO7emTp1qd5vYN998o9jY2Ew7F3Xr1pWHh4c+/PBDu9ElM2fOVHx8fKbtp1ChQho/frxGjhxpeypYatq0aaMTJ05o+vTpKZb9/fffunbtmu29j49Pqn+xz4jmzZvLxcVFw4cPTzHH0u3z8ddff6UYeXM7wLrbLXzLli3TtWvX1KtXL7Vq1SrFq0mTJlq6dKkSEhJUoUIFFShQQOPHj09xTOkZ9dOoUSMlJSXZfZ8lady4cbJYLLbw4eLFiynW/fexXLhwwW65h4eHSpQoIcMw7jqn1meffaaCBQvqhRdeSHGs/fv3l6+vb6q38P1by5YttWfPnhRP25TubwTUv3l7e0tSivOcO3duPfXUU5o2bZpOnTqVYr1z585lqEYfH59U9yP983vYunWrEhMTbW0rVqzQ8ePH03UMFStWVKFChTR69GhdvXo1zVrTc60BAICRUgAAp1WoUCHNnz9fbdu2VXh4uDp16qRSpUopMTFRP/30k5YsWaKoqChJUtmyZRUZGamPP/5Yly5dUkREhH7++WfNnTtXzZs3z/BtTvfi6emp1atXKzIyUlWrVtU333yjlStX6o033rDNz9S4cWONHTtWDRs2VIcOHXT27FlNmjRJhQsX1i+//HJf+71y5Yry58+vVq1aqWzZsvL19dV3332n7du3a8yYMZL+Ga3x/vvvq3PnzoqIiFD79u115swZTZgwQWFhYXr11Vcz5RzkypVLgwYN0rBhw9SwYUM1a9ZMBw4c0OTJk1W5cmU999xzmbIfSerTp889+zz//PNavHixXnjhBW3YsEHVq1dXUlKS9u/fr8WLF2vNmjWqVKmSpH/+Yv7dd99p7NixCg4OVoECBWyT2qdX4cKF9eabb+rtt99WjRo11KJFC1mtVm3fvl3BwcEaOXKk5s6dq8mTJ+vZZ59VoUKFdOXKFU2fPl1+fn62IDU18+bNU44cOfTEE0+kurxZs2aaPn26Vq5cqRYtWmjKlClq2rSpypUrp86dOytv3rzav3+/9u3bpzVr1tz1OJo2bapatWrpzTff1NGjR1W2bFmtXbtWX331lV555RXbyJrhw4frhx9+UOPGjRUaGqqzZ89q8uTJyp8/v20EU/369RUUFKTq1asrT548io2N1cSJE9W4ceM0H1pw8uRJbdiwIcVE67dZrVY1aNBAS5Ys0Ycffih3d/c0j2XAgAH6/PPP1bp1a3Xp0kUVK1bUxYsXtXz5ck2dOlVly5a967m4Fy8vL5UoUUKLFi1S0aJFFRgYqFKlSqlUqVKaNGmSnnzySZUuXVrdu3dXwYIFdebMGW3ZskV//vmn9uzZk+4aCxUqpICAAE2dOlXZsmWTj4+PqlatqgIFCqhbt276/PPP1bBhQ7Vp00ZHjhzRZ599Zvuc7sXFxUUzZszQ008/rZIlS6pz587Kly+fTpw4oQ0bNsjPz09ff/11uq41AAAo9YfyAQDgPA4ePGh0797dCAsLMzw8PIxs2bIZ1atXNz766CO7x6/fvHnTGDZsmFGgQAHD3d3dCAkJMQYNGmTXxzD+eaR648aNU+xHUorHn8fFxRmSjA8++MDWFhkZafj4+BhHjhwx6tevb3h7ext58uQxoqOjjaSkJLv1Z86caRQpUsSwWq1G8eLFjdmzZxvR0dHGv/8Tntq+71x2+xH0CQkJxoABA4yyZcsa2bJlM3x8fIyyZcsakydPTrHeokWLjPLlyxtWq9UIDAw0OnbsaPz55592fW4fy7+lVmNaJk6caBQvXtxwd3c38uTJY/Ts2dP466+/Ut3euXPn7rm99PZN7ZwlJiYa77//vlGyZEnDarUa2bNnNypWrGgMGzbMiI+Pt/Xbv3+/UbNmTcPLy8uQZERGRt5z32mdk1mzZtnOc/bs2Y2IiAjj22+/NQzDMHbt2mW0b9/eeOyxxwyr1Wrkzp3baNKkibFjx440j+vMmTOGm5ub8fzzz6fZ5/r164a3t7fx7LPP2tp+/PFHo169erbvRZkyZYyPPvrItjytz9owDOPKlSvGq6++agQHBxvu7u5GkSJFjA8++MBITk629Vm3bp3xzDPPGMHBwYaHh4cRHBxstG/f3jh48KCtz7Rp04yaNWsaOXLkMKxWq1GoUCFjwIABduf+38aMGWNIMtatW5dmnzlz5hiSjK+++sowjLR/w4ZhGBcuXDB69+5t5MuXz/Dw8DDy589vREZGGufPnzcMwzA2bNhgSDKWLFlit97t3/rs2bPtzlloaKhdv59++smoWLGi4eHhYffbNAzDOHLkiNGpUycjKCjIcHd3N/Lly2c0adLE+PzzzzNUo2EYxldffWWUKFHCcHNzS1HXmDFjjHz58hlWq9WoXr26sWPHDiMiIsKIiIiw9UnrOG/bvXu30aJFC9tnFRoaarRp08b2OWTkWgMAeHRZDCMTxiIDAIB0i4qK0ueff57qrS8AAADAo4I5pQAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApmNOKQAAAAAAAJiOkVIAAAAAAAAwHaEUAAAAAAAATOfm6ALMlpycrJMnTypbtmyyWCyOLgcAAAAAAMCpGIahK1euKDg4WC4uaY+HeuRCqZMnTyokJMTRZQAAAAAAADi148ePK3/+/Gkuf+RCqWzZskn658T4+fk5uBoAAAAAAADncvnyZYWEhNgymLQ8cqHU7Vv2/Pz8CKUAAAAAAACyyL2mTWKicwAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6R65OaXSKykpSTdv3nR0Gchk7u7ucnV1dXQZAAAAAAA88gil/sUwDJ0+fVqXLl1ydCnIIgEBAQoKCrrnhGsAAAAAACDrEEr9y+1AKnfu3PL29ia4cCKGYej69es6e/asJClv3rwOrggAAAAAgEcXodQdkpKSbIFUjhw5HF0OsoCXl5ck6ezZs8qdOze38gEAAAAA4CBMdH6H23NIeXt7O7gSZKXbny9zhgEAAAAA4DiEUqnglj3nxucLAAAAAIDjEUoBAAAAAADAdIRSAAAAAAAAMB0TnadT2MCVpu7v6HuNM9Q/KipKly5d0pdffpk1BQEAAAAAAGQiRkoBAAAAAADAdIRSj4Dvv/9eVapUkdVqVd68eTVw4EDdunXLtvzzzz9X6dKl5eXlpRw5cqhu3bq6du2aJGnjxo2qUqWKfHx8FBAQoOrVq+uPP/5w1KEAAAAAAAAnQSjl5E6cOKFGjRqpcuXK2rNnj6ZMmaKZM2fqnXfekSSdOnVK7du3V5cuXRQbG6uNGzeqRYsWMgxDt27dUvPmzRUREaFffvlFW7ZsUY8ePXh6HQAAAAAA+M+YU8rJTZ48WSEhIZo4caIsFouKFy+ukydP6vXXX9eQIUN06tQp3bp1Sy1atFBoaKgkqXTp0pKkixcvKj4+Xk2aNFGhQoUkSeHh4Q47FgAAAAAA4DwYKeXkYmNjVa1aNbvRTdWrV9fVq1f1559/qmzZsqpTp45Kly6t1q1ba/r06frrr78kSYGBgYqKilKDBg3UtGlTTZgwQadOnXLUoQAAAAAAACdCKPWIc3V11bfffqtvvvlGJUqU0EcffaRixYopLi5OkjR79mxt2bJFTzzxhBYtWqSiRYtq69atDq4aAAAAAAA87AilnFx4eLi2bNkiwzBsbZs3b1a2bNmUP39+SZLFYlH16tU1bNgw7d69Wx4eHlq2bJmtf/ny5TVo0CD99NNPKlWqlObPn2/6cQAAAAAAAOfCnFJOJD4+XjExMXZtPXr00Pjx4/XSSy+pd+/eOnDggKKjo9W3b1+5uLho27ZtWrdunerXr6/cuXNr27ZtOnfunMLDwxUXF6ePP/5YzZo1U3BwsA4cOKBDhw6pU6dOjjlAAAAAAADgNAilnMjGjRtVvnx5u7auXbtq1apVGjBggMqWLavAwEB17dpVgwcPliT5+fnphx9+0Pjx43X58mWFhoZqzJgxevrpp3XmzBnt379fc+fO1YULF5Q3b1716tVL//vf/xxxeAAAAAAAwIlYjDvv63oEXL58Wf7+/oqPj5efn5/dshs3biguLk4FChSQp6engypEVuNzBgAAAAAg69wte7kTc0oBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADT8fQ9AAAA4CERWzzc0SWkKXx/rKNLAAA8ZBgpBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANPx9L30Gupv8v7i72u1LVu26Mknn1TDhg21cuXKTC4KAAAAAAAgcxBKOZmZM2fqpZde0syZM3Xy5EkFBwc7pI7ExER5eHg4ZN8AAAAAAKRlTNsmji4hTf0WrXB0Cabi9j0ncvXqVS1atEg9e/ZU48aNNWfOHLvlX3/9tSpXrixPT0/lzJlTzz77rG1ZQkKCXn/9dYWEhMhqtapw4cKaOXOmJGnOnDkKCAiw29aXX34pi8Viez906FCVK1dOM2bMUIECBeTp6SlJWr16tZ588kkFBAQoR44catKkiY4cOWK3rT///FPt27dXYGCgfHx8VKlSJW3btk1Hjx6Vi4uLduzYYdd//PjxCg0NVXJy8n89ZQAAAAAAwEEIpZzI4sWLVbx4cRUrVkzPPfecZs2aJcMwJEkrV67Us88+q0aNGmn37t1at26dqlSpYlu3U6dOWrBggT788EPFxsZq2rRp8vX1zdD+Dx8+rKVLl+qLL75QTEyMJOnatWvq27evduzYoXXr1snFxUXPPvusLVC6evWqIiIidOLECS1fvlx79uzRa6+9puTkZIWFhalu3bqaPXu23X5mz56tqKgoubjw9QUAAAAA4GHF7XtOZObMmXruueckSQ0bNlR8fLy+//57PfXUU3r33XfVrl07DRs2zNa/bNmykqSDBw9q8eLF+vbbb1W3bl1JUsGCBTO8/8TERH3yySfKlSuXra1ly5Z2fWbNmqVcuXLpt99+U6lSpTR//nydO3dO27dvV2BgoCSpcOHCtv7dunXTCy+8oLFjx8pqtWrXrl3au3evvvrqqwzXBwAAAAAAHhwMNXESBw4c0M8//6z27dtLktzc3NS2bVvbLXgxMTGqU6dOquvGxMTI1dVVERER/6mG0NBQu0BKkg4dOqT27durYMGC8vPzU1hYmCTp2LFjtn2XL1/eFkj9W/PmzeXq6qply5ZJ+udWwlq1atm2AwAAAAAAHk6MlHISM2fO1K1bt+wmNjcMQ1arVRMnTpSXl1ea695tmSS5uLjYbgO87ebNmyn6+fj4pGhr2rSpQkNDNX36dAUHBys5OVmlSpVSYmJiuvbt4eGhTp06afbs2WrRooXmz5+vCRMm3HUdAAAAAADw4GOklBO4deuWPvnkE40ZM0YxMTG21549exQcHKwFCxaoTJkyWrduXarrly5dWsnJyfr+++9TXZ4rVy5duXJF165ds7XdnjPqbi5cuKADBw5o8ODBqlOnjsLDw/XXX3/Z9SlTpoxiYmJ08eLFNLfTrVs3fffdd5o8ebJu3bqlFi1a3HPfAAAAAADgwcZIKSewYsUK/fXXX+ratav8/f3tlrVs2VIzZ87UBx98oDp16qhQoUJq166dbt26pVWrVun1119XWFiYIiMj1aVLF3344YcqW7as/vjjD509e1Zt2rRR1apV5e3trTfeeEMvv/yytm3bluLJfqnJnj27cuTIoY8//lh58+bVsWPHNHDgQLs+7du314gRI9S8eXONHDlSefPm1e7duxUcHKxq1apJksLDw/X444/r9ddfV5cuXe45ugoAAAAAADz4GCnlBGbOnKm6deumCKSkf0KpHTt2KDAwUEuWLNHy5ctVrlw51a5dWz///LOt35QpU9SqVSu9+OKLKl68uLp3724bGRUYGKjPPvtMq1atUunSpbVgwQINHTr0nnW5uLho4cKF2rlzp0qVKqVXX31VH3zwgV0fDw8PrV27Vrlz51ajRo1UunRpvffee3J1dbXr17VrVyUmJqpLly73cYYAAAAAAMCDxmL8e7IgJ3f58mX5+/srPj5efn5+dstu3LihuLg4FShQQJ6eng6qEKl5++23tWTJEv3yyy//eVt8zgAA4GEVWzzc0SWkKXx/rKNLAIB0GdO2iaNLSFO/RSscXUKmuFv2cidGSuGBdvXqVf3666+aOHGiXnrpJUeXAwAAAAAAMgmhFB5ovXv3VsWKFfXUU09x6x4AAAAAAE6Eic7xQJszZ066JlUHAAAAAAAPF0ZKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRTum8Vi0ZdffpnpfQEAAAAAgPNzc3QBD4vSc0ubur+9kXsz1D8qKkpz586VJLm7u+uxxx5Tp06d9MYbb8jNLWs+5lOnTil79uyZ3hcAAAAAADg/Qikn0rBhQ82ePVsJCQlatWqVevXqJXd3dw0aNMiuX2Jiojw8PP7z/oKCgrKkLwAAAAAAcH7cvudErFargoKCFBoaqp49e6pu3bpavny5oqKi1Lx5c7377rsKDg5WsWLFJEnHjx9XmzZtFBAQoMDAQD3zzDM6evSo3TZnzZqlkiVLymq1Km/evOrdu7dt2Z235CUmJqp3797KmzevPD09FRoaqpEjR6baV5L27t2r2rVry8vLSzly5FCPHj109epV2/LbNY8ePVp58+ZVjhw51KtXL928eTPzTxwAAAAAADAdoZQT8/LyUmJioiRp3bp1OnDggL799lutWLFCN2/eVIMGDZQtWzZt2rRJmzdvlq+vrxo2bGhbZ8qUKerVq5d69OihvXv3avny5SpcuHCq+/rwww+1fPlyLV68WAcOHNC8efMUFhaWat9r166pQYMGyp49u7Zv364lS5bou+++swu8JGnDhg06cuSINmzYoLlz52rOnDmaM2dOpp0fAAAAAADgONy+54QMw9C6deu0Zs0avfTSSzp37px8fHw0Y8YM2217n332mZKTkzVjxgxZLBZJ0uzZsxUQEKCNGzeqfv36euedd9SvXz/16dPHtu3KlSunus9jx46pSJEievLJJ2WxWBQaGppmffPnz9eNGzf0ySefyMfHR5I0ceJENW3aVO+//77y5MkjScqePbsmTpwoV1dXFS9eXI0bN9a6devUvXv3TDlPAAAAAADAcRgp5URWrFghX19feXp66umnn1bbtm01dOhQSVLp0qXt5pHas2ePDh8+rGzZssnX11e+vr4KDAzUjRs3dOTIEZ09e1YnT55UnTp10rXvqKgoxcTEqFixYnr55Ze1du3aNPvGxsaqbNmytkBKkqpXr67k5GQdOHDA1layZEm5urra3ufNm1dnz55N7+kAAAAAAAAPMEZKOZFatWppypQp8vDwUHBwsN1T9+4MgCTp6tWrqlixoubNm5diO7ly5ZKLS8byygoVKiguLk7ffPONvvvuO7Vp00Z169bV559/fn8Ho3+eIngni8Wi5OTk+94eAAAAAAB4cBBKOREfH58053z6twoVKmjRokXKnTu3/Pz8Uu0TFhamdevWqVatWunapp+fn9q2bau2bduqVatWatiwoS5evKjAwEC7fuHh4ZozZ46uXbtmC8s2b94sFxcX2yTsAAAAAADAuXH73iOqY8eOypkzp5555hlt2rRJcXFx2rhxo15++WX9+eefkqShQ4dqzJgx+vDDD3Xo0CHt2rVLH330UarbGzt2rBYsWKD9+/fr4MGDWrJkiYKCghQQEJDqvj09PRUZGalff/1VGzZs0EsvvaTnn3/eNp8UAAAAAABwboRSjyhvb2/98MMPeuyxx9SiRQuFh4era9euunHjhm3kVGRkpMaPH6/JkyerZMmSatKkiQ4dOpTq9rJly6ZRo0apUqVKqly5so4ePapVq1alehugt7e31qxZo4sXL6py5cpq1aqV6tSpo4kTJ2bpMQMAAAAAgAeHxTAMw9FFmOny5cvy9/dXfHx8itvWbty4obi4OBUoUECenp4OqhBZjc8ZAAA8rGKLhzu6hDSF7491dAkAkC5j2jZxdAlp6rdohaNLyBR3y17uxEgpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCpnGYrHoyy+/lCQdPXpUFotFMTExDq0JAAAAAAA8mNwcXcDDIrZ4uKn7C98fm6H+UVFRmjt3riTJzc1N+fPnV+vWrTV8+HB5enpmRYkAAAAAAAD3jVDKiTRs2FCzZ8/WzZs3tXPnTkVGRspisej99993dGkAAAAAAAB2uH3PiVitVgUFBSkkJETNmzdX3bp19e2330qSkpOTNXLkSBUoUEBeXl4qW7asPv/8c7v19+3bpyZNmsjPz0/ZsmVTjRo1dOTIEUnS9u3bVa9ePeXMmVP+/v6KiIjQrl27TD9GAAAAAADgHAilnNSvv/6qn376SR4eHpKkkSNH6pNPPtHUqVO1b98+vfrqq3ruuef0/fffS5JOnDihmjVrymq1av369dq5c6e6dOmiW7duSZKuXLmiyMhI/fjjj9q6dauKFCmiRo0a6cqVKw47RgAAAAAA8PDi9j0nsmLFCvn6+urWrVtKSEiQi4uLJk6cqISEBI0YMULfffedqlWrJkkqWLCgfvzxR02bNk0RERGaNGmS/P39tXDhQrm7u0uSihYtatt27dq17fb18ccfKyAgQN9//72aNGli3kECAAAAAACnQCjlRGrVqqUpU6bo2rVrGjdunNzc3NSyZUvt27dP169fV7169ez6JyYmqnz58pKkmJgY1ahRwxZI/duZM2c0ePBgbdy4UWfPnlVSUpKuX7+uY8eOZflxAQAAAAAA50Mo5UR8fHxUuHBhSdKsWbNUtmxZzZw5U6VKlZIkrVy5Uvny5bNbx2q1SpK8vLzuuu3IyEhduHBBEyZMUGhoqKxWq6pVq6bExMQsOBIAAAAAAODsCKWclIuLi9544w317dtXBw8elNVq1bFjxxQREZFq/zJlymju3Lm6efNmqqOlNm/erMmTJ6tRo0aSpOPHj+v8+fNZegwAAAAAAMB5MdG5E2vdurVcXV01bdo09e/fX6+++qrmzp2rI0eOaNeuXfroo480d+5cSVLv3r11+fJltWvXTjt27NChQ4f06aef6sCBA5KkIkWK6NNPP1VsbKy2bdumjh073nN0FQAAAAAAQFoYKeXE3Nzc1Lt3b40aNUpxcXHKlSuXRo4cqd9//10BAQGqUKGC3njjDUlSjhw5tH79eg0YMEARERFydXVVuXLlVL16dUnSzJkz1aNHD1WoUEEhISEaMWKE+vfv78jDAwAAAAAADzGLYRiGo4sw0+XLl+Xv76/4+Hj5+fnZLbtx44bi4uJUoEABeXp6OqhCZDU+ZwAA8LCKLR7u6BLSFL4/1tElAEC6jGn74D5Bvt+iFY4uIVPcLXu5E7fvAQAAAAAAwHSEUgAAAAAAADAdc0oBAAAAAJCG0nNLO7qENO2N3OvoEoD/hJFSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTuTm6gIfFpBfWm7q/XlNrZ6h/VFSU5s6dm6L90KFDOnnypD744APt3LlTp06d0rJly9S8efN7bnPPnj166623tHXrVl2+fFlBQUGqWrWqPvroI+XOnTtD9QEAAAAAANyJkVJOpGHDhjp16pTdq0CBArp27ZrKli2rSZMmpXtb586dU506dRQYGKg1a9YoNjZWs2fPVnBwsK5du5Zlx3Dz5s0s2zYAAAAAAHhwEEo5EavVqqCgILuXq6urnn76ab3zzjt69tln072tzZs3Kz4+XjNmzFD58uVVoEAB1apVS+PGjVOBAgVs/fbt26cmTZrIz89P2bJlU40aNXTkyBFJUnJysoYPH678+fPLarWqXLlyWr16tW3do0ePymKxaNGiRYqIiJCnp6fmzZsnSZoxY4bCw8Pl6emp4sWLa/LkyZl0lgAAAAAAwIOA2/eQqqCgIN26dUvLli1Tq1atZLFYUvQ5ceKEatasqaeeekrr16+Xn5+fNm/erFu3bkmSJkyYoDFjxmjatGkqX768Zs2apWbNmmnfvn0qUqSIbTsDBw7UmDFjVL58eVswNWTIEE2cOFHly5fX7t271b17d/n4+CgyMtK0cwAAAAAAALIOoZQTWbFihXx9fW3vn376aS1ZsuS+tvX444/rjTfeUIcOHfTCCy+oSpUqql27tjp16qQ8efJIkiZNmiR/f38tXLhQ7u7ukqSiRYvatjF69Gi9/vrrateunSTp/fff14YNGzR+/Hi7WwlfeeUVtWjRwvY+OjpaY8aMsbUVKFBAv/32m6ZNm0YoBQAAAACAk+D2PSdSq1YtxcTE2F4ffvhhutYbMWKEfH19ba9jx45Jkt59912dPn1aU6dOVcmSJTV16lQVL15ce/fulSTFxMSoRo0atkDqTpcvX9bJkydVvXp1u/bq1asrNjbWrq1SpUq2P1+7dk1HjhxR165d7Wp65513bLcFAgAAAACAhx8jpZyIj4+PChcunOH1XnjhBbVp08b2Pjg42PbnHDlyqHXr1mrdurVGjBih8uXLa/To0Zo7d668vLwyre7brl69KkmaPn26qlatatfP1dU1U/YHAAAAAAAcj1AKCgwMVGBg4D37eXh4qFChQran75UpU0Zz587VzZs3U4yW8vPzU3BwsDZv3qyIiAhb++bNm1WlSpU095EnTx4FBwfr999/V8eOHe/ziAAAAAAAwIOOUOoRcPXqVR0+fNj2Pi4uTjExMQoMDNRjjz2W6jorVqzQwoUL1a5dOxUtWlSGYejrr7/WqlWrNHv2bElS79699dFHH6ldu3YaNGiQ/P39tXXrVlWpUkXFihXTgAEDFB0drUKFCqlcuXKaPXu2YmJibE/YS8uwYcP08ssvy9/fXw0bNlRCQoJ27Nihv/76S3379s28EwMAAAAAAByGUOoRsGPHDtWqVcv2/nawExkZqTlz5qS6TokSJeTt7a1+/frp+PHjslqtKlKkiGbMmKHnn39e0j+39q1fv14DBgxQRESEXF1dVa5cOds8Ui+//LLi4+PVr18/nT17ViVKlNDy5cvtnryXmm7dusnb21sffPCBBgwYIB8fH5UuXVqvvPLKfz8ZAAAAAADggWAxDMNwdBFmunz5svz9/RUfHy8/Pz+7ZTdu3FBcXJwKFCggT09PB1WIrMbnDAAAHlaxxcMdXUKawvfH3rsT8BAqPbe0o0tI097IvY4u4aE0pm0TR5eQpn6LVji6hExxt+zlTjx9DwAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpHB5KTZo0SWFhYfL09FTVqlX1888/37X/+PHjVaxYMXl5eSkkJESvvvqqbty4YVK1AAAAAAAAyAwODaUWLVqkvn37Kjo6Wrt27VLZsmXVoEEDnT17NtX+8+fP18CBAxUdHa3Y2FjNnDlTixYt0htvvGFy5QAAAAAAAPgvHBpKjR07Vt27d1fnzp1VokQJTZ06Vd7e3po1a1aq/X/66SdVr15dHTp0UFhYmOrXr6/27dvfc3QVAAAAAAAAHiwOC6USExO1c+dO1a1b9/+LcXFR3bp1tWXLllTXeeKJJ7Rz505bCPX7779r1apVatSokSk1494sFou+/PJL2/v9+/fr8ccfl6enp8qVK6ejR4/KYrEoJiYmXduLiopS8+bNs6RWAAAAAADgOG6O2vH58+eVlJSkPHny2LXnyZNH+/fvT3WdDh066Pz583ryySdlGIZu3bqlF1544a637yUkJCghIcH2/vLly/dV75i2Te5rvfvVb9GKDK9z7tw5DRkyRCtXrtSZM2eUPXt2lS1bVkOGDFH16tWzoMqUTp06pezZs9veR0dHy8fHRwcOHJCvr68CAgJ06tQp5cyZM13bmzBhggzDsL1/6qmnVK5cOY0fPz6zSwcAAAAAACZy+ETnGbFx40aNGDFCkydP1q5du/TFF19o5cqVevvtt9NcZ+TIkfL397e9QkJCTKzYXC1bttTu3bs1d+5cHTx4UMuXL9dTTz2lCxcumFZDUFCQrFar7f2RI0f05JNPKjQ0VDly5JCrq6uCgoLk5pa+PNTf318BAQFZVC0AAAAAAHAUh4VSOXPmlKurq86cOWPXfubMGQUFBaW6zltvvaXnn39e3bp1U+nSpfXss89qxIgRGjlypJKTk1NdZ9CgQYqPj7e9jh8/nunH8iC4dOmSNm3apPfff1+1atVSaGioqlSpokGDBqlZs2aS/rm1bsqUKXr66afl5eWlggUL6vPPP7fbzvHjx9WmTRsFBAQoMDBQzzzzjI4ePWrXZ9asWSpZsqSsVqvy5s2r3r1725bdefuexWLRzp07NXz4cFksFg0dOjTV2/f27dunJk2ayM/PT9myZVONGjV05MgRSfa370VFRen777/XhAkTZLFYZLFYFBcXp8KFC2v06NF2NcbExMhisejw4cOZcHYBAAAAAEBmc1go5eHhoYoVK2rdunW2tuTkZK1bt07VqlVLdZ3r16/LxcW+ZFdXV0myu8XrTlarVX5+fnYvZ+Tr6ytfX199+eWXdrcr/ttbb72lli1bas+ePerYsaPatWun2NhYSdLNmzfVoEEDZcuWTZs2bdLmzZvl6+urhg0bKjExUZI0ZcoU9erVSz169NDevXu1fPlyFS5cONV9nTp1SiVLllS/fv106tQp9e/fP0WfEydOqGbNmrJarVq/fr127typLl266NatWyn6TpgwQdWqVVP37t116tQpnTp1So899pi6dOmi2bNn2/WdPXu2atasmWZtAAAAAADAsRw2p5Qk9e3bV5GRkapUqZKqVKmi8ePH69q1a+rcubMkqVOnTsqXL59GjhwpSWratKnGjh2r8uXLq2rVqjp8+LDeeustNW3a1BZOParc3Nw0Z84cde/eXVOnTlWFChUUERGhdu3aqUyZMrZ+rVu3Vrdu3SRJb7/9tr799lt99NFHmjx5shYtWqTk5GTNmDFDFotF0j/hTkBAgDZu3Kj69evrnXfeUb9+/dSnTx/bNitXrpxqTbdv0/P19bWNfjt//rxdn0mTJsnf318LFy6Uu7u7JKlo0aKpbs/f318eHh7y9va2G00XFRWlIUOG6Oeff1aVKlV08+ZNzZ8/P8XoKQAAAAAA8OBwaCjVtm1b2+Tcp0+fVrly5bR69Wrb5OfHjh2zGxk1ePBgWSwWDR48WCdOnFCuXLnUtGlTvfvuu446hAdKy5Yt1bhxY23atElbt27VN998o1GjRmnGjBmKioqSpBSj0KpVq2a7lW7Pnj06fPiwsmXLZtfnxo0bOnLkiM6ePauTJ0+qTp06mVZzTEyMatSoYQuk7kdwcLAaN26sWbNmqUqVKvr666+VkJCg1q1bZ1qdAAAAAAAgczk0lJKk3r17281JdKeNGzfavXdzc1N0dLSio6NNqOzh5OnpqXr16qlevXp666231K1bN0VHR9tCqbu5evWqKlasqHnz5qVYlitXrhS3TmYGLy+vTNlOt27d9Pzzz2vcuHGaPXu22rZtK29v70zZNgAAAAAAyHwP1dP3kHElSpTQtWvXbO+3bt1qt3zr1q0KDw+XJFWoUEGHDh1S7ty5VbhwYbuXv7+/smXLprCwMLt5wP6rMmXKaNOmTbp582a6+nt4eCgpKSlFe6NGjeTj46MpU6Zo9erV6tKlS6bVCAAAAAAAMh+hlJO4cOGCateurc8++0y//PKL4uLitGTJEo0aNUrPPPOMrd+SJUs0a9YsHTx4UNHR0fr5559tI9U6duyonDlz6plnntGmTZsUFxenjRs36uWXX9aff/4pSRo6dKjGjBmjDz/8UIcOHdKuXbv00Ucf3XfdvXv31uXLl9WuXTvt2LFDhw4d0qeffqoDBw6k2j8sLEzbtm3T0aNHdf78edtTF11dXRUVFaVBgwapSJEiaU6WDwAAAAAAHgyEUk7C19dXVatW1bhx41SzZk2VKlVKb731lrp3766JEyfa+g0bNkwLFy5UmTJl9Mknn2jBggUqUaKEJMnb21s//PCDHnvsMbVo0ULh4eHq2rWrbty4YXtqYWRkpMaPH6/JkyerZMmSatKkiQ4dOnTfdefIkUPr16/X1atXFRERoYoVK2r69OlpzjHVv39/ubq6qkSJEsqVK5eOHTtmW9a1a1clJibaJsoHAAAAAAAPLothGIajizDT5cuX5e/vr/j4eFvQctuNGzcUFxenAgUKyNPT00EVZh2LxaJly5apefPmji4lS2zatEl16tTR8ePHbZPlp8bZP2cAAOC8YouHO7qENIXvj3V0CUCWKD23tKNLSNPeyL2OLuGhNKZtE0eXkKZ+i1Y4uoRMcbfs5U4On+gc+K8SEhJ07tw5DR06VK1bt75rIAUAAAAAAB4M3L6Hh96CBQsUGhqqS5cuadSoUY4uBwAAAAAApAMjpR4hznqnZlRUlKKiohxdBgAAAAAAyABGSgEAAAAAAMB0hFKpcNYRRfgHny8AAAAAAI5HKHUHd3d3SdL169cdXAmy0u3P9/bnDQAAAAAAzMecUndwdXVVQECAzp49K0ny9vaWxWJxcFXILIZh6Pr16zp79qwCAgLk6urq6JIAAAAAAHhkEUr9S1BQkCTZgik4n4CAANvnDAAAAAAAHINQ6l8sFovy5s2r3Llz6+bNm44uB5nM3d2dEVIAAAAAADwACKXS4OrqSngBAAAAAACQRZjoHAAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDp3BxdAAAAjlZ6bmlHl5CmvZF7HV0CAAAAkCUYKQUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAEzn5ugCAAAAMtuYtk0cXcJd9Vu0wtElAAAAOBwjpQAAAAAAAGA6QikAAAAAAACYjtv3AAAAnFTYwJWOLiFNR99r7OgSAACAgzFSCgAAAAAAAKZjpBQAOBFGRQAAAAB4WDBSCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDp3BxdAP4bHv8OAAAAAAAeRoRSAAAAAP6zSS+sd3QJaeo1tbajS8C9DPV3dAVpK/CYoysAnBa37wEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANO5OboAAAAAAEDWChu40tEl3NVRT0dXAMARGCkFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHQOD6UmTZqksLAweXp6qmrVqvr555/v2v/SpUvq1auX8ubNK6vVqqJFi2rVqlUmVQsAAAAAAIDM4ObInS9atEh9+/bV1KlTVbVqVY0fP14NGjTQgQMHlDt37hT9ExMTVa9ePeXOnVuff/658uXLpz/++EMBAQHmFw9kkdji4Y4u4a7C98c6ugQAAAAAgBNwaCg1duxYde/eXZ07d5YkTZ06VStXrtSsWbM0cODAFP1nzZqlixcv6qeffpK7u7skKSwszMySAQAAAAAAkAkcdvteYmKidu7cqbp16/5/MS4uqlu3rrZs2ZLqOsuXL1e1atXUq1cv5cmTR6VKldKIESOUlJRkVtkAAAAAAADIBA4bKXX+/HklJSUpT548du158uTR/v37U13n999/1/r169WxY0etWrVKhw8f1osvvqibN28qOjo61XUSEhKUkJBge3/58uXMOwgAAAAAAADcF4dPdJ4RycnJyp07tz7++GNVrFhRbdu21ZtvvqmpU6emuc7IkSPl7+9ve4WEhJhYMQAAAAAAAFLjsFAqZ86ccnV11ZkzZ+zaz5w5o6CgoFTXyZs3r4oWLSpXV1dbW3h4uE6fPq3ExMRU1xk0aJDi4+Ntr+PHj2feQQAAAAAAAOC+OCyU8vDwUMWKFbVu3TpbW3JystatW6dq1aqluk716tV1+PBhJScn29oOHjyovHnzysPDI9V1rFar/Pz87F4AAAAAAABwLIc+fa9v376KjIxUpUqVVKVKFY0fP17Xrl2zPY2vU6dOypcvn0aOHClJ6tmzpyZOnKg+ffropZde0qFDhzRixAi9/PLLjjwMpGWov6MrSNvQeEdXAAAAAADAI82hoVTbtm117tw5DRkyRKdPn1a5cuW0evVq2+Tnx44dk4vL/w/mCgkJ0Zo1a/Tqq6+qTJkyypcvn/r06aPXX3/dUYcAAAAAAACA++DQUEqSevfurd69e6e6bOPGjSnaqlWrpq1bt2ZxVQAAAAAAAMhKD9XT9wAAAAAAAOAcCKUAAAAAAABgOkIpAAAAAAAAmM7hc0oBeLhMemG9o0tIU6+ptR1dAgAAAAAgnQilADiNMW2bOLqENPVbtMLRJQAAAADAA4Xb9wAAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkIpQAAAAAAAGC6DIdSc+fO1cqVK23vX3vtNQUEBOiJJ57QH3/8kanFAQAAAAAAwDllOJQaMWKEvLy8JElbtmzRpEmTNGrUKOXMmVOvvvpqphcIAAAAAAAA5+OW0RWOHz+uwoULS5K+/PJLtWzZUj169FD16tX11FNPZXZ9AAAAAAAAcEIZHinl6+urCxcuSJLWrl2revXqSZI8PT31999/Z251AAAAAAAAcEoZHilVr149devWTeXLl9fBgwfVqFEjSdK+ffsUFhaW2fUBWaL03NKOLiFNix1dAAAAAAAAJsjwSKlJkyapWrVqOnfunJYuXaocOXJIknbu3Kn27dtneoEAAAAAAABwPhkeKRUQEKCJEyemaB82bFimFAQAcFJD/R1dQdoKPOboCgAAAIBHToZHSknSpk2b9Nxzz+mJJ57QiRMnJEmffvqpfvzxx0wtDgAAAAAAAM4pw6HU0qVL1aBBA3l5eWnXrl1KSEiQJMXHx2vEiBGZXiAAAAAAAACcT4ZDqXfeeUdTp07V9OnT5e7ubmuvXr26du3alanFAQAAAAAAwDllOJQ6cOCAatasmaLd399fly5dyoyaAAAAAAAA4OQyHEoFBQXp8OHDKdp//PFHFSxYMFOKAgAAAAAAgHPLcCjVvXt39enTR9u2bZPFYtHJkyc1b9489e/fXz179syKGgEAAAAAAOBk3DK6wsCBA5WcnKw6dero+vXrqlmzpqxWq/r376+XXnopK2oEAAAAAACAk8lQKJWUlKTNmzerV69eGjBggA4fPqyrV6+qRIkS8vX1zaoaAQAAAAAA4GQyFEq5urqqfv36io2NVUBAgEqUKJFVdQEAAAAAAMCJZXhOqVKlSun333/PiloAAAAAAADwiMhwKPXOO++of//+WrFihU6dOqXLly/bvQAAAAAAAIB7yfBE540aNZIkNWvWTBaLxdZuGIYsFouSkpIyrzoAAAAAAAA4pQyHUhs2bMiKOgAAAAAAAPAIyXAoFRERkRV1AAAAAAAA4BGS4VBKki5duqSZM2cqNjZWklSyZEl16dJF/v7+mVocAAAAAAAAnFOGJzrfsWOHChUqpHHjxunixYu6ePGixo4dq0KFCmnXrl1ZUSMAAAAAAACcTIZHSr366qtq1qyZpk+fLje3f1a/deuWunXrpldeeUU//PBDphcJAAAAJzP0AR5hPzTe0RUAAPBIyHAotWPHDrtASpLc3Nz02muvqVKlSplaHAAAAAAAAJxThm/f8/Pz07Fjx1K0Hz9+XNmyZcuUogAAAAAAAODcMhxKtW3bVl27dtWiRYt0/PhxHT9+XAsXLlS3bt3Uvn37rKgRAAAAAAAATibDt++NHj1aFotFnTp10q1btyRJ7u7u6tmzp957771MLxAAAAAAAADOJ8OhlIeHhyZMmKCRI0fqyJEjkqRChQrJ29s704sDAAAAAACAc8pwKBUfH6+kpCQFBgaqdOnStvaLFy/Kzc1Nfn5+mVogAAAAAAAAnE+G55Rq166dFi5cmKJ98eLFateuXaYUBQAAAAAAAOeW4VBq27ZtqlWrVor2p556Stu2bcuUogAAAAAAAODcMhxKJSQk2CY4v9PNmzf1999/Z0pRAAAAAAAAcG4ZDqWqVKmijz/+OEX71KlTVbFixUwpCgAAAAAAAM4twxOdv/POO6pbt6727NmjOnXqSJLWrVun7du3a+3atZleIAAAAAAAAJxPhkdKVa9eXVu2bFFISIgWL16sr7/+WoULF9Yvv/yiGjVqZEWNAAAAAAAAcDIZHiklSeXKldO8efMyuxYAAAAAAAA8ItIdSt26dUtJSUmyWq22tjNnzmjq1Km6du2amjVrpieffDJLigQAAAAAAIBzSXco1b17d3l4eGjatGmSpCtXrqhy5cq6ceOG8ubNq3Hjxumrr75So0aNsqxYAAAAAAAAOId0h1KbN2/WxIkTbe8/+eQTJSUl6dChQ/L399frr7+uDz74gFAKAAAAD7XSc0s7uoQ0LXZ0AQAAZKJ0T3R+4sQJFSlSxPZ+3bp1atmypfz9/SVJkZGR2rdvX+ZXCAAAAAAAAKeT7lDK09NTf//9t+391q1bVbVqVbvlV69ezdzqAAAAAAAA4JTSHUqVK1dOn376qSRp06ZNOnPmjGrXrm1bfuTIEQUHB2d+hQAAAAAAAHA66Z5TasiQIXr66ae1ePFinTp1SlFRUcqbN69t+bJly1S9evUsKRIAAAAAAADOJd2hVEREhHbu3Km1a9cqKChIrVu3tlterlw5ValSJdMLBAAAAAAAgPNJdyglSeHh4QoPD091WY8ePTKlIAAAAAAAADi/dM8pBQAAAAAAAGQWQikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkyHEpt375d27ZtS9G+bds27dixI1OKAgAAAAAAgHPLcCjVq1cvHT9+PEX7iRMn1KtXr0wpCgAAAAAAAM4tw6HUb7/9pgoVKqRoL1++vH777bdMKQoAAAAAAADOLcOhlNVq1ZkzZ1K0nzp1Sm5ubplSFAAAAAAAAJxbhkOp+vXra9CgQYqPj7e1Xbp0SW+88Ybq1auXqcUBAAAAAADAOWV4aNPo0aNVs2ZNhYaGqnz58pKkmJgY5cmTR59++mmmFwgAAAAAAADnk+FQKl++fPrll180b9487dmzR15eXurcubPat28vd3f3rKgRAAAAAAA8RCa9sN7RJeAhcF+TQPn4+KhHjx6ZXQsAAAAAAAAeEekKpZYvX66nn35a7u7uWr58+V37NmvWLFMKAwAAAAAAgPNKVyjVvHlznT59Wrlz51bz5s3T7GexWJSUlJRZtQEAAAAAAMBJpSuUSk5OTvXPAAAAAAAAwP1wyUjnmzdvqk6dOjp06FBW1QMAAAAAAIBHQIZCKXd3d/3yyy9ZVQsAAAAAAAAeERkKpSTpueee08yZM7OiFgAAAAAAADwi0jWn1J1u3bqlWbNm6bvvvlPFihXl4+Njt3zs2LGZVhwAAAAAAACcU4ZDqV9//VUVKlSQJB08eDDTCwIAAAAAAIDzy3AotWHDhqyoAwAAAAAAAI+QDM8p1aVLF125ciVF+7Vr19SlS5dMKQoAAAAAAADOLcOh1Ny5c/X333+naP/777/1ySefZEpRAAAAAAAAcG7pvn3v8uXLMgxDhmHoypUr8vT0tC1LSkrSqlWrlDt37iwpEgAAAAAAAM4l3aFUQECALBaLLBaLihYtmmK5xWLRsGHDMrU4AAAAAAAAOKd0h1IbNmyQYRiqXbu2li5dqsDAQNsyDw8PhYaGKjg4OEuKBAAAAAAAgHNJdygVEREhSYqLi9Njjz0mi8WSZUUBAAAAAADAuWV4ovPQ0FD9+OOPeu655/TEE0/oxIkTkqRPP/1UP/74Y6YXCAAAAAAAAOeT4VBq6dKlatCggby8vLRr1y4lJCRIkuLj4zVixIhMLxAAAAAAAADOJ8Oh1DvvvKOpU6dq+vTpcnd3t7VXr15du3btytTiAAAAAAAA4JwyHEodOHBANWvWTNHu7++vS5cuZUZNAAAAAAAAcHIZDqWCgoJ0+PDhFO0//vijChYsmClFAQAAAAAAwLllOJTq3r27+vTpo23btslisejkyZOaN2+e+vfvr549e2ZFjQAAAAAAAHAybhldYeDAgUpOTladOnV0/fp11axZU1arVf3799dLL72UFTUCAAAAAADAyWQ4lLJYLHrzzTc1YMAAHT58WFevXlWJEiXk6+ubFfUBAAAAAADACWU4lLrNw8NDJUqUyMxaAAAAAAAA8IhIdyjVpUuXdPWbNWvWfRcDAAAAAACAR0O6Q6k5c+YoNDRU5cuXl2EYWVkTAAAAAAAAnFy6Q6mePXtqwYIFiouLU+fOnfXcc88pMDAwK2sDAAAAAACAk3JJb8dJkybp1KlTeu211/T1118rJCREbdq00Zo1axg5BQAAAAAAgAzJ0ETnVqtV7du3V/v27fXHH39ozpw5evHFF3Xr1i3t27ePJ/ABAJDJYouHO7qENIXvj3V0CQAAAHiIpXukVIoVXVxksVhkGIaSkpIysyYAAAAAAAA4uQyFUgkJCVqwYIHq1aunokWLau/evZo4caKOHTvGKCkAAAAAAACkW7pv33vxxRe1cOFChYSEqEuXLlqwYIFy5syZlbUBAAAAAADASaU7lJo6daoee+wxFSxYUN9//72+//77VPt98cUXmVYcAAAAAAAAnFO6Q6lOnTrJYrFkZS0AAAAAAAB4RKQ7lJozZ04WlgEAAAAAAIBHyX0/fQ8AAAAAAAC4X4RSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTPRCh1KRJkxQWFiZPT09VrVpVP//8c7rWW7hwoSwWi5o3b561BQIAAAAAACBTOTyUWrRokfr27avo6Gjt2rVLZcuWVYMGDXT27Nm7rnf06FH1799fNWrUMKlSAAAAAAAAZBaHh1Jjx45V9+7d1blzZ5UoUUJTp06Vt7e3Zs2aleY6SUlJ6tixo4YNG6aCBQuaWC0AAAAAAAAyg0NDqcTERO3cuVN169a1tbm4uKhu3brasmVLmusNHz5cuXPnVteuXe+5j4SEBF2+fNnuBQAAAAAAAMdyaCh1/vx5JSUlKU+ePHbtefLk0enTp1Nd58cff9TMmTM1ffr0dO1j5MiR8vf3t71CQkL+c90AAAAAAAD4bxx++15GXLlyRc8//7ymT5+unDlzpmudQYMGKT4+3vY6fvx4FlcJAAAAAACAe3Fz5M5z5swpV1dXnTlzxq79zJkzCgoKStH/yJEjOnr0qJo2bWprS05OliS5ubnpwIEDKlSokN06VqtVVqs1C6oHAAAAAADA/XLoSCkPDw9VrFhR69ats7UlJydr3bp1qlatWor+xYsX1969exUTE2N7NWvWTLVq1VJMTAy35gEAAAAAADwkHDpSSpL69u2ryMhIVapUSVWqVNH48eN17do1de7cWZLUqVMn5cuXTyNHjpSnp6dKlSplt35AQIAkpWgHAABZa9IL6x1dAgAAAB5iDg+l2rZtq3PnzmnIkCE6ffq0ypUrp9WrV9smPz927JhcXB6qqa8AAAAAAABwDw4PpSSpd+/e6t27d6rLNm7ceNd158yZk/kFAQAAAAAAIEsxBAkAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmc3N0AQAAAAAAIONii4c7uoS0PTXJ0RXgIcBIKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYLoHIpSaNGmSwsLC5OnpqapVq+rnn39Os+/06dNVo0YNZc+eXdmzZ1fdunXv2h8AAAAAAAAPHoeHUosWLVLfvn0VHR2tXbt2qWzZsmrQoIHOnj2bav+NGzeqffv22rBhg7Zs2aKQkBDVr19fJ06cMLlyAAAAAAAA3C+Hh1Jjx45V9+7d1blzZ5UoUUJTp06Vt7e3Zs2alWr/efPm6cUXX1S5cuVUvHhxzZgxQ8nJyVq3bp3JlQMAAAAAAOB+OTSUSkxM1M6dO1W3bl1bm4uLi+rWrastW7akaxvXr1/XzZs3FRgYmOryhIQEXb582e4FAAAAAAAAx3JoKHX+/HklJSUpT548du158uTR6dOn07WN119/XcHBwXbB1p1Gjhwpf39/2yskJOQ/1w0AAAAAAID/xuG37/0X7733nhYuXKhly5bJ09Mz1T6DBg1SfHy87XX8+HGTqwQAAAAAAMC/uTly5zlz5pSrq6vOnDlj137mzBkFBQXddd3Ro0frvffe03fffacyZcqk2c9qtcpqtWZKvQAAAAAAAMgcDh0p5eHhoYoVK9pNUn570vJq1aqlud6oUaP09ttva/Xq1apUqZIZpQIAAAAAACATOXSklCT17dtXkZGRqlSpkqpUqaLx48fr2rVr6ty5sySpU6dOypcvn0aOHClJev/99zVkyBDNnz9fYWFhtrmnfH195evr67DjAAAAAAAAQPo5PJRq27atzp07pyFDhuj06dMqV66cVq9ebZv8/NixY3Jx+f8BXVOmTFFiYqJatWplt53o6GgNHTrUzNIBAAAAAABwnxweSklS79691bt371SXbdy40e790aNHs74gAAAAAAAAZKmH+ul7AAAAAAAAeDgRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANO5OboAAAAAAMhKY9o2cXQJaeq3aIWjSwAAh2GkFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMN0DEUpNmjRJYWFh8vT0VNWqVfXzzz/ftf+SJUtUvHhxeXp6qnTp0lq1apVJlQIAAAAAACAzODyUWrRokfr27avo6Gjt2rVLZcuWVYMGDXT27NlU+//0009q3769unbtqt27d6t58+Zq3ry5fv31V5MrBwAAAAAAwP1yeCg1duxYde/eXZ07d1aJEiU0depUeXt7a9asWan2nzBhgho2bKgBAwYoPDxcb7/9tipUqKCJEyeaXDkAAAAAAADul0NDqcTERO3cuVN169a1tbm4uKhu3brasmVLquts2bLFrr8kNWjQIM3+AAAAAAAAePC4OXLn58+fV1JSkvLkyWPXnidPHu3fvz/VdU6fPp1q/9OnT6faPyEhQQkJCbb38fHxkqTLly//l9IfGMkJ1x1dQpouWwxHl5CmpL+THF1Cmq4mPbi1SdLfidccXUKaEm7edHQJaTLrmsM14f5wTbg/XA/uH9cErgn3i2vC/XmQrwlcD/7BNeH+cE24P1wTst7t4zCMu/+2HRpKmWHkyJEaNmxYivaQkBAHVPNo8Xd0AXcV6+gC0lTF0QXcy+Fmjq7goTR42YP9izDDg30GuCbcF64H941rAteE+8U1wflwPfjHg30WuCbcF64J98XZrglXrlyRv3/ax+TQUCpnzpxydXXVmTNn7NrPnDmjoKCgVNcJCgrKUP9Bgwapb9++tvfJycm6ePGicuTIIYvF8h+PAMhcly9fVkhIiI4fPy4/Pz9HlwPAwbgmALgT1wQAd+KagAeZYRi6cuWKgoOD79rPoaGUh4eHKlasqHXr1ql58+aS/gmN1q1bp969e6e6TrVq1bRu3Tq98sortrZvv/1W1apVS7W/1WqV1Wq1awsICMiM8oEs4+fnx39YANhwTQBwJ64JAO7ENQEPqruNkLrN4bfv9e3bV5GRkapUqZKqVKmi8ePH69q1a+rcubMkqVOnTsqXL59GjhwpSerTp48iIiI0ZswYNW7cWAsXLtSOHTv08ccfO/IwAAAAAAAAkAEOD6Xatm2rc+fOaciQITp9+rTKlSun1atX2yYzP3bsmFxc/v8hgU888YTmz5+vwYMH64033lCRIkX05ZdfqlSpUo46BAAAAAAAAGSQw0MpSerdu3eat+tt3LgxRVvr1q3VunXrLK4KMJ/ValV0dHSKW04BPJq4JgC4E9cEAHfimgBnYDHu9Xw+AAAAAAAAIJO53LsLAAAAAAAAkLkIpQAAAAAAAGA6QikAAAAAAACYjlAKeAht3LhRzzzzjPLmzSsfHx+VK1dO8+bNc3RZABzkxo0bioqKUunSpeXm5qbmzZs7uiTgkXX69Gm99NJLKliwoKxWq0JCQtS0aVOtW7dOkhQWFiaLxaKtW7farffKK6/oqaeesr0fOnSoLBaLXnjhBbt+MTExslgsOnr06D1rOXr0qCwWi2JiYlJdPmfOHFkslhSvGTNmZOiYgYfVuXPn1LNnTz322GOyWq0KCgpSgwYNtHnzZkn//3u1WCzy8fFRhQoVtGTJEtv6t3+n/34VL17cbj+HDx9W586dlT9/flmtVhUoUEDt27fXjh070vwd3vk6evSo3b5cXV0VEhKiHj166OLFiymO66efflKjRo2UPXt2eXp6qnTp0ho7dqySkpIydH42bNigRo0aKUeOHPL29laJEiXUr18/nThxQtI/fyexWCwqWbJkim0HBARozpw5tvfpvfbh0UMoBTyEfvrpJ5UpU0ZLly7VL7/8os6dO6tTp05asWKFo0sD4ABJSUny8vLSyy+/rLp16zq6HOCRdfToUVWsWFHr16/XBx98oL1792r16tWqVauWevXqZevn6emp119//Z7b8/T01MyZM3Xo0KEsq9nPz0+nTp2ye3Xs2DHL9gc8SFq2bKndu3dr7ty5OnjwoJYvX66nnnpKFy5csPUZPny4Tp06pd27d6ty5cpq27atfvrpJ9vykiVLpvgN/fjjj7blO3bsUMWKFXXw4EFNmzZNv/32m5YtW6bixYurX79+atu2rd261apVU/fu3e3aQkJC7PZ17NgxzZ49W6tXr1bPnj3tjmnZsmWKiIhQ/vz5tWHDBu3fv199+vTRO++8o3bt2im9zzmbNm2a6tatq6CgIC1dulS//fabpk6dqvj4eI0ZM8au7++//65PPvnknttM77UPjxgDQKZLSkoyRowYYYSFhRmenp5GmTJljCVLlhjJyclGnTp1jPr16xvJycmGYRjGhQsXjHz58hlvvfWWYRiGsWHDBkOSsWLFCqN06dKG1Wo1qlatauzdu/eu+2zUqJHRuXPnLD82ABln5jUhMjLSeOaZZ8w6NAB3ePrpp418+fIZV69eTbHsr7/+MgzDMEJDQ42XX37Z8PDwMFauXGlb3qdPHyMiIsL2Pjo62ihbtqxRr149o3Xr1rb23bt3G5KMuLi4e9YTFxdnSDJ2796d6vLZs2cb/v7+6Tk0wOn89ddfhiRj48aNafYJDQ01xo0bZ3t/8+ZNw9vb2xg4cKBhGP//O01LcnKyUbJkSaNixYpGUlJSqjX8W0REhNGnT58U7antq2/fvkb27Nlt769evWrkyJHDaNGiRYr1ly9fbkgyFi5cmGa9tx0/ftzw8PAwXnnllVSX36779v9HGTBggBESEmLcuHHD1sff39+YPXu27X16r3149DBSCsgCI0eO1CeffKKpU6dq3759evXVV/Xcc8/phx9+0Ny5c7V9+3Z9+OGHkqQXXnhB+fLl05AhQ+y2MWDAAI0ZM0bbt29Xrly51LRpU928eTPNfcbHxyswMDBLjwvA/XHENQGAuS5evKjVq1erV69e8vHxSbE8ICDA9ucCBQrohRde0KBBg5ScnHzX7b733ntaunSpduzYkdklA480X19f+fr66ssvv1RCQkK61nFzc5O7u7sSExPT1T8mJkb79u1Tv3795OKS8q/ed14XMuro0aNas2aNPDw8bG1r167VhQsX1L9//xT9mzZtqqJFi2rBggX33PaSJUuUmJio1157LdXl/677lVde0a1bt/TRRx/ddbsZufbh0UEoBWSyhIQEjRgxQrNmzVKDBg1UsGBBRUVF6bnnntO0adOUL18+TZs2TQMHDtSgQYO0atUqffbZZ3Jzc7PbTnR0tOrVq6fSpUtr7ty5OnPmjJYtW5bqPhcvXqzt27erc+fOZhwigAxwxDUBgPkOHz4swzBSzCWTlsGDBysuLu6ec0JWqFBBbdq0ybJbXuLj421/Off19VVQUFCW7Ad40Li5uWnOnDmaO3euAgICVL16db3xxhv65ZdfUu2fmJiokSNHKj4+XrVr17a179271+435Ovra5sL7vatt+m9LtzL7X15eXmpQIEC2rdvn9214eDBg5Kk8PDwVNcvXry4rc/dHDp0SH5+fsqbN2+66vL29lZ0dLTt/NxNeq99eHS43bsLgIw4fPiwrl+/rnr16tm1JyYmqnz58pKk1q1ba9myZXrvvfc0ZcoUFSlSJMV2qlWrZvtzYGCgihUrptjY2BT9NmzYoM6dO2v69OkqWbJkJh8NgP/K7GsCAMcw0jlPy225cuVS//79NWTIELVt2/aufd955x2Fh4dr7dq1yp07938pM4Vs2bJp165dtvepjeYAnFXLli3VuHFjbdq0SVu3btU333yjUaNGacaMGYqKipIkvf766xo8eLBu3LghX19fvffee2rcuLFtG8WKFdPy5cvttuvn5ycp49eFe7m9rxs3buizzz5TTEyMXnrppRT9/ut+DcOQxWLJ0Dpdu3bVmDFj9P7772vEiBFp9svItQ+PBkIpIJNdvXpVkrRy5Urly5fPbpnVapUkXb9+XTt37pSrq+t/mrz0+++/V9OmTTVu3Dh16tTp/osGkGXMvCYAcJwiRYrIYrFo//796V6nb9++mjx5siZPnnzXfoUKFVL37t01cOBAzZw587+WasfFxUWFCxfO1G0CDxNPT0/Vq1dP9erV01tvvaVu3bopOjraFkoNGDBAUVFR8vX1VZ48eVKENR4eHmn+hooWLSpJ2r9/v+0fov6LO/d1OxwbNmyY3n77bbv9xcbG6oknnkixfmxsrEqUKHHP/RQtWlTx8fE6depUukdLubm56d1331VUVJR69+59177pvfbh0cA/hQCZrESJErJarTp27JgKFy5s97r95Izb95V/8803+vDDD7V+/foU27nzcal//fWXDh48aDcUd+PGjWrcuLHef/999ejRI+sPDMB9MeuaAMCxAgMD1aBBA02aNEnXrl1LsfzSpUsp2nx9ffXWW2/p3Xff1ZUrV+66/SFDhujgwYNauHBhZpUMIBUlSpSw+w3nzJlThQsXVlBQUIZHD5UrV04lSpTQmDFjUp1DKbXrQkYMHjxYo0eP1smTJyVJ9evXV2BgYIqn40nS8uXLdejQIbVv3/6e223VqpU8PDw0atSoVJenVXfr1q1VsmRJDRs27K7bz8i1D86PkVJAJsuWLZv69++vV199VcnJyXryyScVHx+vzZs3y8/PTzlz5tSsWbO0ZcsWVahQQQMGDFBkZKR++eUXZc+e3bad4cOHK0eOHMqTJ4/efPNN5cyZU82bN5f0zy17TZo0UZ8+fdSyZUudPn1a0j//esJk58CDxYxrgiT99ttvSkxM1MWLF3XlyhXFxMRI+uf/EAMwx6RJk1S9enVVqVJFw4cPV5kyZXTr1i19++23mjJlSqq33Pbo0UPjxo3T/PnzVbVq1TS3nSdPHvXt21cffPBBhus6cOBAijZu+cej7sKFC2rdurW6dOmiMmXKKFu2bNqxY4dGjRqlZ555Jt3buXXrlu3/i99msVhso6pmz56tunXrqkaNGnrzzTdVvHhxXb16VV9//bXWrl2r77///r6PoVq1aipTpoxGjBihiRMnysfHR9OmTVO7du3Uo0cP9e7dW35+flq3bp0GDBigVq1aqU2bNvfcbkhIiMaNG6fevXvr8uXL6tSpk8LCwvTnn3/qk08+ka+vb6rBl/TPCK4GDRrccx/pvfbhEeDQZ/8BTio5OdkYP368UaxYMcPd3d3IlSuX0aBBA2Pjxo1Gnjx5jBEjRtj6JiYmGhUrVjTatGljGMb/P1r166+/NkqWLGl4eHgYVapUMfbs2WNbJzIy0pCU4sXjVIEHU1ZfEwzjn0ctp3ZdAGCukydPGr169TJCQ0MNDw8PI1++fEazZs2MDRs2GIaR8hHzhmEY8+fPT/Hf8dQe/x4fH2/kzJnTkGTExcXds5a4uLhUrwuSjOPHjxuzZ882/P39/9PxAg+rGzduGAMHDjQqVKhg+Pv7G97e3kaxYsWMwYMHG9evXzcMI/Xf652io6NT/X1ZrVa7fgcOHDA6depkBAcHGx4eHkZoaKjRvn17Y9euXSm2GRERYfTp0yfVff37mvB/7d1/TNXVH8fx1xVBQLlmhfkjlIbdFE2Dmg6M1GCBmVN0WII/QNEomVpiQrbEf6y5WlgrawvBlYp/SOgmls2JiZoiDnCDEhkXK203EjMCFfF8//Dr/XoDFPtxxa/Px/bZ7jnnc855fz5sd3fvnXMwxpgtW7aYHj16mFOnTjnrvvnmGxMdHW2sVqvx8vIyw4cPN++88465fPly517Of3399dcmOjra9OnTx3h7e5uhQ4eatLQ0c/r0aWPM/36jNDQ0uPR75plnjCSTk5PjrOvsdx/uPhZj/uHT1wD8LUVFRZowYYIaGhr+1r+JBfD/ge8EAAAA/L/iTCkAAAAAAAC4HUkpAAAA4A6UkpKiXr16tXulpKTc7vAAdFFr1qzp8Ltj4sSJtzs83GXYvgcAAADcgRwOh86fP99um9VqVd++fd0cEYA7wdmzZ3X27Nl223x8fDRw4EA3R4S7GUkpAAAAAAAAuB3b9wAAAAAAAOB2JKUAAAAAAADgdiSlAAAAAAAA4HYkpQAAAAAAAOB2JKUAAMBdqaioSBaLRefOnet0n8DAQGVlZf1rMd2IxWJRQUFBh+1/5XkAAABuJ5JSAACgy0lMTJTFYlFKSkqbtkWLFslisSgxMdH9gXXSjz/+KC8vL40YMcJtc4aHh+vMmTPq3bu3JCk3N1f33HPPPz7P+PHjtXTp0n98XAAAcPchKQUAALqkgIAA5eXlqbm52Vl34cIFbd68WYMGDbqNkd1cbm6uZsyYofPnz+vw4cM3vb+lpeVvz+nl5aV+/frJYrH87bHc4dKlS7c7BAAAcJuRlAIAAF1SaGioAgIClJ+f76zLz8/XoEGDFBIS4nLvxYsXtXjxYvXt21fe3t568sknVVJS4nJPYWGhbDabfHx8NGHCBNnt9jZzFhcXKyIiQj4+PgoICNDixYv1xx9/3FLcxhjl5ORo9uzZio+PV3Z2tku73W6XxWLR1q1bNW7cOHl7e2vTpk2SpA0bNmj48OHq0aOH+vfvr9TUVJe+9fX1io2Nla+vrx5++GHt2LHD2Xb99r2ioiIlJSXpt99+k8VikcViUWZmpvNdpaWlaeDAgerZs6fGjBmjoqIil3kOHDig8ePHy9fXV3369FF0dLQaGhqUmJioffv2ad26dc5x7XZ7u6uyCgoKXBJkmZmZeuyxx/Tpp5/qoYcekre3tyTp3LlzSk5Olr+/v6xWq55++mmVl5c7+5WXl2vChAny8/OT1WrV448/rqNHj97S3wQAAHRNJKUAAECXNW/ePOXk5DjLGzZsUFJSUpv7XnvtNW3btk0bN27UsWPHNGTIEEVHR+vs2bOSpB9++EHTpk3T5MmTVVZWpuTkZKWnp7uMUVNTo5iYGE2fPl0VFRXaunWriouL2ySGbmbv3r1qampSVFSUZs2apby8vHYTW+np6VqyZImqqqoUHR2t9evXa9GiRVq4cKGOHz+uHTt2aMiQIS59Vq9erRkzZqiiokLPPvusEhISnM94vfDwcGVlZclqterMmTM6c+aM0tLSJEmpqak6dOiQ8vLyVFFRobi4OMXExKi6ulqSVFZWpsjISAUHB+vQoUMqLi7W5MmT1draqnXr1iksLEwLFixwjhsQENDpd3Py5Elt27ZN+fn5KisrkyTFxcXJ4XBo165dKi0tVWhoqCIjI53PlZCQoAcffFAlJSUqLS1Venq6PD09Oz0nAADowgwAAEAXM3fuXDNlyhTjcDhMjx49jN1uN3a73Xh7e5tffvnFTJkyxcydO9cYY0xjY6Px9PQ0mzZtcva/dOmSGTBggFm7dq0xxpiMjAwTHBzsMseKFSuMJNPQ0GCMMWb+/Plm4cKFLvfs37/fdOvWzTQ3NxtjjBk8eLB57733bhh7fHy8Wbp0qbM8atQok5OT4yzX1tYaSSYrK8ul34ABA8zKlSs7HFeSeeONN5zlxsZGI8ns2rXLGGPM3r17XZ4nJyfH9O7d22WMuro64+HhYX766SeX+sjISJORkWGMMWbmzJlm7NixHcYxbtw4s2TJEpe69ub64osvzPU/NVetWmU8PT2Nw+Fw1u3fv99YrVZz4cIFl75BQUHmk08+McYY4+fnZ3JzczuMBwAA3Lm6386EGAAAwI34+/tr0qRJys3NlTFGkyZN0v333+9yT01NjVpaWjR27Fhnnaenp0aPHq2qqipJUlVVlcaMGePSLywszKVcXl6uiooK51Y66epWvCtXrqi2tlbDhg27abznzp1Tfn6+iouLnXWzZs1SdnZ2m4PZn3jiCednh8Oh06dPKzIy8objjxw50vm5Z8+eslqtcjgcN43rmuPHj6u1tVU2m82l/uLFi7rvvvskXV0pFRcX1+kxb8XgwYPl7+/vLJeXl6uxsdE59zXNzc2qqamRJL366qtKTk7WZ599pqioKMXFxSkoKOhfiQ8AALgXSSkAANClzZs3z7mF7sMPP/zX5mlsbNSLL76oxYsXt2nr7MHqmzdv1oULF1wSYNcSWydOnHBJBvXs2dP52cfHp1Pj/3nbmsVi0ZUrVzrVV7r6jB4eHiotLZWHh4dLW69evW4plut169ZNxhiXuvYOb7/+ma/F079//zZnWklynlGVmZmp+Ph47dy5U7t27dKqVauUl5en2NjYW44TAAB0LZwpBQAAurSYmBhdunRJLS0tio6ObtMeFBQkLy8vHThwwFnX0tKikpISBQcHS5KGDRumI0eOuPT79ttvXcqhoaGqrKzUkCFD2lxeXl6dijU7O1vLli1TWVmZ8yovL1dERIQ2bNjQYT8/Pz8FBgZqz549nZqnM7y8vNTa2upSFxISotbWVjkcjjbP2K9fP0lXV2PdKI72xvX399fvv//ucnbWtTOjbiQ0NFQ///yzunfv3iae61fE2Ww2vfLKK9q9e7emTZvmcs4YAAC4c5GUAgAAXZqHh4eqqqpUWVnZZnWPdHX1zUsvvaTly5fryy+/VGVlpRYsWKCmpibNnz9fkpSSkqLq6motX75c33//vTZv3qzc3FyXcVasWKGDBw8qNTVVZWVlqq6u1vbt2zt90HlZWZmOHTum5ORkjRgxwuWaOXOmNm7cqMuXL3fYPzMzU++++67ef/99VVdX69ixY/rggw86/6L+JDAwUI2NjdqzZ4/q6+vV1NQkm82mhIQEzZkzR/n5+aqtrdWRI0f01ltvaefOnZKkjIwMlZSU6OWXX1ZFRYW+++47rV+/XvX19c5xDx8+LLvdrvr6el25ckVjxoyRr6+vXn/9ddXU1LT7ftsTFRWlsLAwTZ06Vbt375bdbtfBgwe1cuVKHT16VM3NzUpNTVVRUZHq6up04MABlZSUdGorJQAA6PpISgEAgC7ParXKarV22P72229r+vTpmj17tkJDQ3Xy5El99dVX6tOnj6Sr2++2bdumgoICjRo1Sh9//LHWrFnjMsbIkSO1b98+nThxQhEREQoJCdGbb76pAQMGdCrG7OxsBQcHa+jQoW3aYmNj5XA4VFhY2GH/uXPnKisrSx999JGGDx+u5557zvkf8f6K8PBwpaSk6Pnnn5e/v7/Wrl0rScrJydGcOXO0bNkyPfLII5o6dapKSkqcWxRtNpt2796t8vJyjR49WmFhYdq+fbu6d7966kNaWpo8PDwUHBwsf39/nTp1Svfee68+//xzFRYW6tFHH9WWLVuUmZl50xgtFosKCwv11FNPKSkpSTabTS+88ILq6ur0wAMPyMPDQ7/++qvmzJkjm82mGTNmaOLEiVq9evVffi8AAKDrsJg/HwAAAAAAAAAA/MtYKQUAAAAAAAC3IykFAAAAAAAAtyMpBQAAAAAAALcjKQUAAAAAAAC3IykFAAAAAAAAtyMpBQAAAAAAALcjKQUAAAAAAAC3IykFAAAAAAAAtyMpBQAAAAAAALcjKQUAAAAAAAC3IykFAAAAAAAAtyMpBQAAAAAAALf7D4qeFrAbBgfdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "# Diccionario de arquitecturas\n",
    "arqs_to_test = {\n",
    "    \"exp2\": [\n",
    "        [7, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 4, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
    "    ],\n",
    "    \"exp1\": [\n",
    "        [6, 9, 0, 1, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n",
    "    ],\n",
    "    \"CNN_LF\": [\n",
    "        [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
    "    ],\n",
    "    \"SPECTRO_CNN\": [\n",
    "        [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Configuración de parámetros globales\n",
    "config = Config(epochs=50)\n",
    "# Cargar y procesar datos de audio\n",
    "audio_dict, sample_rate = load_audio_data('./SM-27', config.window_size, config.sample_rate)\n",
    "audio_dict = preprocess_audio(audio_dict, sample_rate)\n",
    "\n",
    "# División inicial en conjuntos de datos\n",
    "X, Y = train_test_split_audio(audio_dict)\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resultados por arquitectura\n",
    "results = {key: [] for key in arqs_to_test.keys()}\n",
    "\n",
    "# Configuración de parámetros globales\n",
    "config = Config(epochs=50)\n",
    "\n",
    "# Resultados por arquitectura\n",
    "all_fold_results = []  # Para almacenar resultados de cada fold\n",
    "results = {key: [] for key in arqs_to_test.keys()}  # Resumen por arquitectura\n",
    "\n",
    "# Loop para cada arquitectura en el diccionario\n",
    "for model_name, architectures in arqs_to_test.items():\n",
    "    print(f\"Testing model: {model_name}\")\n",
    "    for arq in tqdm(architectures, desc=f\"Testing architectures for {model_name}\"):\n",
    "        # Ajustar la arquitectura\n",
    "        fixed_arch = fixArch(arq, verbose=True)\n",
    "        model_dict = decode_model_architecture(fixed_arch)\n",
    "        \n",
    "        # Crear el modelo\n",
    "        model = build_tf_model_from_dict(model_dict, input_shape=(128, 128, 1))\n",
    "        \n",
    "        # Aplicar K-Fold\n",
    "        kfold = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=42)\n",
    "        fold_metrics = []\n",
    "        \n",
    "        for fold, (train_index, val_index) in enumerate(kfold.split(X_train_val, Y_train_val), 1):\n",
    "            X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "            Y_train, Y_val = Y_train_val[train_index], Y_train_val[val_index]\n",
    "            # Compilar y entrenar el modelo\n",
    "            model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\", 'Precision', 'Recall', F1])\n",
    "            model.fit(X_train, Y_train, epochs=config.epochs, validation_data=(X_val, Y_val), verbose=0)\n",
    "            \n",
    "            # Evaluar el modelo\n",
    "            results_fold = model.evaluate(X_test, Y_test, verbose=0)\n",
    "            Y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "            \n",
    "            # Calcular métricas adicionales\n",
    "            precision = precision_score(Y_test, Y_pred)\n",
    "            recall = recall_score(Y_test, Y_pred)\n",
    "            f1 = f1_score(Y_test, Y_pred)\n",
    "            specificity = specificity_score(Y_test, Y_pred)\n",
    "            \n",
    "            # Guardar resultados de cada fold\n",
    "            fold_result = {\n",
    "                \"Architecture\": model_name,\n",
    "                \"Fold\": fold,\n",
    "                \"Loss\": results_fold[0],\n",
    "                \"Accuracy\": results_fold[1],\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1-Score\": f1,\n",
    "                \"Specificity\": specificity\n",
    "            }\n",
    "            all_fold_results.append(fold_result)\n",
    "            fold_metrics.append([results_fold[0], results_fold[1], precision, recall, f1, specificity])\n",
    "            \n",
    "            # Mostrar progreso de cada fold\n",
    "            print(f\"Fold {fold} results for {model_name}: Loss={results_fold[0]:.3f}, \"\n",
    "                  f\"Accuracy={results_fold[1]:.3f}, Precision={precision:.3f}, \"\n",
    "                  f\"Recall={recall:.3f}, F1-Score={f1:.3f}, Specificity={specificity:.3f}\")\n",
    "        \n",
    "        # Promediar métricas por fold\n",
    "        avg_metrics = np.mean(fold_metrics, axis=0)\n",
    "        results[model_name].append(avg_metrics)\n",
    "\n",
    "# Crear un DataFrame con los resultados de todos los folds\n",
    "df_results = pd.DataFrame(all_fold_results)\n",
    "\n",
    "# Ajustar decimales a 3 dígitos (puedes cambiarlo según sea necesario)\n",
    "df_results = df_results.round(3)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "df_results.to_csv(\"./ga_model_comparison_results.csv\", index=False)\n",
    "\n",
    "# Mostrar el resumen por arquitectura\n",
    "print(\"\\nSummary per architecture:\")\n",
    "for model_name, metrics in results.items():\n",
    "    avg_metrics = np.mean(metrics, axis=0)\n",
    "    print(f\"{model_name} - Loss: {avg_metrics[0]:.3f}, Accuracy: {avg_metrics[1]:.3f}, \"\n",
    "          f\"Precision: {avg_metrics[2]:.3f}, Recall: {avg_metrics[3]:.3f}, \"\n",
    "          f\"F1-Score: {avg_metrics[4]:.3f}, Specificity: {avg_metrics[5]:.3f}\")\n",
    "\n",
    "# Crear gráfico de barras\n",
    "metrics_names = [\"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Specificity\"]\n",
    "x_labels = list(results.keys())\n",
    "averaged_metrics = np.array([np.mean(metrics, axis=0) for metrics in results.values()])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "bar_width = 0.15\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "for i, metric in enumerate(metrics_names):\n",
    "    ax.bar(x + i * bar_width, averaged_metrics[:, i], bar_width, label=metric)\n",
    "\n",
    "ax.set_xlabel(\"Model Architectures\")\n",
    "ax.set_ylabel(\"Metric Scores\")\n",
    "ax.set_title(\"Comparison of Metrics Across Architectures\")\n",
    "ax.set_xticks(x + (bar_width * (len(metrics_names) - 1)) / 2)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Architecture</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN_LF</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.5348</td>\n",
       "      <td>0.5086</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPECTRO_CNN</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6198</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.8486</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.9380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.7172</td>\n",
       "      <td>0.4322</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.6826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6628</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.5664</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>0.5852</td>\n",
       "      <td>0.5824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Fold    Loss  Accuracy  Precision  Recall  F1-Score  Specificity\n",
       "Architecture                                                                  \n",
       "CNN_LF         3.0  0.6778    0.5348     0.5086  0.9492    0.6606       0.1604\n",
       "SPECTRO_CNN    3.0  0.6198    0.6612     0.8486  0.3546    0.4808       0.9380\n",
       "exp1           3.0  0.6746    0.5638     0.7172  0.4322    0.3936       0.6826\n",
       "exp2           3.0  0.6628    0.5940     0.5664  0.6066    0.5852       0.5824"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby('Architecture').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-Wn8zMQSpva",
    "outputId": "a483f55b-1869-445c-c1c5-0560babd8122"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086797843097632"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = max(best_models, key=lambda x: x['fitness'])\n",
    "best_model['fitness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAVZIg3-bbII",
    "outputId": "1ae23da3-61bf-494f-e982-78c403e5c7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 0, 1, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(best_model['individual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wGVVEFTS844",
    "outputId": "249d7596-ce36-4bee-ac0a-76b799ca1168"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers': [{'type': 'Conv2D',\n",
       "   'filters': 32,\n",
       "   'strides': 1,\n",
       "   'activation': 'relu'},\n",
       "  {'type': 'DepthwiseConv2D',\n",
       "   'filters': 9,\n",
       "   'strides': 1,\n",
       "   'activation': 'leaky_relu'},\n",
       "  {'type': 'Dropout', 'rate': 0.5},\n",
       "  {'type': 'MaxPooling', 'strides': 2},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'Flatten'},\n",
       "  {'type': 'Dropout', 'rate': 0.4},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'BatchNorm'},\n",
       "  {'type': 'DontCare'},\n",
       "  {'type': 'Flatten'},\n",
       "  {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = decode_model_architecture(best_model['individual'])\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5AVvAx2S-5Q",
    "outputId": "edc1d9b4-e9b4-4b58-d0bd-0cebdf300549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = build_tf_model_from_dict(model_dict)\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "en2Yo7OtTAay",
    "outputId": "f3cd2e93-fa33-4f24-f7c4-95727a0fad37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "cnn.save('/drive/MyDrive/NAS/EC_Project/best_model_mu100_gens1000_F0p5_5000mu_autoadapt.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ieouY-Z7TBuV"
   },
   "outputs": [],
   "source": [
    "cnn.save('/drive/MyDrive/NAS/EC_Project/best_model_mu100_gens1000_F0p5_5000mu_autoadapt.keras')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
