{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, DepthwiseConv2D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codificación real de Conv2D: [0, 16, 0, 0]\n",
      "Decodificación Conv2D: {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Dropout: [3, 1, 0, 0]\n",
      "Decodificación Dropout: {'type': 'Dropout', 'rate': 0.3}\n",
      "\n",
      "Codificación real de Dense: [4, 128, 0, 0]\n",
      "Decodificación Dense: {'type': 'Dense', 'units': 128, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Repetition: [8, 3, 5, 0]\n",
      "Decodificación Repetition: {'type': 'Repetition', 'repetition_layers': 3, 'repetition_count': 5}\n"
     ]
    }
   ],
   "source": [
    "# Opciones de decodificación para otros parámetros\n",
    "layer_type_options = {\n",
    "    0: 'Conv2D', \n",
    "    1: 'BatchNorm', \n",
    "    2: 'MaxPooling', \n",
    "    3: 'Dropout', \n",
    "    4: 'Dense', \n",
    "    5: 'Flatten',\n",
    "    6: 'DepthwiseConv2D',  \n",
    "    7: 'DontCare',  \n",
    "    8: 'Repetition'\n",
    "}\n",
    "stride_options = {0: 1, 1: 2}\n",
    "dropout_options = {0: 0.2, 1: 0.3, 2: 0.4, 3: 0.5}\n",
    "activation_options = {0: 'relu', 1: 'leaky_relu', 2: 'sigmoid', 3: 'tanh'}\n",
    "\n",
    "# Función para codificar los parámetros de la capa\n",
    "def encode_layer_params(layer_type_idx, param1=0, param2=0, param3=0):\n",
    "    \"\"\"\n",
    "    Codifica una capa en una lista en función del tipo de capa y sus parámetros.\n",
    "    \n",
    "    layer_type_idx : int : índice del tipo de capa según layer_type_options.\n",
    "    param1         : int/float : filtros, neuronas, capas de repetición, etc.\n",
    "    param2         : int : stride, número de repeticiones, etc.\n",
    "    param3         : int : índice de activación o tasa de dropout.\n",
    "    \"\"\"\n",
    "    return [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "# Función para decodificar los parámetros de la capa\n",
    "def decode_layer_params(encoded_params):\n",
    "    \"\"\"\n",
    "    Decodifica una capa desde su representación codificada en parámetros interpretables.\n",
    "    \n",
    "    encoded_params : list : [tipo de capa, param1, param2, param3].\n",
    "    \"\"\"\n",
    "    layer_type_idx = encoded_params[0]\n",
    "    layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "    \n",
    "    # Decodificar en función del tipo de capa\n",
    "    if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "        filters = max(4, min(encoded_params[1], 32))  # Limitar filtros entre 4 y 32\n",
    "        strides = stride_options.get(encoded_params[2], 1)\n",
    "        activation = activation_options.get(encoded_params[3], 'relu')\n",
    "        return {\n",
    "            'type': layer_type,\n",
    "            'filters': filters,\n",
    "            'strides': strides,\n",
    "            'activation': activation\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {'type': 'BatchNorm'}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        strides = stride_options.get(encoded_params[1], 1)\n",
    "        return {'type': 'MaxPooling', 'strides': strides}\n",
    "    elif layer_type == 'Dropout':\n",
    "        rate = dropout_options.get(encoded_params[1], 0.2)\n",
    "        return {'type': 'Dropout', 'rate': rate}\n",
    "    elif layer_type == 'Dense':\n",
    "        units = max(1, min(encoded_params[1], 512))  # Limitar unidades entre 1 y 512\n",
    "        activation = activation_options.get(encoded_params[2], 'relu')\n",
    "        return {'type': 'Dense', 'units': units, 'activation': activation}\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {'type': 'Flatten'}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            'type': 'Repetition',\n",
    "            'repetition_layers': int(encoded_params[1]),\n",
    "            'repetition_count': int(encoded_params[2])\n",
    "        }\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {'type': \"DontCare\"}\n",
    "\n",
    "    return None\n",
    "\n",
    "# Ejemplos de codificación y decodificación\n",
    "encoded_conv2d = encode_layer_params(0, 16, 0, 0)  # Conv2D con 16 filtros, stride 1 y activación ReLU\n",
    "decoded_conv2d = decode_layer_params(encoded_conv2d)\n",
    "print(f\"\\nCodificación real de Conv2D: {encoded_conv2d}\")\n",
    "print(f\"Decodificación Conv2D: {decoded_conv2d}\")\n",
    "\n",
    "encoded_dropout = encode_layer_params(3, 1)  # Dropout con tasa de 0.3\n",
    "decoded_dropout = decode_layer_params(encoded_dropout)\n",
    "print(f\"\\nCodificación real de Dropout: {encoded_dropout}\")\n",
    "print(f\"Decodificación Dropout: {decoded_dropout}\")\n",
    "\n",
    "encoded_dense = encode_layer_params(4, 128, 0)  # Dense con 128 neuronas y activación ReLU\n",
    "decoded_dense = decode_layer_params(encoded_dense)\n",
    "print(f\"\\nCodificación real de Dense: {encoded_dense}\")\n",
    "print(f\"Decodificación Dense: {decoded_dense}\")\n",
    "\n",
    "encoded_repetition = encode_layer_params(8, 3, 5)  # Repetition para repetir las últimas 3 capas 5 veces\n",
    "decoded_repetition = decode_layer_params(encoded_repetition)\n",
    "print(f\"\\nCodificación real de Repetition: {encoded_repetition}\")\n",
    "print(f\"Decodificación Repetition: {decoded_repetition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete archs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para capas neutrales 'DontCare'\n",
    "class DontCareLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(DontCareLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_model_architecture(model_dict, max_alleles=48):\n",
    "    \"\"\"\n",
    "    Codifica la arquitectura del modelo en una lista de valores con un máximo de `max_alleles`.\n",
    "    Cada capa se codifica en función de sus parámetros.\n",
    "    \"\"\"\n",
    "    encoded_layers = []\n",
    "    total_alleles = 0\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Repetition':  # Codificar capa de repetición\n",
    "            encoded_layer = encode_layer_params(\n",
    "                layer_type_idx=8,  # índice para 'Repetition'\n",
    "                param1=layer.get('repetition_layers', 0),\n",
    "                param2=layer.get('repetition_count', 1)\n",
    "            )\n",
    "        else:\n",
    "            layer_type_idx = next(\n",
    "                key for key, value in layer_type_options.items() if value == layer['type']\n",
    "            )\n",
    "            \n",
    "            # Codificar parámetros específicos de cada tipo de capa\n",
    "            if layer['type'] in ['Conv2D', 'DepthwiseConv2D']:  \n",
    "                # Limitar filtros dentro del rango [4, 32]\n",
    "                param1 = max(4, min(layer.get('filters', 8), 32))  \n",
    "                param2 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                param3 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "            elif layer['type'] == 'Dense':\n",
    "                # Limitar neuronas dentro del rango [1, 512]\n",
    "                param1 = max(1, min(layer.get('units', 1), 512))\n",
    "                param2 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, 0]\n",
    "\n",
    "            elif layer['type'] == 'MaxPooling':\n",
    "                param1 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Dropout':\n",
    "                param1 = next((key for key, value in dropout_options.items() if value == layer.get('rate', 0.2)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'BatchNorm':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Flatten':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'DontCare':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "        # Añadir la codificación de la capa a la lista de alelos\n",
    "        encoded_layers.extend(encoded_layer)\n",
    "        total_alleles += len(encoded_layer)\n",
    "\n",
    "    # Rellenar con 'DontCare' si el total de alelos es menor que `max_alleles`\n",
    "    while total_alleles < max_alleles:\n",
    "        dont_care_encoding = encode_layer_params(7)  # índice de 'DontCare'\n",
    "        encoded_layers.extend(dont_care_encoding)\n",
    "        total_alleles += len(dont_care_encoding)\n",
    "\n",
    "    # Recortar si excede `max_alleles`\n",
    "    final_encoding = encoded_layers[:max_alleles]\n",
    "    print(f\"Final Encoded Model: {final_encoding}\")\n",
    "    \n",
    "    return final_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fixArch(encoded_model, verbose=False):\n",
    "    \"\"\"\n",
    "    Corrige la arquitectura codificada del modelo, asegurando que:\n",
    "    - Se evite la presencia de capas incompatibles después de una capa Flatten.\n",
    "    - En caso de una capa de Repetition, se ajuste el alcance de repetición si no hay suficientes capas anteriores.\n",
    "    \n",
    "    Parameters:\n",
    "        encoded_model (list): Lista codificada de la arquitectura del modelo.\n",
    "        verbose (bool): Si es True, muestra las correcciones realizadas.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista con la arquitectura corregida, truncada a un máximo de 48 alelos.\n",
    "    \"\"\"\n",
    "    \n",
    "    fixed_layers = []  # Lista que almacenará la arquitectura corregida\n",
    "    input_is_flattened = False  # Indicador para saber si ya hay una capa Flatten en el modelo\n",
    "    index = 0  # Índice para recorrer el modelo codificado\n",
    "\n",
    "    # Procesar cada capa en el modelo sin forzar la primera capa a ser específica\n",
    "    while index < len(encoded_model) and len(fixed_layers) < 48:\n",
    "        layer_type = int(encoded_model[index])  # Obtener el tipo de capa actual\n",
    "\n",
    "        # Procesar la capa de Repetition\n",
    "        if layer_type == 8:\n",
    "            repetition_layers = int(encoded_model[index + 1])  # Número de capas a repetir\n",
    "            repetition_count = int(encoded_model[index + 2])  # Cantidad de repeticiones\n",
    "            \n",
    "            # Verificar si hay suficientes capas para la repetición solicitada\n",
    "            actual_layers_to_repeat = min(repetition_layers, len(fixed_layers) // 4)\n",
    "            \n",
    "            if actual_layers_to_repeat != repetition_layers:\n",
    "                if verbose:\n",
    "                    print(f\"Ajustando alcance de repetición de {repetition_layers} a {actual_layers_to_repeat} debido a falta de capas.\")\n",
    "                repetition_layers = actual_layers_to_repeat\n",
    "\n",
    "            # Añadir la capa de repetición sin modificar su estructura\n",
    "            fixed_layers.extend([layer_type, repetition_layers, repetition_count, 0])\n",
    "            index += 4\n",
    "            continue\n",
    "\n",
    "        # Procesar cada tipo de capa normal con sus restricciones\n",
    "        if layer_type == 0:  # Conv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "        \n",
    "        elif layer_type == 6:  # DepthwiseConv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "        \n",
    "        elif layer_type == 2:  # MaxPooling\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                stride_idx = min(max(int(encoded_model[index + 1]), 0), 1)\n",
    "                fixed_layers.extend([layer_type, stride_idx, 0, 0])\n",
    "        \n",
    "        elif layer_type == 3:  # Dropout\n",
    "            rate_idx = min(max(int(encoded_model[index + 1]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, rate_idx, 0, 0])\n",
    "        \n",
    "        elif layer_type == 4:  # Dense\n",
    "            # Limitar el número de neuronas entre 1 y 512\n",
    "            neurons = min(max(int(encoded_model[index + 1]), 1), 512)\n",
    "            activation_idx = min(max(int(encoded_model[index + 2]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, neurons, activation_idx, 0])\n",
    "        \n",
    "        elif layer_type == 1:  # BatchNorm\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "        \n",
    "        elif layer_type == 5:  # Flatten\n",
    "            if len(fixed_layers) < 16:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            elif input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "                input_is_flattened = True  # Marcar que ya hay un Flatten\n",
    "        \n",
    "        elif layer_type == 7:  # DontCare\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        index += 4  # Avanzar al siguiente grupo de parámetros\n",
    "\n",
    "    return fixed_layers[:48]  # Limitar a 48 alelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ejemplo 1 ---\n",
      "Modelo Original: 48 alelos\n",
      "[0, 3, 0, 0, 2, 1, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 1, 1, 0, 6, 1, 1, 0, 5, 0, 0, 0, 4, 3, 2, 0, 4, 1, 3, 0, 4, 1, 2, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 0, 0, 2, 1, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 4, 1, 0, 6, 4, 1, 0, 5, 0, 0, 0, 4, 3, 2, 0, 4, 1, 3, 0, 4, 1, 2, 0]\n",
      "\n",
      "--- Ejemplo 2 ---\n",
      "Modelo Original: 48 alelos\n",
      "[5, 0, 0, 0, 0, 2, 1, 1, 2, 1, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 2, 1, 0, 4, 2, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 4, 3, 3, 0, 7, 0, 0, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[7, 0, 0, 0, 0, 4, 1, 1, 2, 1, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 6, 4, 1, 0, 4, 2, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 4, 3, 3, 0, 7, 0, 0, 0]\n",
      "\n",
      "--- Ejemplo 3 ---\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "Modelo Original: 48 alelos\n",
      "[0, 1, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 2, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 4, 1, 0, 0, 4, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "\n",
      "--- Ejemplo 4 ---\n",
      "Modelo Original: 48 alelos\n",
      "[0, 4, 2, 1, 3, 5, 0, 0, 4, 5, 3, 0, 6, 4, 2, 0, 1, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 4, 3, 1, 0, 7, 0, 0, 0, 4, 1, 2, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 1, 1, 3, 3, 0, 0, 4, 5, 3, 0, 6, 4, 1, 0, 1, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 3, 1, 0, 7, 0, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "--- Ejemplo 5 ---\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "Modelo Original: 48 alelos\n",
      "[0, 2, 1, 0, 8, 2, 3, 0, 5, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 2, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 1, 0, 8, 1, 3, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 4, 1, 0, 0, 4, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar ejemplos de prueba para la función fixArch con arquitecturas de 12 capas (48 valores en total)\n",
    "\n",
    "# Ejemplo 1: Arquitectura sin Flatten antes de Dense y con capas adicionales\n",
    "encoded_model_1 = [\n",
    "    0, 3, 0, 0,    # Conv2D, 32 filtros, stride 1, activación relu\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu (sin Flatten antes)\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    3, 2, 0, 0,    # Dropout, tasa 0.4\n",
    "    0, 1, 1, 0,    # Conv2D, 16 filtros, stride 2, activación relu\n",
    "    6, 1, 1, 0,    # DepthwiseConv2D, 16 filtros, stride 2, activación relu\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    4, 3, 2, 0,    # Dense, 256 neuronas, activación sigmoid\n",
    "    4, 1, 3, 0,    # Dense, 32 neuronas, activación tanh\n",
    "    4, 1, 2, 0     # Dense, 32 neuronas, activación sigmoid\n",
    "]\n",
    "\n",
    "# Ejemplo 2: Arquitectura con Flatten al inicio (inválido) y sin Dense al final\n",
    "encoded_model_2 = [\n",
    "    5, 0, 0, 0,    # Flatten (inválido al inicio)\n",
    "    0, 2, 1, 1,    # Conv2D, 30 filtros, stride 2, activación leaky_relu\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    3, 1, 0, 0,    # Dropout, tasa 0.3\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    0, 1, 0, 0,    # Conv2D, 16 filtros, stride 1, activación relu\n",
    "    6, 2, 1, 0,    # DepthwiseConv2D, 30 filtros, stride 2, activación relu\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu\n",
    "    3, 0, 0, 0,    # Dropout, tasa 0.2\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    4, 3, 3, 0,    # Dense, 256 neuronas, activación tanh\n",
    "    7, 0, 0, 0     # DontCare\n",
    "]\n",
    "\n",
    "# Ejemplo 3: Arquitectura con Repetition y sin Dense al final\n",
    "encoded_model_3 = [\n",
    "    0, 1, 0, 0,    # Conv2D, 16 filtros, stride 1, activación relu\n",
    "    8, 2, 2, 0,    # Repetition, repite las últimas 2 capas 2 veces\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    3, 1, 0, 0,    # Dropout, tasa 0.3\n",
    "    6, 2, 1, 0,    # DepthwiseConv2D, 30 filtros, stride 2, activación relu\n",
    "    0, 3, 0, 1,    # Conv2D, 32 filtros, stride 1, activación leaky_relu\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    3, 2, 0, 0     # Dropout, tasa 0.4\n",
    "]\n",
    "\n",
    "# Ejemplo 4: Arquitectura con parámetros fuera de límite\n",
    "encoded_model_4 = [\n",
    "    0, 4, 2, 1,    # Conv2D, 64 filtros (fuera de límite), stride 2, activación leaky_relu\n",
    "    3, 5, 0, 0,    # Dropout, tasa 0.6 (fuera de límite)\n",
    "    4, 5, 3, 0,    # Dense, 512 neuronas (fuera de límite), activación sigmoid\n",
    "    6, 4, 2, 0,    # DepthwiseConv2D, 64 filtros (fuera de límite), stride 2, activación relu\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    3, 3, 0, 0,    # Dropout, tasa 0.5\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    0, 1, 0, 0,    # Conv2D, 16 filtros, stride 1, activación relu\n",
    "    4, 3, 1, 0,    # Dense, 256 neuronas, activación leaky_relu\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    4, 1, 2, 0     # Dense, 32 neuronas, activación sigmoid\n",
    "]\n",
    "# Ejemplo 5: Arquitectura con capa de Repetition que repite las últimas capas\n",
    "encoded_model_5 = [\n",
    "    0, 2, 1, 0,    # Conv2D, 30 filtros, stride 2, activación relu\n",
    "    8, 2, 3, 0,    # Repetition, repite las últimas 2 capas 3 veces\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    3, 1, 0, 0,    # Dropout, tasa 0.3\n",
    "    6, 2, 1, 0,    # DepthwiseConv2D, 30 filtros, stride 2, activación relu\n",
    "    0, 3, 0, 1,    # Conv2D, 32 filtros, stride 1, activación leaky_relu\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    3, 2, 0, 0     # Dropout, tasa 0.4\n",
    "]\n",
    "\n",
    "# Lista de modelos para probar\n",
    "model_examples = [encoded_model_1, encoded_model_2, encoded_model_3, encoded_model_4, encoded_model_5]\n",
    "\n",
    "# Ejecución de pruebas\n",
    "for i, model in enumerate(model_examples, 1):\n",
    "    print(f\"\\n--- Ejemplo {i} ---\")\n",
    "    fixed_model = fixArch(model, verbose=True)\n",
    "    print(f\"Modelo Original: {len(model)} alelos\\n{model}\") \n",
    "    print(f\"Modelo Corregido: {len(fixed_model)} alelos\\n{fixed_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_model_architecture(encoded_model):\n",
    "    \"\"\"\n",
    "    Decodifica la arquitectura del modelo a partir de la lista codificada de valores (índices),\n",
    "    aplicando las reglas de repetición y asegurando la inclusión de una capa convolucional inicial.\n",
    "    \"\"\"\n",
    "    model_dict = {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}]}  # Inserta Conv2D inicial\n",
    "    index = 0\n",
    "\n",
    "    while index < len(encoded_model):\n",
    "        layer_type = int(encoded_model[index])\n",
    "        param1 = encoded_model[index + 1]\n",
    "        param2 = encoded_model[index + 2]\n",
    "        param3 = encoded_model[index + 3]\n",
    "\n",
    "        if layer_type == 8:  # Capa de Repetition\n",
    "            repetition_layers = int(param1)\n",
    "            repetition_count = int(param2)\n",
    "            # Selecciona solo el grupo válido de capas para la repetición\n",
    "            layers_to_repeat = select_group_for_repetition(model_dict['layers'], repetition_layers)\n",
    "            \n",
    "            if len(layers_to_repeat) > 0:\n",
    "                for _ in range(repetition_count):\n",
    "                    model_dict['layers'].extend(layers_to_repeat)\n",
    "\n",
    "        else:\n",
    "            decoded_layer = {}\n",
    "\n",
    "            if layer_type == 0:  # Conv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'Conv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 6:  # DepthwiseConv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'DepthwiseConv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 2:  # MaxPooling\n",
    "                decoded_layer = {\n",
    "                    'type': 'MaxPooling',\n",
    "                    'strides': stride_options.get(param1, 1)\n",
    "                }\n",
    "            elif layer_type == 3:  # Dropout\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dropout',\n",
    "                    'rate': dropout_options.get(param1, 0.2)\n",
    "                }\n",
    "            elif layer_type == 4:  # Dense\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dense',\n",
    "                    'units': max(1, min(param1, 512)),  # Limita `units` entre 1 y 512\n",
    "                    'activation': activation_options.get(param2, 'relu')\n",
    "                }\n",
    "            elif layer_type == 1:  # BatchNorm\n",
    "                decoded_layer = {'type': 'BatchNorm'}\n",
    "            elif layer_type == 5:  # Flatten\n",
    "                decoded_layer = {'type': 'Flatten'}\n",
    "            elif layer_type == 7:  # DontCare\n",
    "                decoded_layer = {'type': 'DontCare'}\n",
    "\n",
    "            model_dict['layers'].append(decoded_layer)\n",
    "\n",
    "        index += 4\n",
    "\n",
    "    # Asegura que haya una capa Flatten antes de la capa Dense final, si no ya existe una Flatten\n",
    "    if model_dict['layers'][-1]['type'] != 'Flatten':\n",
    "        model_dict['layers'].append({'type': 'Flatten'})\n",
    "        \n",
    "    # Añade la capa Dense final obligatoria\n",
    "    model_dict['layers'].append({'type': 'Dense', 'units': 1, 'activation': 'sigmoid'})\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "def select_group_for_repetition(layers, repetition_layers):\n",
    "    \"\"\"\n",
    "    Selecciona el primer grupo válido para repetición en función de las reglas de compatibilidad.\n",
    "\n",
    "    Parameters:\n",
    "        layers (list): Lista de capas ya procesadas, donde cada capa es un diccionario.\n",
    "        repetition_layers (int): Número de capas hacia atrás para considerar en la repetición.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de capas compatibles para repetición.\n",
    "    \"\"\"\n",
    "    valid_layers = []\n",
    "    group_type = None\n",
    "\n",
    "    # Retrocede desde el final de `layers` para encontrar el grupo válido\n",
    "    for layer in reversed(layers[-repetition_layers:]):\n",
    "        if group_type is None:\n",
    "            # Determina el tipo de grupo\n",
    "            if layer['type'] in ['Flatten', 'Dense']:\n",
    "                group_type = 'dense'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling']:\n",
    "                group_type = 'convolutional'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['BatchNorm', 'DontCare']:  # BatchNorm y DontCare son compatibles con ambos grupos\n",
    "                valid_layers.insert(0, layer)\n",
    "        else:\n",
    "            # Agrega solo capas compatibles con el grupo seleccionado\n",
    "            if group_type == 'dense' and layer['type'] in ['Flatten', 'Dense', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif group_type == 'convolutional' and layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "\n",
    "    return valid_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modelo 1 Decodificado ---\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'BatchNorm'}, {'type': 'Dropout', 'rate': 0.4}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 3, 'activation': 'sigmoid'}, {'type': 'Dense', 'units': 1, 'activation': 'tanh'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "--- Modelo 2 Decodificado ---\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'leaky_relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'Dense', 'units': 3, 'activation': 'tanh'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "\n",
      "--- Modelo 3 Decodificado ---\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'Dropout', 'rate': 0.4}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "--- Modelo 4 Decodificado ---\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'leaky_relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 5, 'activation': 'tanh'}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Flatten'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 3, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "\n",
      "--- Modelo 5 Decodificado ---\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'Dropout', 'rate': 0.4}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "--- Todos los Modelos Decodificados ---\n",
      "Modelo 1 Decodificado: {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'BatchNorm'}, {'type': 'Dropout', 'rate': 0.4}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 3, 'activation': 'sigmoid'}, {'type': 'Dense', 'units': 1, 'activation': 'tanh'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "Modelo 2 Decodificado: {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'leaky_relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'Dense', 'units': 3, 'activation': 'tanh'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "Modelo 3 Decodificado: {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'Dropout', 'rate': 0.4}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "Modelo 4 Decodificado: {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'leaky_relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 5, 'activation': 'tanh'}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Flatten'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 3, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "Modelo 5 Decodificado: {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'DepthwiseConv2D', 'filters': 4, 'strides': 2, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 4, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 2, 'activation': 'leaky_relu'}, {'type': 'DontCare'}, {'type': 'Dropout', 'rate': 0.4}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n"
     ]
    }
   ],
   "source": [
    "# Reparar cada ejemplo con fixArch y luego decodificar con decode_model_architecture\n",
    "repaired_and_decoded_models = []\n",
    "\n",
    "for i, encoded_model in enumerate([encoded_model_1, encoded_model_2, encoded_model_3, encoded_model_4, encoded_model_5], 1):\n",
    "    # Reparar el modelo\n",
    "    repaired_model = fixArch(encoded_model, verbose=True)\n",
    "    # Decodificar el modelo reparado\n",
    "    decoded_model = decode_model_architecture(repaired_model)\n",
    "    # Guardar el modelo decodificado\n",
    "    repaired_and_decoded_models.append(decoded_model)\n",
    "    print(f\"\\n--- Modelo {i} Decodificado ---\")\n",
    "    print(decoded_model)\n",
    "\n",
    "# Opcional: Mostrar todos los modelos decodificados juntos\n",
    "print(\"\\n--- Todos los Modelos Decodificados ---\")\n",
    "for i, model in enumerate(repaired_and_decoded_models, 1):\n",
    "    print(f\"Modelo {i} Decodificado:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, DepthwiseConv2D\n",
    "\n",
    "\n",
    "\n",
    "def build_tf_model_from_dict(model_dict, input_shape=(28, 28, 3)):\n",
    "    \"\"\"\n",
    "    Construye un modelo de TensorFlow a partir de un diccionario JSON expandido.\n",
    "    \"\"\"\n",
    "    print(\"\\nConstruyendo el modelo en TensorFlow desde el JSON expandido...\")\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Conv2D':\n",
    "            model.add(Conv2D(filters=layer['filters'], kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "        \n",
    "        elif layer['type'] == 'DepthwiseConv2D':\n",
    "            model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "        \n",
    "        elif layer['type'] == 'BatchNorm':\n",
    "            model.add(BatchNormalization())\n",
    "        \n",
    "        elif layer['type'] == 'MaxPooling':\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=int(layer['strides']), padding='same'))\n",
    "        \n",
    "        elif layer['type'] == 'Flatten':\n",
    "            model.add(Flatten())\n",
    "        \n",
    "        elif layer['type'] == 'Dense':\n",
    "            model.add(Dense(units=int(layer['units']), activation=layer['activation']))\n",
    "        \n",
    "        elif layer['type'] == 'Dropout':\n",
    "            model.add(Dropout(rate=layer['rate']))\n",
    "        \n",
    "        elif layer['type'] == 'DontCare':\n",
    "            model.add(DontCareLayer())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: build_CNN_LF_model\n",
    "model_CNN_LF = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 30, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},  # Revisar 'filters'\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.3},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 2: build_reduced_model\n",
    "model_reduced = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 3: build_Spectro_CNN_model\n",
    "model_spectro_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2}, \n",
    "         \n",
    "         \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "         {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "         {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "    {\"type\":\"Flatten\"},\n",
    "    {\"type\":\"Dense\",\"units\":256,\"activation\":\"relu\"},   \n",
    "    {\"type\":\"Dropout\",\"rate\":0.5},\n",
    "                \n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo corregido: build_Spectro_CNN_model con capas de repetición\n",
    "model_spectro_CNN_with_repetition = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2}, \n",
    "        # Aquí indicamos que las siguientes 10 capas (5 Conv2D + 5 BatchNorm) se repiten 10 veces\n",
    "        {\"type\": \"Repetition\", \"repetition_layers\": 3, \"repetition_count\": 31},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Ejemplo 4: Simple Conv2D model\n",
    "model_simple_conv = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 5: Simple Dense model\n",
    "model_dense_only = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 6: Small CNN model with Dropout\n",
    "model_small_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 7: Deep CNN model\n",
    "model_deep_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 10, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 8: Basic Dense with Dropout\n",
    "model_dense_dropout = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "model_with_depthwise = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"DepthwiseConv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"sigmoid\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_pipeline(model_dict, input_shape=(28, 28, 3), verbose=False):\n",
    "    \"\"\"\n",
    "    Procesa el pipeline de creación del modelo desde el JSON inicial hasta el modelo de TensorFlow.\n",
    "    \n",
    "    Parameters:\n",
    "        model_dict (dict): Modelo en formato JSON.\n",
    "        input_shape (tuple): Forma de entrada para el modelo.\n",
    "        verbose (bool): Si es True, muestra los detalles de cada etapa del proceso.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: El modelo de TensorFlow construido a partir del JSON procesado.\n",
    "    \"\"\"\n",
    "    # Codificar el modelo\n",
    "    encoded_model = encode_model_architecture(model_dict, max_alleles=48)\n",
    "    if verbose:\n",
    "        print(f\"\\nModelo codificado: {encoded_model}\")\n",
    "\n",
    "    # Reparar el modelo codificado\n",
    "    fixed_model = fixArch(encoded_model, verbose=verbose)\n",
    "    if verbose:\n",
    "        print(f\"\\nModelo codificado y reparado: {fixed_model}\")\n",
    "\n",
    "    # Decodificar el modelo reparado\n",
    "    decoded_model = decode_model_architecture(fixed_model)\n",
    "    if verbose:\n",
    "        print(f\"\\nModelo decodificado:\\n{decoded_model}\")\n",
    "\n",
    "    # Construir el modelo de TensorFlow\n",
    "    tf_model = build_tf_model_from_dict(decoded_model, input_shape=input_shape)\n",
    "    if verbose:\n",
    "        print(\"\\nModelo de TensorFlow construido.\")\n",
    "        tf_model.summary()\n",
    "    \n",
    "    return tf_model\n",
    "\n",
    "\n",
    "# Ejemplo de uso con un modelo y verbose activado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifications:\n",
      "\n",
      "Model 1: CNN_LF\n",
      "Final Encoded Model: [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "Modelo codificado: [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 30, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 30)        8670      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 30)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 30)       120       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 30)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 16)        4336      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,305\n",
      "Trainable params: 215,213\n",
      "Non-trainable params: 92\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 2: Reduced\n",
      "Final Encoded Model: [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'leaky_relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                200736    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " dont_care_layer (DontCareLa  (None, 1)                0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " dont_care_layer_1 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_2 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_3 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,675\n",
      "Trainable params: 207,563\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 3: Spectro CNN\n",
      "Final Encoded Model: [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,417\n",
      "Trainable params: 72,161\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 3.5 Spectro CNN with repetition\n",
      "Final Encoded Model: [0, 32, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 8, 3, 31, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 3, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 32, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 8, 3, 31, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 3, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 32, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 8, 3, 31, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 3, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 14, 14, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 7, 7, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 4, 4, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 2, 2, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " dont_care_layer_4 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_5 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_6 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_7 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,635\n",
      "Trainable params: 307,587\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 4: Simple Conv2D\n",
      "Final Encoded Model: [0, 16, 0, 0, 5, 0, 0, 0, 4, 128, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 16, 0, 0, 5, 0, 0, 0, 4, 128, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 16, 0, 0, 7, 0, 0, 0, 4, 128, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_47 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 16)        4624      \n",
      "                                                                 \n",
      " dont_care_layer_8 (DontCare  (None, 28, 28, 16)       0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 28, 28, 128)       2176      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 28, 28, 1)         129       \n",
      "                                                                 \n",
      " dont_care_layer_9 (DontCare  (None, 28, 28, 1)        0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_10 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_11 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_12 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_13 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_14 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_15 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_16 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 785       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,610\n",
      "Trainable params: 8,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 5: Dense Only\n",
      "Final Encoded Model: [5, 0, 0, 0, 4, 256, 0, 0, 4, 128, 0, 0, 4, 256, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [5, 0, 0, 0, 4, 256, 0, 0, 4, 128, 0, 0, 4, 256, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [7, 0, 0, 0, 4, 256, 0, 0, 4, 128, 0, 0, 4, 256, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " dont_care_layer_17 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 28, 28, 256)       8448      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 28, 28, 128)       32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 28, 28, 256)       33024     \n",
      "                                                                 \n",
      " dont_care_layer_18 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_19 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_20 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_21 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_22 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_23 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_24 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_25 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 200704)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 200705    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,969\n",
      "Trainable params: 275,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 6: Small CNN\n",
      "Final Encoded Model: [0, 8, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 8, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 8, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 4, 32, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_50 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 28, 28, 8)         2312      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 14, 14, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dont_care_layer_26 (DontCar  (None, 14, 14, 8)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 14, 14, 32)        288       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 14, 14, 1)         33        \n",
      "                                                                 \n",
      " dont_care_layer_27 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_28 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_29 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_30 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_31 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_32 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 196)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 197       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,726\n",
      "Trainable params: 3,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 7: Deep CNN\n",
      "Final Encoded Model: [0, 32, 0, 0, 0, 32, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 10, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 32, 0, 0, 0, 32, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 10, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 32, 0, 0, 0, 32, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 4, 32, 0, 0, 4, 10, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 10, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dont_care_layer_33 (DontCar  (None, 14, 14, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 14, 14, 32)        1056      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 14, 14, 10)        330       \n",
      "                                                                 \n",
      " dont_care_layer_34 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_35 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_36 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_37 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_38 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_39 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1960)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 1961      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,739\n",
      "Trainable params: 22,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 8: Dense with Dropout\n",
      "Final Encoded Model: [5, 0, 0, 0, 4, 128, 0, 0, 3, 3, 0, 0, 4, 32, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [5, 0, 0, 0, 4, 128, 0, 0, 3, 3, 0, 0, 4, 32, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [7, 0, 0, 0, 4, 128, 0, 0, 3, 3, 0, 0, 4, 32, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 32, 'activation': 'tanh'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " dont_care_layer_40 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 28, 28, 128)       4224      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 28, 28, 32)        4128      \n",
      "                                                                 \n",
      " dont_care_layer_41 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_42 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_43 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_44 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_45 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_46 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_47 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_48 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 25089     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,337\n",
      "Trainable params: 34,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model with DepthwiseConv2D\n",
      "Final Encoded Model: [6, 16, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 128, 2, 0, 4, 1, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verificación de los modelos\n",
    "print(\"Verifications:\")\n",
    "\n",
    "print(\"\\nModel 1: CNN_LF\")\n",
    "tf_model_example = process_model_pipeline(model_CNN_LF, verbose=True)  # Ejemplo 1\n",
    "\n",
    "print(\"\\nModel 2: Reduced\")\n",
    "tf_model_example = process_model_pipeline(model_reduced, verbose=True)  # Ejemplo 2\n",
    "\n",
    "print(\"\\nModel 3: Spectro CNN\")\n",
    "tf_model_example = process_model_pipeline(model_spectro_CNN, verbose=True)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 3.5 Spectro CNN with repetition\")\n",
    "tf_model_example = process_model_pipeline(model_spectro_CNN_with_repetition, verbose=True)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 4: Simple Conv2D\")\n",
    "tf_model_example = process_model_pipeline(model_simple_conv, verbose=True)  # Ejemplo 4\n",
    "\n",
    "print(\"\\nModel 5: Dense Only\")\n",
    "tf_model_example = process_model_pipeline(model_dense_only, verbose=True)  # Ejemplo 5\n",
    "\n",
    "print(\"\\nModel 6: Small CNN\")\n",
    "tf_model_example = process_model_pipeline(model_small_CNN, verbose=True)  # Ejemplo 6\n",
    "\n",
    "print(\"\\nModel 7: Deep CNN\")\n",
    "tf_model_example = process_model_pipeline(model_deep_CNN, verbose=True)  # Ejemplo 7\n",
    "\n",
    "print(\"\\nModel 8: Dense with Dropout\")\n",
    "tf_model_example = process_model_pipeline(model_dense_dropout, verbose=True)  # Ejemplo 8\n",
    "\n",
    "print(\"\\nModel with DepthwiseConv2D\")\n",
    "tf_model_example = process_model_pipeline(model_with_depthwise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing random generated architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Encoded Model: [2, 1, 0, 0, 0, 13, 1, 2, 2, 1, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 8, 2, 1, 0, 4, 13, 1, 0, 0, 7, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 4, 86, 0, 0, 0, 8, 1, 2]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 3, 2, 0, 8, 2, 1, 0, 2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 4, 118, 0, 0, 5, 0, 0, 0, 4, 19, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 6, 5, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 4, 127, 1, 0, 6, 7, 1, 2, 3, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 2, 1, 0, 6, 10, 0, 2, 5, 0, 0, 0, 8, 1, 2, 0, 4, 27, 1, 0, 4, 27, 2, 0, 4, 5, 3, 0, 8, 2, 2, 0, 3, 1, 0, 0, 5, 0, 0, 0, 8, 2, 1, 0, 8, 1, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 13, 1, 0, 3, 0, 0, 0, 6, 11, 1, 2, 0, 9, 1, 0, 7, 0, 0, 0, 3, 0, 0, 0, 3, 2, 0, 0, 2, 1, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 6, 7, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 3, 1, 0, 0, 4, 60, 3, 0, 8, 3, 1, 0, 7, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 0, 14, 1, 3, 4, 27, 0, 0, 6, 12, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 13, 1, 3, 0, 14, 0, 3, 8, 2, 1, 0, 8, 3, 2, 0, 6, 6, 1, 0, 6, 10, 0, 3, 3, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 6, 5, 0, 3, 8, 3, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 12, 0, 2, 2, 1, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 4, 49, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 9, 1, 1, 5, 0, 0, 0, 1, 0, 0, 0, 8, 3, 1, 0, 3, 3, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 7, 0, 0, 0, 4, 87, 1, 0, 7, 0, 0, 0, 8, 1, 2, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 2, 0, 7, 0, 0, 0, 6, 13, 1, 3, 6, 7, 0, 0, 8, 2, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 4, 106, 2, 0, 6, 5, 0, 1, 4, 49, 2, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 14, 0, 3, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 4, 122, 2, 0, 0, 9, 0, 3, 6, 7, 1, 3, 8, 1, 1, 0, 3, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 1, 2, 0, 6, 15, 0, 3, 1, 0, 0, 0, 8, 1, 1, 0, 6, 9, 0, 0, 7, 0, 0, 0, 0, 10, 1, 2, 7, 0, 0, 0, 0, 4, 0, 1, 6, 12, 0, 0, 8, 3, 1, 0, 6, 10, 0, 2]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 58, 2, 0, 4, 27, 1, 0, 6, 15, 1, 2, 8, 2, 2, 0, 1, 0, 0, 0, 6, 15, 1, 1, 1, 0, 0, 0, 3, 2, 0, 0, 8, 3, 1, 0, 4, 9, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 33, 0, 0, 4, 92, 0, 0, 6, 7, 0, 2, 7, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 1, 0, 0, 0, 6, 14, 0, 3, 8, 3, 2, 0, 5, 0, 0, 0, 0, 13, 0, 0, 8, 3, 1, 0, 0, 6, 0, 3, 5, 0, 0, 0, 6, 8, 1, 1, 4, 88, 2, 0, 4, 31, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 4, 0, 1, 7, 0, 0, 0, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 6, 13, 0, 3, 2, 1, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 7, 1, 3, 6, 15, 0, 3, 4, 91, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 1, 0, 0, 0, 11, 0, 2, 6, 4, 0, 2, 3, 1, 0, 0, 0, 8, 1, 3, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 1, 0, 3, 0, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 0, 11, 0, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 8, 3, 1, 0, 1, 0, 0, 0, 8, 1, 2, 0, 4, 25, 2, 0, 7, 0, 0, 0, 3, 0, 0, 0, 4, 54, 2, 0, 4, 71, 0, 0, 3, 1, 0, 0, 6, 8, 1, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 6, 14, 1, 1, 7, 0, 0, 0, 4, 105, 3, 0, 8, 3, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 8, 2, 2, 0, 4, 106, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 0, 7, 0, 3, 7, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 0, 6, 0, 3, 3, 1, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 0, 5, 0, 1, 0, 7, 1, 1, 4, 36, 1, 0, 5, 0, 0, 0, 3, 2, 0, 0, 8, 2, 2, 0, 4, 51, 0, 0, 4, 41, 3, 0, 2, 1, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 8, 1, 0, 4, 49, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 6, 6, 1, 3, 4, 125, 2, 0, 2, 1, 0, 0, 6, 10, 0, 0, 3, 2, 0, 0, 4, 112, 0, 0, 4, 76, 0, 0, 4, 60, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 1, 0, 0, 2, 1, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 4, 116, 0, 0, 6, 14, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 6, 5, 0, 2, 8, 2, 2, 0, 4, 2, 2, 0, 4, 11, 2, 0, 5, 0, 0, 0, 3, 1, 0, 0, 4, 122, 2, 0, 2, 1, 0, 0, 3, 0, 0, 0, 3, 1, 0, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 13, 0, 3, 8, 2, 1, 0, 8, 2, 2, 0, 8, 2, 2, 0, 2, 0, 0, 0, 6, 10, 0, 3, 3, 0, 0, 0, 7, 0, 0, 0, 8, 1, 1, 0, 5, 0, 0, 0, 0, 4, 0, 2, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 2, 0, 0, 0, 4, 5, 3, 0, 0, 10, 0, 1, 6, 4, 1, 2, 3, 1, 0, 0, 6, 14, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 8, 1, 1, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 73, 3, 0, 5, 0, 0, 0, 4, 67, 3, 0, 6, 8, 0, 3, 7, 0, 0, 0, 6, 12, 1, 2, 8, 1, 1, 0, 0, 8, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 3, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 3, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 4, 75, 3, 0, 2, 1, 0, 0, 6, 15, 1, 1, 3, 0, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 3, 0, 0, 0, 0, 14, 0, 0, 0, 16, 0, 2, 8, 1, 1, 0, 8, 3, 1, 0, 5, 0, 0, 0, 4, 69, 3, 0, 4, 10, 0, 0, 4, 68, 1, 0, 7, 0, 0, 0, 6, 5, 0, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 24, 2, 0, 2, 1, 0, 0, 3, 0, 0, 0, 0, 15, 1, 3, 8, 1, 1, 0, 6, 11, 0, 1, 4, 13, 0, 0, 3, 2, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 2, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 8, 1, 2, 0, 4, 121, 1, 0, 2, 1, 0, 0, 3, 0, 0, 0, 4, 54, 0, 0, 2, 1, 0, 0, 3, 2, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 3, 3, 2, 0, 0, 8, 1, 2, 0, 5, 0, 0, 0, 6, 16, 0, 1, 7, 0, 0, 0, 6, 14, 0, 3, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 8, 2, 2, 0, 3, 3, 0, 0, 0, 14, 1, 2, 7, 0, 0, 0, 6, 6, 1, 1, 0, 4, 0, 1, 0, 15, 1, 1, 5, 0, 0, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 15, 1, 2, 1, 0, 0, 0, 3, 0, 0, 0, 4, 104, 1, 0, 0, 15, 1, 3, 3, 0, 0, 0, 4, 53, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 4, 93, 2, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 1, 1, 0, 3, 2, 0, 0, 8, 1, 1, 0, 0, 6, 0, 3, 7, 0, 0, 0, 1, 0, 0, 0, 6, 10, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 8, 1, 2, 0, 6, 9, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 3, 0, 0, 3, 2, 0, 0, 4, 110, 3, 0, 3, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 6, 6, 1, 2, 3, 2, 0, 0, 1, 0, 0, 0, 6, 15, 0, 3, 4, 57, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 13, 1, 2, 6, 13, 1, 2, 7, 0, 0, 0, 8, 3, 1, 0, 4, 106, 2, 0, 8, 1, 2, 0, 2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 8, 2, 2, 0, 6, 12, 0, 0, 4, 41, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 0, 4, 0, 2, 3, 2, 0, 0, 4, 101, 3, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 4, 71, 0, 0, 0, 5, 1, 2, 6, 16, 0, 2, 6, 5, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 3, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 8, 1, 2, 0, 0, 7, 0, 3, 3, 3, 0, 0, 0, 4, 1, 0, 1, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 9, 1, 3, 6, 16, 0, 1, 7, 0, 0, 0, 6, 11, 1, 2, 7, 0, 0, 0, 7, 0, 0, 0, 4, 18, 1, 0, 4, 21, 0, 0, 2, 1, 0, 0, 4, 54, 0, 0, 2, 0, 0, 0, 0, 11, 0, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 10, 0, 3, 0, 8, 0, 1, 7, 0, 0, 0, 1, 0, 0, 0, 4, 50, 1, 0, 1, 0, 0, 0, 6, 16, 0, 0, 1, 0, 0, 0, 8, 2, 2, 0, 2, 0, 0, 0, 4, 33, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 8, 0, 1, 5, 0, 0, 0, 6, 10, 1, 0, 2, 1, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 6, 12, 1, 3, 7, 0, 0, 0, 6, 15, 0, 3, 2, 0, 0, 0, 6, 15, 1, 0, 4, 108, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 4, 85, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 5, 0, 0, 0, 6, 13, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 11, 1, 0, 0, 12, 0, 1, 4, 113, 2, 0, 8, 3, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 95, 2, 0, 3, 0, 0, 0, 2, 1, 0, 0, 6, 10, 1, 2, 5, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 2, 1, 0, 0, 8, 1, 1, 0, 3, 0, 0, 0, 6, 16, 0, 2, 8, 2, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 15, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 8, 1, 1, 0, 8, 2, 1, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 6, 8, 1, 0, 4, 48, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 5, 0, 3, 6, 11, 1, 0, 3, 2, 0, 0, 5, 0, 0, 0, 4, 121, 2, 0, 4, 116, 1, 0, 7, 0, 0, 0, 0, 15, 1, 1, 8, 1, 1, 0, 6, 7, 1, 2, 5, 0, 0, 0, 6, 11, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 8, 1, 2, 0, 6, 8, 0, 1, 4, 125, 2, 0, 7, 0, 0, 0, 8, 3, 1, 0, 0, 12, 1, 1, 5, 0, 0, 0, 8, 2, 2, 0, 7, 0, 0, 0, 2, 0, 0, 0, 8, 2, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 33, 3, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 2, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 8, 3, 1, 0, 4, 49, 2, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 0, 15, 1, 0, 0, 7, 1, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 6, 1, 1, 0, 7, 1, 1, 6, 10, 1, 0, 4, 45, 2, 0, 3, 3, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 10, 0, 3, 4, 90, 0, 0, 5, 0, 0, 0, 6, 8, 0, 3, 3, 3, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 4, 128, 1, 0, 6, 5, 0, 0, 5, 0, 0, 0, 8, 1, 2, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 0, 16, 0, 2, 3, 3, 0, 0, 4, 5, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 6, 8, 1, 0, 4, 51, 2, 0, 4, 30, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 6, 8, 1, 0, 3, 0, 0, 0, 6, 14, 1, 1, 2, 0, 0, 0, 0, 6, 1, 1, 7, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 6, 13, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 0, 11, 1, 2, 5, 0, 0, 0, 5, 0, 0, 0, 8, 2, 2, 0, 2, 0, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 2, 0, 0, 0, 8, 0, 2, 1, 0, 0, 0, 6, 10, 0, 2, 6, 4, 0, 0, 7, 0, 0, 0, 6, 4, 1, 0, 2, 1, 0, 0, 7, 0, 0, 0, 0, 13, 1, 1, 4, 125, 3, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 6, 4, 1, 0, 0, 9, 0, 1, 6, 5, 0, 2, 4, 50, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 6, 11, 0, 0, 2, 1, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 15, 1, 3, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 34, 2, 0, 7, 0, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 4, 42, 0, 0, 0, 8, 0, 1, 7, 0, 0, 0, 8, 1, 2, 0, 4, 100, 0, 0, 1, 0, 0, 0, 0, 4, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 56, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 1, 0, 0, 4, 81, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 6, 6, 0, 0, 3, 2, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 6, 15, 0, 0, 7, 0, 0, 0, 0, 10, 0, 2]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 13, 0, 2, 0, 9, 1, 2, 0, 9, 1, 1, 2, 0, 0, 0, 8, 2, 1, 0, 8, 1, 1, 0, 7, 0, 0, 0, 0, 12, 1, 3, 5, 0, 0, 0, 8, 3, 1, 0, 2, 0, 0, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 6, 14, 1, 1, 3, 1, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 0, 14, 0, 3, 4, 42, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 8, 0, 3, 4, 25, 3, 0, 5, 0, 0, 0, 6, 13, 0, 2, 7, 0, 0, 0, 3, 0, 0, 0, 8, 1, 1, 0, 3, 2, 0, 0, 0, 7, 1, 1, 3, 3, 0, 0, 2, 0, 0, 0, 0, 16, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 8, 3, 1, 0, 3, 2, 0, 0, 7, 0, 0, 0, 0, 14, 0, 1, 5, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 0, 8, 0, 2, 0, 8, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 2, 0, 0, 0, 6, 16, 0, 1, 4, 56, 2, 0, 2, 1, 0, 0, 4, 94, 3, 0, 2, 1, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 2, 0, 0, 0, 7, 0, 0, 0, 0, 9, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 6, 11, 1, 3, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 4, 126, 2, 0, 0, 16, 1, 3, 2, 1, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 11, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 0, 14, 1, 0, 6, 15, 1, 1, 4, 59, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 15, 0, 3, 0, 7, 0, 1, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 39, 3, 0, 5, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 0, 10, 0, 1, 2, 1, 0, 0, 3, 0, 0, 0, 4, 81, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 8, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 3, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 3, 2, 0, 0, 4, 121, 2, 0, 0, 15, 0, 3, 2, 0, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 0, 6, 7, 1, 1, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 6, 1, 0, 8, 3, 1, 0, 7, 0, 0, 0, 4, 101, 1, 0, 1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 6, 16, 1, 3, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 10, 0, 0, 7, 0, 0, 0, 4, 30, 1, 0, 8, 1, 1, 0, 7, 0, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 4, 2, 2, 0, 0, 14, 1, 0, 2, 0, 0, 0, 4, 110, 1, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 12, 0, 2, 6, 4, 0, 1, 7, 0, 0, 0, 0, 4, 0, 1, 2, 1, 0, 0, 1, 0, 0, 0, 6, 8, 0, 2, 6, 4, 0, 0, 4, 100, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 14, 1, 2, 3, 2, 0, 0, 6, 14, 0, 3, 6, 13, 0, 3, 6, 10, 1, 2, 2, 1, 0, 0, 4, 79, 2, 0, 7, 0, 0, 0, 6, 5, 1, 3, 1, 0, 0, 0, 4, 9, 2, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 4, 1, 1, 4, 85, 0, 0, 1, 0, 0, 0, 0, 8, 1, 1, 6, 16, 0, 2, 6, 6, 0, 1, 0, 11, 1, 1, 1, 0, 0, 0, 0, 12, 0, 3, 3, 1, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 8, 2, 2, 0, 6, 8, 0, 1, 5, 0, 0, 0, 6, 5, 1, 2, 0, 13, 0, 3, 6, 7, 1, 1, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 2, 0, 0, 2, 1, 0, 0, 4, 45, 1, 0, 1, 0, 0, 0, 5, 0, 0, 0, 6, 15, 0, 0, 0, 8, 1, 1, 8, 2, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0, 7, 0, 0, 0, 0, 12, 0, 1, 6, 6, 1, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 11, 1, 0, 8, 2, 2, 0, 0, 11, 0, 1, 3, 2, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 3, 1, 0, 0, 4, 16, 3, 0, 3, 2, 0, 0, 1, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0, 3, 3, 0, 0, 6, 4, 0, 2, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 8, 1, 2, 4, 8, 2, 0, 4, 64, 2, 0, 4, 63, 0, 0, 6, 11, 1, 1, 7, 0, 0, 0, 4, 64, 0, 0, 6, 6, 0, 2, 3, 2, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 103, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 9, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 0, 16, 0, 3, 0, 7, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 119, 2, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 2, 2, 0, 7, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 6, 11, 1, 2, 4, 99, 2, 0, 6, 10, 1, 3, 7, 0, 0, 0, 8, 3, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 3, 2, 0, 0, 8, 1, 3, 0, 9, 0, 1, 0, 4, 1, 0, 4, 105, 3, 0, 7, 0, 0, 0, 4, 23, 3, 0, 3, 1, 0, 0, 1, 0, 0, 0, 4, 63, 2, 0, 3, 2, 0, 0, 0, 8, 0, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 12, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 4, 105, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 4, 61, 1, 0, 4, 96, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 0, 8, 1, 1, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 3, 0, 0, 8, 2, 2, 0, 8, 1, 2, 0, 8, 1, 2, 0, 0, 6, 1, 2, 8, 3, 2, 0, 2, 1, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 0, 15, 0, 0, 6, 10, 1, 1, 4, 61, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 51, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 8, 3, 1, 0, 6, 14, 1, 1, 8, 1, 1, 0, 1, 0, 0, 0, 4, 5, 0, 0, 4, 11, 2, 0, 5, 0, 0, 0, 2, 1, 0, 0, 4, 89, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 3, 2, 0, 0, 3, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 0, 15, 1, 3, 3, 3, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 0, 11, 0, 1, 1, 0, 0, 0, 4, 63, 0, 0, 0, 15, 1, 3, 4, 96, 3, 0, 0, 14, 1, 3, 7, 0, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 2, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 118, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0, 4, 62, 1, 0, 0, 11, 1, 1, 1, 0, 0, 0, 6, 9, 1, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 64, 2, 0, 7, 0, 0, 0, 8, 1, 1, 0, 0, 16, 1, 2, 3, 3, 0, 0, 2, 0, 0, 0, 6, 15, 1, 3, 0, 16, 0, 3, 0, 5, 0, 2, 4, 107, 3, 0, 3, 1, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 6, 16, 1, 3, 6, 10, 0, 1, 4, 95, 1, 0, 8, 1, 2, 0, 0, 4, 1, 3, 0, 13, 1, 2, 6, 8, 0, 2, 4, 31, 0, 0, 6, 5, 1, 3, 4, 16, 0, 0, 6, 8, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 7, 0, 0, 0, 6, 12, 0, 3, 7, 0, 0, 0, 8, 2, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 6, 12, 0, 2, 3, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 6, 7, 0, 1, 5, 0, 0, 0, 6, 13, 1, 0, 1, 0, 0, 0, 8, 2, 1, 0, 3, 0, 0, 0, 6, 14, 0, 3, 8, 1, 2, 0, 0, 9, 1, 2, 1, 0, 0, 0, 8, 3, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 100, 2, 0, 8, 3, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 6, 4, 0, 1, 6, 5, 1, 3, 1, 0, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 1, 0, 0, 8, 2, 1, 0, 1, 0, 0, 0, 4, 3, 1, 0, 7, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 6, 10, 0, 3, 4, 95, 2, 0, 3, 1, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 3, 1, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 4, 115, 0, 0, 6, 14, 0, 1, 1, 0, 0, 0, 0, 7, 1, 1, 5, 0, 0, 0, 0, 4, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 7, 0, 0, 0, 8, 3, 1, 0, 3, 1, 0, 0, 8, 1, 2, 0, 6, 13, 1, 1, 8, 3, 1, 0, 0, 9, 1, 1, 3, 1, 0, 0, 4, 10, 3, 0, 2, 0, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 8, 1, 0, 2, 1, 0, 0, 6, 5, 1, 0, 4, 13, 2, 0, 5, 0, 0, 0, 0, 16, 1, 2, 3, 1, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 0, 8, 1, 3, 7, 0, 0, 0, 5, 0, 0, 0, 4, 34, 3, 0, 1, 0, 0, 0, 4, 52, 0, 0, 1, 0, 0, 0, 0, 8, 1, 3, 0, 15, 0, 2, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 3, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 0, 11, 0, 3, 1, 0, 0, 0, 2, 1, 0, 0, 8, 1, 2, 0, 8, 3, 2, 0, 6, 11, 0, 3, 2, 1, 0, 0, 6, 5, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 4, 0, 2, 5, 0, 0, 0, 7, 0, 0, 0, 6, 8, 0, 3, 0, 16, 0, 2, 5, 0, 0, 0, 5, 0, 0, 0, 4, 71, 3, 0, 5, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 10, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 6, 16, 0, 1, 2, 1, 0, 0, 0, 10, 1, 3, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 4, 32, 2, 0, 5, 0, 0, 0, 8, 1, 2, 0, 6, 16, 1, 3, 8, 2, 2, 0, 1, 0, 0, 0, 6, 5, 0, 0, 8, 1, 2, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 0, 4, 1, 2, 5, 0, 0, 0, 8, 3, 2, 0, 2, 1, 0, 0, 6, 16, 0, 1, 4, 35, 2, 0, 6, 8, 0, 2, 5, 0, 0, 0, 5, 0, 0, 0, 8, 1, 1, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 2, 0, 0, 5, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 6, 10, 0, 2, 6, 12, 1, 3, 2, 1, 0, 0, 4, 13, 1, 0, 6, 4, 0, 0, 8, 1, 1, 0, 2, 0, 0, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 12, 0, 3, 0, 15, 0, 2, 2, 1, 0, 0, 5, 0, 0, 0, 0, 9, 1, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 8, 1, 1, 7, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 2, 1, 0, 2, 0, 0, 0, 8, 1, 2, 0, 5, 0, 0, 0, 6, 8, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 3, 2, 0, 0, 8, 1, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 4, 68, 3, 0, 8, 3, 2, 0, 0, 8, 1, 3, 5, 0, 0, 0, 0, 11, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 7, 1, 3, 0, 6, 1, 2]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 65, 1, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 14, 0, 3, 5, 0, 0, 0, 8, 2, 1, 0, 6, 14, 0, 3, 0, 8, 0, 2, 6, 4, 0, 3, 3, 2, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 4, 0, 2, 8, 3, 2, 0, 0, 14, 1, 2, 8, 1, 2, 0, 3, 1, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 8, 1, 1, 0, 8, 2, 1, 0, 0, 5, 0, 0, 6, 7, 0, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 13, 1, 0, 4, 25, 0, 0, 0, 16, 0, 1, 5, 0, 0, 0, 6, 10, 0, 0, 0, 16, 1, 0, 7, 0, 0, 0, 4, 18, 1, 0, 1, 0, 0, 0, 6, 5, 1, 1, 2, 0, 0, 0, 6, 13, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 3, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 4, 34, 0, 0, 8, 3, 1, 0, 6, 6, 0, 1, 3, 0, 0, 0, 6, 6, 1, 1, 2, 0, 0, 0, 8, 3, 2, 0, 4, 68, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 2, 2, 0, 5, 0, 0, 0, 6, 16, 1, 0, 3, 2, 0, 0, 8, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 4, 30, 3, 0, 4, 105, 3, 0, 1, 0, 0, 0, 4, 18, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 14, 1, 0, 6, 11, 1, 2, 8, 1, 2, 0, 8, 2, 1, 0, 3, 2, 0, 0, 8, 3, 2, 0, 0, 7, 1, 0, 5, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 6, 15, 0, 1, 0, 13, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 4, 62, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 6, 4, 1, 1, 5, 0, 0, 0, 4, 128, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 4, 75, 0, 0, 6, 16, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 5, 0, 3, 8, 3, 2, 0, 7, 0, 0, 0, 8, 3, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 2, 0, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 3, 2, 0, 0, 0, 8, 1, 1, 2, 0, 0, 0, 5, 0, 0, 0, 4, 128, 3, 0, 7, 0, 0, 0, 2, 1, 0, 0, 6, 10, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 0, 15, 1, 0, 1, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 4, 47, 3, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 4, 98, 3, 0, 7, 0, 0, 0, 0, 15, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 1, 2, 0, 1, 0, 0, 0, 0, 9, 1, 2, 8, 2, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 23, 3, 0, 4, 124, 3, 0, 7, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 8, 3, 1, 0, 2, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 0, 15, 1, 2, 7, 0, 0, 0, 0, 6, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 7, 0, 0, 0, 0, 4, 1, 3, 1, 0, 0, 0, 5, 0, 0, 0, 8, 3, 2, 0, 3, 2, 0, 0, 6, 6, 0, 3, 6, 7, 0, 3, 5, 0, 0, 0, 1, 0, 0, 0, 8, 2, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 9, 1, 0, 7, 0, 0, 0, 6, 9, 0, 0, 5, 0, 0, 0, 8, 1, 1, 0, 1, 0, 0, 0, 8, 2, 2, 0, 2, 1, 0, 0, 8, 2, 1, 0, 4, 91, 1, 0, 3, 1, 0, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 4, 29, 2, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 16, 1, 1, 6, 7, 1, 3, 1, 0, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0, 8, 1, 1, 0, 6, 12, 0, 1, 0, 11, 0, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 7, 0, 0, 0, 6, 6, 1, 0, 8, 1, 1, 0, 5, 0, 0, 0, 4, 68, 1, 0, 2, 1, 0, 0, 0, 12, 1, 1, 2, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0, 8, 1, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 2, 0, 2, 1, 0, 0, 3, 3, 0, 0, 4, 48, 1, 0, 5, 0, 0, 0, 6, 10, 0, 2, 3, 1, 0, 0, 2, 0, 0, 0, 4, 55, 3, 0, 7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 9, 0, 2, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 4, 24, 1, 0, 0, 14, 1, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 8, 0, 1, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 4, 19, 0, 0, 7, 0, 0, 0, 4, 57, 2, 0, 8, 3, 1, 0, 4, 24, 3, 0, 0, 12, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 7, 1, 1, 5, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 0, 11, 1, 3, 6, 11, 1, 0, 7, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 11, 1, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 6, 9, 0, 2, 5, 0, 0, 0, 5, 0, 0, 0, 4, 95, 1, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 10, 1, 0, 7, 0, 0, 0, 8, 1, 1, 0, 1, 0, 0, 0, 6, 4, 0, 1, 0, 16, 0, 0, 3, 3, 0, 0, 4, 120, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 113, 1, 0, 4, 43, 1, 0, 8, 2, 2, 0, 2, 0, 0, 0, 6, 10, 1, 3, 6, 7, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 8, 3, 2, 0, 3, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 0, 9, 1, 0, 7, 0, 0, 0, 4, 90, 2, 0, 0, 16, 1, 1, 6, 8, 1, 0, 7, 0, 0, 0, 2, 0, 0, 0, 0, 8, 1, 1, 1, 0, 0, 0, 6, 14, 1, 1, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 58, 3, 0, 4, 108, 3, 0, 3, 0, 0, 0, 6, 11, 0, 0, 0, 11, 1, 3, 5, 0, 0, 0, 0, 4, 0, 1, 3, 0, 0, 0, 4, 63, 0, 0, 6, 12, 1, 0, 4, 60, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 7, 0, 0, 0, 8, 3, 1, 0, 4, 13, 3, 0, 3, 2, 0, 0, 1, 0, 0, 0, 0, 12, 1, 0, 6, 14, 0, 3, 3, 2, 0, 0, 4, 25, 2, 0, 4, 28, 3, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 78, 2, 0, 2, 1, 0, 0, 4, 98, 1, 0, 5, 0, 0, 0, 6, 7, 0, 3, 3, 0, 0, 0, 8, 3, 1, 0, 8, 1, 2, 0, 6, 14, 1, 3, 1, 0, 0, 0, 4, 38, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 2, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 0, 13, 1, 3, 1, 0, 0, 0, 2, 1, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 0, 15, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 2, 0, 7, 0, 0, 0, 8, 1, 2, 0, 0, 11, 1, 3, 5, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 3, 2, 0, 0, 4, 42, 3, 0, 2, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 101, 2, 0, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 0, 10, 1, 1, 0, 7, 0, 3, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 2, 0, 3, 1, 0, 0, 6, 7, 0, 3, 5, 0, 0, 0, 6, 7, 0, 2, 3, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 14, 0, 1, 2, 1, 0, 0, 4, 89, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 34, 1, 0, 3, 3, 0, 0, 8, 1, 1, 0, 7, 0, 0, 0, 6, 13, 1, 2, 6, 12, 1, 3, 8, 1, 1, 0, 6, 14, 1, 0, 8, 1, 1, 0, 6, 8, 0, 3, 1, 0, 0, 0, 6, 4, 0, 2]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 4, 113, 3, 0, 0, 12, 0, 1, 8, 3, 2, 0, 7, 0, 0, 0, 4, 74, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 6, 4, 0, 2, 7, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 0, 14, 0, 1, 7, 0, 0, 0, 8, 1, 1, 0, 8, 1, 2, 0, 0, 11, 0, 3, 4, 55, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 2, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 8, 1, 0, 8, 3, 2, 0, 4, 61, 0, 0, 0, 15, 0, 3, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 8, 1, 3, 3, 1, 0, 0, 4, 102, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 6, 5, 0, 2, 2, 0, 0, 0, 4, 116, 3, 0, 8, 1, 1, 0, 4, 67, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 1, 0, 0, 0, 6, 13, 0, 2, 8, 3, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 8, 3, 1, 0, 0, 12, 0, 2, 6, 15, 1, 1, 3, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 4, 109, 0, 0, 4, 13, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 10, 1, 2, 4, 3, 2, 0, 1, 0, 0, 0, 6, 4, 1, 2, 7, 0, 0, 0, 3, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 2, 0, 0, 0, 8, 3, 1, 0, 2, 0, 0, 0, 8, 3, 2, 0, 0, 4, 1, 1, 4, 40, 2, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 8, 2, 1, 0, 1, 0, 0, 0, 6, 16, 1, 0, 3, 2, 0, 0, 6, 15, 0, 2, 0, 4, 0, 0, 2, 1, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 4, 71, 1, 0, 5, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 6, 11, 1, 1, 2, 1, 0, 0, 5, 0, 0, 0, 4, 16, 3, 0, 3, 0, 0, 0, 8, 1, 2, 0, 4, 68, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 22, 0, 0, 7, 0, 0, 0, 4, 42, 1, 0, 2, 0, 0, 0, 8, 1, 2, 0, 6, 11, 0, 2, 6, 10, 1, 3, 5, 0, 0, 0, 4, 56, 3, 0, 6, 6, 1, 0, 7, 0, 0, 0, 3, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 8, 3, 1, 0, 4, 116, 2, 0, 6, 8, 0, 1, 3, 1, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 0, 11, 0, 2, 6, 15, 0, 1, 5, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 10, 0, 0, 4, 69, 1, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 21, 0, 0, 2, 1, 0, 0, 0, 12, 0, 3, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 12, 0, 1, 4, 104, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 4, 36, 2, 0, 7, 0, 0, 0, 4, 53, 2, 0, 6, 11, 0, 2, 5, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 0, 12, 0, 2, 4, 89, 1, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 16, 0, 3, 5, 0, 0, 0, 4, 73, 3, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 6, 8, 1, 0, 5, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 8, 3, 2, 0, 3, 2, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 60, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 8, 1, 0, 0, 8, 0, 0, 6, 15, 0, 0, 2, 0, 0, 0, 4, 113, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 6, 14, 0, 3, 6, 6, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 123, 2, 0, 0, 8, 1, 2, 5, 0, 0, 0, 8, 2, 1, 0, 3, 3, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 6, 5, 0, 1, 1, 0, 0, 0, 0, 13, 0, 2, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 4, 86, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 4, 83, 0, 0, 8, 3, 1, 0, 5, 0, 0, 0, 4, 13, 3, 0, 6, 10, 0, 2, 2, 0, 0, 0, 0, 10, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 14, 0, 0, 6, 12, 0, 1, 8, 3, 2, 0, 6, 6, 1, 0, 0, 5, 1, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 8, 1, 1, 4, 85, 2, 0, 1, 0, 0, 0, 4, 87, 1, 0, 4, 76, 0, 0, 8, 2, 2, 0, 4, 106, 1, 0, 5, 0, 0, 0, 1, 0, 0, 0, 6, 6, 0, 3, 8, 2, 1, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 6, 8, 1, 3, 2, 0, 0, 0, 3, 0, 0, 0, 0, 5, 1, 2, 2, 0, 0, 0, 3, 1, 0, 0, 0, 15, 0, 0, 1, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 8, 1, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 6, 8, 1, 1, 8, 1, 1, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 0, 13, 0, 3, 0, 13, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 4, 114, 0, 0, 4, 64, 1, 0, 6, 7, 0, 1, 8, 1, 2, 0, 4, 80, 3, 0, 6, 6, 1, 1, 0, 7, 0, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 16, 1, 0, 5, 0, 0, 0, 5, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 6, 16, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [4, 66, 3, 0, 4, 75, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 13, 0, 3, 2, 1, 0, 0, 8, 2, 1, 0, 4, 64, 3, 0, 8, 3, 1, 0, 0, 6, 0, 0, 4, 107, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 0, 12, 1, 1, 8, 3, 2, 0, 3, 2, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 0, 4, 0, 2, 3, 2, 0, 0, 4, 60, 3, 0, 3, 0, 0, 0, 0, 8, 0, 2, 3, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 1, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 6, 15, 0, 1, 6, 8, 1, 1, 3, 2, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 0, 7, 1, 2, 7, 0, 0, 0, 8, 2, 2, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 16, 1, 2, 0, 15, 1, 2, 4, 71, 0, 0, 0, 15, 0, 2, 0, 15, 0, 0, 4, 49, 1, 0, 8, 3, 2, 0, 1, 0, 0, 0, 4, 59, 1, 0, 2, 1, 0, 0, 8, 3, 2, 0, 4, 28, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 6, 15, 0, 3, 5, 0, 0, 0, 8, 3, 2, 0, 3, 1, 0, 0, 0, 7, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 14, 1, 3, 1, 0, 0, 0, 4, 3, 0, 0, 6, 6, 1, 1, 6, 6, 0, 3, 2, 1, 0, 0, 4, 87, 3, 0, 0, 4, 0, 3, 5, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 2, 2, 0, 7, 0, 0, 0, 8, 1, 1, 0, 8, 3, 2, 0, 1, 0, 0, 0, 3, 0, 0, 0, 4, 11, 3, 0, 8, 1, 2, 0, 4, 125, 0, 0, 3, 2, 0, 0, 4, 19, 3, 0, 3, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 1, 1, 0, 3, 3, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 102, 1, 0, 3, 2, 0, 0, 4, 128, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 6, 9, 0, 1, 5, 0, 0, 0, 0, 13, 1, 3, 0, 6, 1, 1]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 14, 0, 2, 1, 0, 0, 0, 8, 2, 2, 0, 0, 9, 1, 0, 1, 0, 0, 0, 6, 5, 0, 3, 7, 0, 0, 0, 6, 14, 1, 3, 6, 11, 0, 3, 8, 3, 2, 0, 2, 1, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 9, 0, 1, 2, 0, 0, 0, 5, 0, 0, 0, 8, 3, 2, 0, 4, 26, 0, 0, 6, 4, 0, 1, 7, 0, 0, 0, 6, 9, 0, 3, 4, 68, 3, 0, 2, 0, 0, 0, 0, 16, 1, 1, 0, 9, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 79, 3, 0, 3, 1, 0, 0, 0, 10, 0, 2, 1, 0, 0, 0, 8, 1, 1, 0, 7, 0, 0, 0, 2, 1, 0, 0, 8, 1, 1, 0, 0, 5, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 0, 10, 1, 2, 0, 14, 0, 1, 0, 13, 0, 2, 1, 0, 0, 0, 6, 12, 1, 1, 8, 2, 1, 0, 7, 0, 0, 0, 6, 6, 0, 3, 3, 3, 0, 0, 5, 0, 0, 0, 4, 94, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 3, 1, 0, 5, 0, 0, 0, 7, 0, 0, 0, 4, 42, 0, 0, 3, 0, 0, 0, 0, 14, 1, 1, 1, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 5, 0, 1, 1, 0, 0, 0, 7, 0, 0, 0, 0, 15, 0, 1, 1, 0, 0, 0, 6, 11, 1, 1, 5, 0, 0, 0, 6, 15, 1, 1, 5, 0, 0, 0, 4, 17, 3, 0, 8, 3, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 1, 0, 0, 4, 3, 0, 0, 3, 3, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 4, 19, 3, 0, 3, 1, 0, 0, 2, 0, 0, 0, 0, 12, 1, 0, 3, 3, 0, 0, 6, 16, 1, 3]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 8, 1, 1, 0, 0, 13, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 8, 3, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 7, 1, 3, 8, 1, 2, 0, 6, 5, 1, 3, 2, 1, 0, 0, 3, 3, 0, 0, 6, 14, 1, 3, 3, 1, 0, 0, 6, 6, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 6, 4, 0, 1, 3, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 10, 0, 3, 2, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 4, 95, 2, 0, 3, 3, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 12, 0, 3, 0, 13, 0, 2, 2, 1, 0, 0, 0, 7, 0, 2, 4, 98, 3, 0, 3, 1, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 4, 59, 0, 0, 4, 48, 2, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 10, 1, 2, 3, 1, 0, 0, 4, 66, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 8, 2, 1, 0, 8, 2, 1, 0, 6, 16, 1, 2, 8, 2, 1, 0, 0, 10, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 4, 25, 2, 0, 7, 0, 0, 0, 0, 6, 1, 3, 0, 8, 0, 2, 3, 2, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 16, 1, 2, 7, 0, 0, 0, 4, 124, 2, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 4, 86, 2, 0, 1, 0, 0, 0, 4, 52, 1, 0, 0, 13, 1, 2, 2, 1, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 2, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 0, 0, 0, 5, 0, 0, 0, 8, 2, 1, 0, 0, 11, 0, 1, 5, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 4, 107, 0, 0, 2, 1, 0, 0, 6, 5, 1, 1, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 8, 1, 0, 0, 7, 0, 1, 6, 9, 1, 1, 3, 1, 0, 0, 8, 1, 1, 0, 3, 1, 0, 0, 0, 14, 0, 2, 4, 1, 3, 0, 5, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 6, 1, 2]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [2, 1, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 8, 1, 1, 0, 0, 14, 0, 2, 2, 0, 0, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 8, 3, 1, 0, 3, 2, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 6, 0, 3, 6, 6, 1, 1, 8, 2, 2, 0, 3, 3, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 8, 2, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 16, 0, 2, 8, 3, 2, 0, 1, 0, 0, 0, 0, 16, 1, 3, 1, 0, 0, 0, 7, 0, 0, 0, 4, 92, 1, 0, 6, 5, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [7, 0, 0, 0, 6, 15, 0, 3, 6, 6, 0, 2, 2, 1, 0, 0, 4, 12, 1, 0, 8, 1, 1, 0, 3, 3, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 8, 2, 1, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [8, 2, 1, 0, 3, 2, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 4, 126, 1, 0, 4, 83, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 0, 15, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [6, 14, 0, 1, 8, 3, 2, 0, 6, 10, 1, 1, 7, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 8, 2, 1, 0, 4, 104, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 13, 1, 3, 0, 4, 1, 0, 4, 123, 1, 0, 1, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 8, 3, 1, 0, 3, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 7, 1, 3, 5, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 8, 1, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [3, 0, 0, 0, 4, 36, 0, 0, 8, 2, 2, 0, 4, 47, 2, 0, 7, 0, 0, 0, 5, 0, 0, 0, 4, 99, 3, 0, 8, 3, 2, 0, 3, 1, 0, 0, 4, 76, 0, 0, 6, 9, 0, 3, 5, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 6, 12, 1, 3, 2, 0, 0, 0, 6, 11, 1, 2, 8, 1, 2, 0, 4, 49, 2, 0, 6, 4, 0, 0, 4, 107, 3, 0, 2, 1, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [0, 5, 0, 2, 2, 1, 0, 0, 4, 18, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 4, 107, 3, 0, 1, 0, 0, 0, 4, 54, 3, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 6, 9, 1, 1, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 4, 104, 0, 0, 1, 0, 0, 0, 8, 3, 1, 0, 8, 2, 2, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelos únicos después de la reparación: 198\n",
      "Modelos duplicados después de la reparación: 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_random_architecture():\n",
    "    num_layers = 12\n",
    "    layers = []\n",
    "   \n",
    "    for _ in range(num_layers):\n",
    "        layer_type = random.choice([\n",
    "            'Conv2D', 'DepthwiseConv2D', 'BatchNorm', 'MaxPooling', 'Dropout', \n",
    "            'Dense', 'Flatten', 'DontCare', 'Repetition'\n",
    "        ])\n",
    "        layers.append(generate_layer(layer_type))\n",
    "    return {\"layers\": layers}\n",
    "\n",
    "def generate_layer(layer_type):\n",
    "    if layer_type == 'Conv2D':\n",
    "        return {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'DepthwiseConv2D':\n",
    "        return {\n",
    "            \"type\": \"DepthwiseConv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {\"type\": \"BatchNorm\"}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        return {\n",
    "            \"type\": \"MaxPooling\",\n",
    "            \"strides\": random.choice([1, 2])\n",
    "        }\n",
    "    elif layer_type == 'Dropout':\n",
    "        return {\n",
    "            \"type\": \"Dropout\",\n",
    "            \"rate\": random.choice([0.2, 0.3, 0.4, 0.5])\n",
    "        }\n",
    "    elif layer_type == 'Dense':\n",
    "        return {\n",
    "            \"type\": \"Dense\",\n",
    "            \"units\": random.randint(1, 128),  # Rango reducido para unidades\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {\"type\": \"Flatten\"}\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {\"type\": \"DontCare\"}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            \"type\": \"Repetition\",\n",
    "            \"repetition_layers\": random.randint(1, 3),  # Limitar el número de capas para repetir\n",
    "            \"repetition_count\": random.randint(1, 2)  # Limitar el conteo de repeticiones\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "def generate_and_compare_repaired_models(num_models=1000):\n",
    "    repaired_models = set()\n",
    "    duplicate_count = 0\n",
    "\n",
    "    for i in range(num_models):\n",
    "        random_architecture = generate_random_architecture()\n",
    "        repaired_architecture = process_model_pipeline(random_architecture)\n",
    "        repaired_architecture_str = str(repaired_architecture)\n",
    "\n",
    "        if repaired_architecture_str in repaired_models:\n",
    "            duplicate_count += 1\n",
    "        else:\n",
    "            repaired_models.add(repaired_architecture_str)\n",
    "        \n",
    "        # Liberar memoria\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    unique_count = len(repaired_models)\n",
    "    print(f\"\\nModelos únicos después de la reparación: {unique_count}\")\n",
    "    print(f\"Modelos duplicados después de la reparación: {duplicate_count}\")\n",
    "\n",
    "generate_and_compare_repaired_models(num_models=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando el modelo surogado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 21ms/step\n",
      "Modelo 52 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 53/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 1, 1, 0, 7, 0, 0, 0, 0, 4, 1, 2, 6, 12, 0, 3, 7, 0, 0, 0, 3, 0, 0, 0, 0, 14, 1, 3, 1, 0, 0, 0, 6, 8, 1, 1, 0, 12, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 53 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 53 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 54/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 3, 1, 0, 0, 16, 0, 3, 1, 0, 0, 0, 5, 0, 0, 0, 0, 10, 0, 1, 4, 100, 1, 0, 8, 2, 2, 0, 7, 0, 0, 0, 0, 4, 1, 1, 0, 5, 0, 3, 0, 14, 0, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 54 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 54 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 55/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 15, 1, 0, 7, 0, 0, 0, 2, 1, 0, 0, 6, 6, 1, 3, 5, 0, 0, 0, 3, 0, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 55 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 55 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 56/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 119, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 8, 3, 2, 0, 0, 13, 1, 0, 3, 2, 0, 0, 6, 12, 1, 3, 7, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 56 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 15ms/step\n",
      "Modelo 56 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 57/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 8, 2, 2, 0, 6, 14, 1, 1, 4, 47, 0, 0, 7, 0, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 57 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 57 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 58/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 5, 0, 0, 0, 0, 9, 1, 2, 3, 3, 0, 0, 7, 0, 0, 0, 6, 8, 1, 0, 8, 3, 1, 0, 4, 15, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 8, 1, 2, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 58 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 58 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 59/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 4, 60, 0, 0, 3, 3, 0, 0, 4, 116, 1, 0, 4, 38, 0, 0, 3, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 59 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 59 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 60/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 6, 14, 0, 2, 4, 35, 0, 0, 6, 16, 0, 0, 8, 3, 1, 0, 0, 9, 0, 3, 5, 0, 0, 0, 5, 0, 0, 0, 0, 13, 1, 0, 3, 3, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 60 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 16ms/step\n",
      "Modelo 60 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 61/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 6, 4, 0, 3, 1, 0, 0, 0, 8, 3, 2, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 16, 0, 3, 3, 2, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 61 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 61 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 62/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 4, 65, 1, 0, 1, 0, 0, 0, 6, 7, 1, 1, 2, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 62 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 62 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 63/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 5, 0, 0, 0, 7, 0, 0, 0, 6, 6, 1, 0, 2, 0, 0, 0, 6, 16, 1, 2, 4, 35, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 6, 5, 1, 1, 4, 109, 2, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 63 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 63 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 64/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 53, 0, 0, 1, 0, 0, 0, 0, 15, 1, 1, 6, 8, 0, 0, 5, 0, 0, 0, 4, 107, 2, 0, 0, 13, 1, 3, 8, 3, 2, 0, 8, 2, 1, 0, 6, 9, 1, 2, 5, 0, 0, 0, 0, 11, 0, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 64 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 64 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 65/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 6, 7, 1, 2, 0, 8, 0, 2, 4, 83, 2, 0, 4, 56, 1, 0, 5, 0, 0, 0, 0, 4, 0, 3, 7, 0, 0, 0, 3, 3, 0, 0, 4, 60, 2, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 65 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 7ms/step\n",
      "Modelo 65 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 66/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 3, 2, 0, 3, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 8, 2, 1, 0, 0, 12, 1, 2, 0, 7, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 66 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 66 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 67/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 1, 2, 2, 1, 0, 0, 3, 0, 0, 0, 6, 14, 1, 2, 0, 13, 1, 0, 7, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 67 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 67 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 68/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 2, 0, 6, 12, 1, 3, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 6, 14, 0, 0, 0, 8, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 6, 12, 0, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 68 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 68 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 69/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 3, 1, 0, 3, 1, 0, 0, 3, 1, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 4, 101, 3, 0, 8, 3, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0, 8, 2, 2, 0, 3, 3, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 69 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 69 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 70/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 4, 14, 2, 0, 4, 128, 1, 0, 5, 0, 0, 0, 0, 13, 0, 3, 3, 3, 0, 0, 8, 2, 2, 0, 8, 3, 2, 0, 3, 1, 0, 0, 6, 10, 1, 3, 6, 15, 1, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 70 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 33ms/step\n",
      "Modelo 70 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 71/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 115, 2, 0, 6, 10, 1, 1, 7, 0, 0, 0, 4, 119, 3, 0, 4, 56, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 0, 7, 0, 3, 7, 0, 0, 0, 4, 54, 0, 0, 1, 0, 0, 0, 0, 6, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 71 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 24ms/step\n",
      "Modelo 71 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 72/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 8, 0, 3, 5, 0, 0, 0, 2, 1, 0, 0, 3, 2, 0, 0, 6, 6, 0, 0, 1, 0, 0, 0, 0, 13, 0, 3, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 72 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 11ms/step\n",
      "Modelo 72 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 73/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 0, 11, 1, 1, 1, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 4, 1, 3, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 73 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 73 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 74/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 13, 1, 3, 7, 0, 0, 0, 5, 0, 0, 0, 0, 9, 0, 2, 3, 2, 0, 0, 8, 1, 1, 0, 0, 6, 0, 1, 8, 2, 1, 0, 5, 0, 0, 0, 7, 0, 0, 0, 0, 15, 1, 1, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 74 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 74 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 75/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 5, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 0, 9, 1, 0, 2, 1, 0, 0, 4, 94, 2, 0, 4, 24, 1, 0, 5, 0, 0, 0, 8, 1, 1, 0, 6, 11, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 75 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 75 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 76/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 8, 1, 1, 0, 6, 9, 1, 3, 1, 0, 0, 0, 4, 108, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 76 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 76 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 77/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 1, 0, 0, 6, 4, 1, 0, 8, 2, 2, 0, 2, 0, 0, 0, 8, 3, 2, 0, 4, 111, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 0, 6, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 77 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 77 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 78/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 7, 0, 0, 0, 6, 11, 0, 1, 8, 1, 2, 0, 3, 3, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 9, 0, 2, 4, 27, 2, 0, 1, 0, 0, 0, 4, 33, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 78 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 78 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 79/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0, 0, 4, 1, 1, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 6, 9, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 79 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 79 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 80/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 14, 0, 3, 6, 16, 0, 3, 5, 0, 0, 0, 8, 2, 2, 0, 8, 3, 2, 0, 6, 9, 1, 1, 0, 12, 1, 3, 0, 9, 1, 2, 5, 0, 0, 0, 3, 2, 0, 0, 0, 12, 1, 1, 6, 5, 1, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 80 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 21ms/step\n",
      "Modelo 80 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 81/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 84, 0, 0, 6, 8, 1, 3, 0, 12, 1, 0, 4, 65, 3, 0, 6, 14, 0, 1, 6, 15, 1, 2, 5, 0, 0, 0, 2, 1, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 81 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 14ms/step\n",
      "Modelo 81 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 82/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 3, 2, 0, 5, 0, 0, 0, 8, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 9, 0, 2, 8, 3, 1, 0, 7, 0, 0, 0, 0, 9, 0, 2, 5, 0, 0, 0, 3, 2, 0, 0, 0, 4, 1, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 82 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 19ms/step\n",
      "Modelo 82 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 83/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 101, 3, 0, 7, 0, 0, 0, 3, 1, 0, 0, 2, 0, 0, 0, 6, 7, 0, 2, 7, 0, 0, 0, 6, 16, 0, 3, 7, 0, 0, 0, 5, 0, 0, 0, 6, 6, 1, 2, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 83 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 33ms/step\n",
      "Modelo 83 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 84/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 1, 0, 0, 0, 0, 14, 0, 2, 5, 0, 0, 0, 8, 2, 1, 0, 6, 13, 1, 3, 0, 7, 1, 3, 0, 14, 1, 3, 7, 0, 0, 0, 5, 0, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 84 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 84 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 85/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 47, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 4, 95, 0, 0, 3, 3, 0, 0, 6, 14, 1, 1, 2, 1, 0, 0, 3, 0, 0, 0, 4, 119, 3, 0, 8, 3, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 85 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 25ms/step\n",
      "Modelo 85 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 86/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 5, 0, 2, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 2, 1, 0, 0, 4, 53, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 86 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 86 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 87/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 12, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 8, 2, 2, 0, 3, 2, 0, 0, 8, 2, 2, 0, 1, 0, 0, 0, 4, 128, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 87 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 87 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 88/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 0, 5, 0, 0, 6, 10, 0, 3, 7, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 0, 6, 1, 0, 8, 2, 1, 0, 3, 2, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 88 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 88 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 89/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 3, 3, 0, 0, 2, 1, 0, 0, 0, 9, 0, 1, 6, 5, 0, 3, 4, 91, 1, 0, 3, 3, 0, 0, 3, 2, 0, 0, 6, 5, 1, 2, 2, 0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 89 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 89 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 90/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 72, 2, 0, 6, 14, 1, 1, 8, 2, 2, 0, 1, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 8, 1, 1, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 90 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 14ms/step\n",
      "Modelo 90 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 91/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 0, 0, 0, 8, 2, 2, 0, 0, 15, 0, 2, 0, 15, 1, 3, 7, 0, 0, 0, 0, 9, 1, 3, 7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 12, 0, 2, 3, 1, 0, 0, 6, 6, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 91 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 12ms/step\n",
      "Modelo 91 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 92/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 4, 20, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 6, 9, 1, 1, 2, 1, 0, 0, 8, 3, 2, 0, 4, 60, 1, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 92 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 92 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 93/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 1, 0, 3, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 14, 1, 0, 4, 50, 3, 0, 0, 10, 0, 2, 8, 2, 2, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 93 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 93 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 94/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 1, 0, 6, 4, 1, 2, 6, 9, 1, 3, 3, 1, 0, 0, 6, 15, 0, 1, 4, 39, 1, 0, 7, 0, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 8, 1, 2, 0, 6, 6, 0, 3, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 94 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 12ms/step\n",
      "Modelo 94 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 95/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 0, 15, 1, 3, 1, 0, 0, 0, 0, 15, 0, 3, 3, 3, 0, 0, 7, 0, 0, 0, 4, 82, 3, 0, 4, 90, 0, 0, 0, 5, 1, 3, 6, 9, 1, 3, 0, 5, 0, 2, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 95 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 95 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 96/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 12, 1, 0, 7, 0, 0, 0, 0, 13, 0, 1, 0, 6, 1, 1, 4, 6, 1, 0, 6, 11, 1, 1, 5, 0, 0, 0, 6, 8, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 96 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 96 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 97/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 2, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 14, 0, 1, 7, 0, 0, 0, 8, 1, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 97 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 97 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 98/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 5, 0, 0, 0, 4, 89, 2, 0, 8, 3, 1, 0, 4, 12, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 6, 15, 0, 1, 1, 0, 0, 0, 8, 1, 1, 0, 0, 13, 1, 3, 6, 15, 1, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 98 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 20ms/step\n",
      "Modelo 98 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 99/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 12, 0, 3, 2, 1, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 0, 0, 4, 0, 1, 3, 0, 0, 0, 6, 5, 0, 3, 8, 2, 2, 0, 3, 0, 0, 0, 5, 0, 0, 0, 6, 9, 1, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 99 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 99 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 100/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 8, 2, 2, 0, 4, 56, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 0, 13, 1, 0, 8, 2, 2, 0, 6, 7, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 100 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 100 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 101/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 1, 0, 0, 0, 0, 4, 1, 2, 0, 11, 1, 3, 7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 101 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 101 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 102/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 81, 0, 0, 5, 0, 0, 0, 4, 120, 3, 0, 3, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 12, 0, 1, 3, 3, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 102 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 37ms/step\n",
      "Modelo 102 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 103/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 1, 0, 6, 15, 0, 2, 8, 2, 2, 0, 6, 10, 0, 2, 7, 0, 0, 0, 0, 15, 0, 3, 5, 0, 0, 0, 6, 8, 0, 3, 6, 4, 1, 2, 4, 87, 2, 0, 6, 13, 0, 2, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 103 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 28ms/step\n",
      "Modelo 103 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 104/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 8, 3, 2, 0, 8, 1, 1, 0, 6, 14, 0, 2, 6, 4, 0, 0, 4, 110, 0, 0, 0, 8, 0, 2, 5, 0, 0, 0, 4, 82, 0, 0, 0, 8, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 104 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 32ms/step\n",
      "Modelo 104 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 105/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 0, 14, 1, 2, 0, 14, 1, 1, 6, 8, 1, 1, 8, 3, 1, 0, 8, 1, 2, 0, 7, 0, 0, 0, 6, 10, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 105 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 105 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 106/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 7, 1, 0, 1, 0, 0, 0, 0, 15, 0, 0, 3, 1, 0, 0, 6, 10, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 0, 16, 0, 3, 1, 0, 0, 0, 4, 125, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 106 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 106 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 107/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 5, 1, 1, 0, 8, 0, 1, 7, 0, 0, 0, 5, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 4, 57, 0, 0, 3, 0, 0, 0, 0, 10, 1, 2, 0, 16, 0, 0, 4, 103, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 107 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 107 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 108/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 3, 1, 0, 0, 13, 1, 3, 1, 0, 0, 0, 8, 2, 2, 0, 0, 10, 1, 0, 3, 2, 0, 0, 6, 6, 1, 2, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 8, 0, 2, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 108 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 108 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 109/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 8, 2, 2, 0, 6, 6, 1, 3, 6, 6, 0, 2, 7, 0, 0, 0, 1, 0, 0, 0, 8, 2, 2, 0, 1, 0, 0, 0, 6, 8, 1, 3, 4, 63, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 109 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 109 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 110/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 2, 1, 0, 0, 13, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 8, 2, 1, 0, 6, 10, 1, 2, 1, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 110 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 110 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 111/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 8, 2, 2, 0, 7, 0, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 0, 9, 0, 1, 5, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 111 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 111 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 112/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 2, 1, 0, 0, 0, 9, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 112 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 112 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 113/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 0, 0, 0, 3, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 4, 67, 2, 0, 1, 0, 0, 0, 5, 0, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 1, 0, 0, 0, 8, 2, 2, 0, 0, 6, 0, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 113 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 14ms/step\n",
      "Modelo 113 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 114/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 4, 50, 0, 0, 4, 74, 2, 0, 5, 0, 0, 0, 0, 4, 1, 2, 6, 5, 0, 1, 8, 3, 1, 0, 0, 9, 0, 1, 2, 0, 0, 0, 0, 4, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 114 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 114 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 115/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 1, 0, 6, 5, 0, 3, 5, 0, 0, 0, 1, 0, 0, 0, 8, 1, 1, 0, 5, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 115 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 115 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 116/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 5, 1, 1, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 6, 5, 1, 0, 3, 2, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 4, 11, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 116 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 116 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 117/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 2, 0, 0, 0, 16, 1, 3, 7, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 6, 6, 1, 1, 2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 4, 83, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 117 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 117 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 118/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 4, 80, 0, 0, 4, 96, 0, 0, 4, 5, 3, 0, 7, 0, 0, 0, 6, 6, 1, 2, 0, 8, 1, 3, 1, 0, 0, 0, 5, 0, 0, 0, 0, 10, 0, 3, 0, 10, 1, 1, 0, 10, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 118 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 20ms/step\n",
      "Modelo 118 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 119/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 3, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 8, 1, 2, 0, 4, 89, 2, 0, 8, 2, 1, 0, 2, 1, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 6, 14, 1, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 119 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 119 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 120/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 5, 0, 0, 0, 0, 9, 0, 2, 0, 13, 1, 0, 2, 1, 0, 0, 0, 8, 0, 0, 1, 0, 0, 0, 4, 66, 1, 0, 2, 1, 0, 0, 0, 7, 1, 1, 8, 2, 2, 0, 8, 3, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 120 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 120 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 121/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 5, 1, 0, 3, 0, 0, 0, 6, 8, 1, 3, 0, 5, 0, 2, 2, 1, 0, 0, 7, 0, 0, 0, 6, 4, 0, 0, 6, 12, 0, 1, 0, 16, 0, 1, 6, 14, 1, 2, 5, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 121 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 121 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 122/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 2, 1, 0, 0, 4, 55, 3, 0, 8, 3, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 4, 128, 0, 0, 0, 16, 1, 0, 4, 28, 1, 0, 4, 95, 3, 0, 0, 15, 0, 1, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 122 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 122 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 123/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 3, 1, 0, 7, 0, 0, 0, 8, 1, 2, 0, 3, 3, 0, 0, 8, 1, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 6, 9, 1, 0, 4, 99, 0, 0, 1, 0, 0, 0, 0, 4, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 123 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 123 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 124/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 8, 1, 2, 0, 3, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 1, 0, 8, 3, 1, 0, 6, 8, 0, 1, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 124 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 124 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 125/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 4, 0, 2, 4, 4, 3, 0, 8, 3, 2, 0, 3, 2, 0, 0, 8, 2, 2, 0, 2, 1, 0, 0, 8, 3, 2, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 125 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 12ms/step\n",
      "Modelo 125 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 126/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 8, 3, 1, 0, 3, 1, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 4, 27, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 126 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 126 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 127/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 5, 0, 0, 0, 6, 9, 1, 3, 3, 1, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 2, 0, 0, 4, 113, 1, 0, 3, 2, 0, 0, 0, 12, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 127 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 127 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 128/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 78, 3, 0, 7, 0, 0, 0, 0, 8, 0, 1, 6, 16, 1, 0, 7, 0, 0, 0, 0, 11, 1, 3, 3, 0, 0, 0, 4, 1, 2, 0, 4, 7, 1, 0, 5, 0, 0, 0, 0, 5, 0, 3, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 128 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 22ms/step\n",
      "Modelo 128 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 129/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 2, 0, 0, 8, 2, 1, 0, 8, 2, 1, 0, 0, 7, 0, 1, 6, 6, 0, 2, 5, 0, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0, 5, 0, 0, 0, 6, 7, 0, 3, 1, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 129 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 15ms/step\n",
      "Modelo 129 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 130/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 1, 0, 0, 0, 4, 90, 0, 0, 4, 97, 0, 0, 8, 3, 2, 0, 6, 14, 0, 2, 4, 66, 1, 0, 7, 0, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 130 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 3s 79ms/step\n",
      "Modelo 130 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 131/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 6, 6, 0, 1, 6, 12, 0, 0, 4, 19, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 4, 23, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 8, 1, 2, 0, 4, 66, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 131 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 28ms/step\n",
      "Modelo 131 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 132/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 10, 0, 3, 0, 14, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 8, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 4, 5, 3, 0, 7, 0, 0, 0, 0, 8, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 132 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 132 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 133/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 5, 0, 0, 0, 4, 106, 3, 0, 2, 1, 0, 0, 8, 3, 1, 0, 8, 1, 1, 0, 3, 1, 0, 0, 0, 6, 1, 2, 2, 1, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 133 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 20ms/step\n",
      "Modelo 133 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 134/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 10, 0, 2, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 6, 11, 1, 3, 1, 0, 0, 0, 0, 15, 1, 1, 2, 1, 0, 0, 3, 2, 0, 0, 3, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 134 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 14ms/step\n",
      "Modelo 134 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 135/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 4, 62, 1, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 8, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 135 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 33ms/step\n",
      "Modelo 135 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 136/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 9, 1, 1, 2, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 108, 1, 0, 2, 1, 0, 0, 4, 27, 1, 0, 5, 0, 0, 0, 2, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 136 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 136 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 137/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 1, 0, 0, 0, 4, 116, 1, 0, 4, 109, 0, 0, 7, 0, 0, 0, 0, 6, 1, 3, 1, 0, 0, 0, 2, 0, 0, 0, 4, 90, 1, 0, 1, 0, 0, 0, 6, 10, 1, 2, 4, 28, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 137 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 2s 39ms/step\n",
      "Modelo 137 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 138/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 7, 0, 0, 0, 0, 10, 0, 3, 1, 0, 0, 0, 6, 7, 1, 0, 2, 1, 0, 0, 4, 73, 1, 0, 8, 3, 1, 0, 3, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 138 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 14ms/step\n",
      "Modelo 138 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 139/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 9, 0, 3, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 6, 5, 0, 1, 3, 0, 0, 0, 0, 4, 0, 0, 4, 52, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 139 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 34ms/step\n",
      "Modelo 139 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 140/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 16, 0, 1, 7, 0, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 8, 2, 1, 0, 4, 104, 2, 0, 6, 10, 0, 3, 8, 3, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 140 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 2s 46ms/step\n",
      "Modelo 140 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 141/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 13, 0, 0, 8, 1, 2, 0, 3, 1, 0, 0, 6, 5, 1, 1, 6, 8, 0, 3, 5, 0, 0, 0, 6, 9, 1, 0, 1, 0, 0, 0, 8, 3, 2, 0, 4, 34, 3, 0, 4, 39, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 141 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 141 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 142/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 13, 1, 3, 3, 1, 0, 0, 7, 0, 0, 0, 6, 14, 1, 2, 0, 10, 1, 1, 2, 1, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 142 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 142 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 143/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 127, 0, 0, 3, 3, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 4, 106, 1, 0, 2, 0, 0, 0, 8, 1, 1, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 143 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 33ms/step\n",
      "Modelo 143 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 144/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 2, 1, 0, 0, 4, 85, 1, 0, 2, 0, 0, 0, 5, 0, 0, 0, 4, 9, 2, 0, 3, 1, 0, 0, 3, 1, 0, 0, 8, 3, 2, 0, 8, 3, 1, 0, 1, 0, 0, 0, 0, 15, 1, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 144 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 144 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 145/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 6, 12, 0, 1, 8, 1, 1, 0, 6, 12, 0, 1, 4, 78, 2, 0, 8, 3, 2, 0, 5, 0, 0, 0, 8, 2, 2, 0, 6, 9, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 145 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 145 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 146/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 11, 1, 0, 0, 4, 0, 3, 6, 6, 0, 0, 3, 1, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 3, 2, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 146 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 146 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 147/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 11, 1, 0, 2, 1, 0, 0, 6, 15, 0, 3, 8, 1, 2, 0, 1, 0, 0, 0, 0, 5, 1, 0, 1, 0, 0, 0, 3, 1, 0, 0, 6, 6, 0, 2, 3, 3, 0, 0, 1, 0, 0, 0, 4, 8, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 147 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 147 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 148/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 4, 25, 1, 0, 5, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 6, 13, 0, 1, 6, 10, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 148 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 148 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 149/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 44, 2, 0, 5, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 14, 1, 1, 3, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 4, 78, 2, 0, 3, 3, 0, 0, 8, 3, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 149 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 12ms/step\n",
      "Modelo 149 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 150/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 6, 8, 1, 0, 7, 0, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 4, 78, 2, 0, 6, 6, 0, 2, 3, 3, 0, 0, 0, 12, 1, 2, 4, 16, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 150 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 150 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 151/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 72, 3, 0, 0, 8, 1, 2, 5, 0, 0, 0, 6, 12, 1, 2, 0, 8, 1, 0, 0, 6, 0, 3, 8, 2, 1, 0, 4, 59, 3, 0, 6, 16, 1, 0, 8, 3, 1, 0, 3, 3, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 151 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 21ms/step\n",
      "Modelo 151 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 152/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 16, 0, 3, 7, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 6, 13, 1, 3, 0, 5, 0, 1, 1, 0, 0, 0, 6, 12, 1, 0, 8, 3, 2, 0, 8, 3, 1, 0, 4, 106, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 152 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 152 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 153/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 2, 2, 0, 4, 56, 0, 0, 5, 0, 0, 0, 0, 12, 0, 3, 8, 3, 2, 0, 4, 35, 2, 0, 2, 0, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 3, 3, 0, 0, 0, 12, 0, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 153 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 2s 39ms/step\n",
      "Modelo 153 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 154/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 0, 10, 1, 1, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 12, 1, 3, 6, 12, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 4, 33, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 154 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 154 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 155/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 1, 0, 0, 0, 4, 61, 3, 0, 5, 0, 0, 0, 4, 2, 2, 0, 6, 11, 0, 1, 5, 0, 0, 0, 8, 3, 1, 0, 2, 1, 0, 0, 0, 10, 0, 0, 0, 8, 0, 0, 8, 3, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 155 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 155 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 156/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 12, 1, 1, 1, 0, 0, 0, 6, 10, 1, 2, 8, 2, 1, 0, 2, 1, 0, 0, 6, 9, 0, 2, 2, 1, 0, 0, 4, 61, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 0, 7, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 156 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 156 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 157/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 2, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 6, 12, 1, 3, 8, 1, 1, 0, 6, 10, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 8, 3, 2, 0, 3, 1, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 157 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 157 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 158/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 2, 1, 0, 0, 3, 0, 0, 0, 8, 2, 1, 0, 2, 1, 0, 0, 8, 1, 2, 0, 4, 28, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 158 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 158 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 159/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 9, 1, 3, 5, 0, 0, 0, 4, 75, 0, 0, 5, 0, 0, 0, 4, 37, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 4, 122, 2, 0, 6, 5, 1, 3, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 159 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 159 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 160/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 3, 0, 0, 0, 6, 10, 0, 3, 1, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 8, 1, 1, 0, 4, 108, 2, 0, 1, 0, 0, 0, 4, 58, 2, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 160 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 13ms/step\n",
      "Modelo 160 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 161/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 6, 8, 1, 3, 4, 11, 3, 0, 2, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 16, 1, 3, 6, 11, 1, 3, 2, 1, 0, 0, 4, 102, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 161 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 161 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 162/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 3, 2, 0, 0, 4, 94, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 162 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 162 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 163/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 8, 3, 2, 0, 7, 0, 0, 0, 6, 8, 1, 0, 0, 5, 0, 3, 0, 7, 0, 1, 7, 0, 0, 0, 0, 11, 1, 2, 3, 0, 0, 0, 6, 8, 0, 0, 4, 7, 1, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 163 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 163 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 164/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 0, 0, 0, 6, 16, 1, 1, 0, 16, 1, 1, 7, 0, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 3, 3, 0, 0, 6, 4, 0, 3, 2, 0, 0, 0, 8, 1, 1, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 164 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 164 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 165/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 15, 1, 0, 4, 105, 1, 0, 8, 2, 2, 0, 1, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 0, 9, 0, 1, 8, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 6, 10, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 165 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 17ms/step\n",
      "Modelo 165 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 166/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 6, 0, 1, 5, 0, 0, 0, 5, 0, 0, 0, 0, 6, 0, 2, 1, 0, 0, 0, 7, 0, 0, 0, 0, 9, 1, 2, 8, 3, 1, 0, 8, 2, 2, 0, 7, 0, 0, 0, 8, 1, 2, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 166 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 166 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 167/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 3, 2, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 4, 106, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 12, 0, 2, 4, 17, 2, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 167 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 167 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 168/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 0, 14, 1, 2, 0, 4, 0, 3, 4, 48, 2, 0, 2, 0, 0, 0, 6, 7, 1, 2, 3, 2, 0, 0, 8, 3, 2, 0, 6, 6, 0, 0, 0, 13, 1, 3, 0, 11, 0, 2, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 168 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 168 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 169/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 0, 0, 0, 6, 10, 0, 2, 0, 13, 0, 1, 1, 0, 0, 0, 8, 2, 2, 0, 2, 1, 0, 0, 5, 0, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 7, 0, 0, 0, 3, 2, 0, 0, 0, 5, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 169 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 17ms/step\n",
      "Modelo 169 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 170/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 4, 85, 2, 0, 0, 11, 0, 1, 4, 39, 0, 0, 4, 38, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 4, 84, 0, 0, 6, 4, 1, 0, 3, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 170 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 31ms/step\n",
      "Modelo 170 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 171/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 1, 0, 7, 0, 0, 0, 4, 24, 2, 0, 6, 11, 0, 2, 5, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 6, 11, 0, 2, 7, 0, 0, 0, 4, 74, 0, 0, 0, 12, 1, 1, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 171 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 13ms/step\n",
      "Modelo 171 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 172/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 29, 3, 0, 3, 0, 0, 0, 4, 53, 3, 0, 6, 7, 0, 3, 1, 0, 0, 0, 6, 14, 1, 3, 2, 1, 0, 0, 7, 0, 0, 0, 3, 2, 0, 0, 8, 3, 1, 0, 5, 0, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 172 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 16ms/step\n",
      "Modelo 172 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 173/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 9, 1, 3, 5, 0, 0, 0, 6, 10, 1, 3, 7, 0, 0, 0, 6, 13, 1, 2, 1, 0, 0, 0, 8, 2, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 0, 14, 1, 3, 0, 15, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 173 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 173 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 174/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 1, 0, 7, 0, 0, 0, 6, 6, 0, 2, 5, 0, 0, 0, 0, 16, 1, 2, 5, 0, 0, 0, 0, 4, 1, 1, 2, 1, 0, 0, 2, 0, 0, 0, 8, 3, 1, 0, 3, 0, 0, 0, 0, 10, 1, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 174 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 174 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 175/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 6, 9, 0, 0, 5, 0, 0, 0, 8, 1, 2, 0, 3, 3, 0, 0, 0, 10, 0, 2, 4, 72, 1, 0, 6, 14, 1, 3, 1, 0, 0, 0, 4, 28, 3, 0, 4, 50, 1, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 175 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 19ms/step\n",
      "Modelo 175 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 176/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 8, 1, 2, 2, 1, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 7, 0, 0, 0, 4, 58, 0, 0, 5, 0, 0, 0, 0, 11, 0, 2, 0, 14, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 176 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 176 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 177/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 6, 13, 1, 2, 6, 10, 0, 3, 0, 16, 1, 3, 0, 6, 1, 0, 4, 107, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 15, 1, 0, 0, 8, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 177 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 177 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 178/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 9, 0, 0, 7, 0, 0, 0, 8, 1, 2, 0, 2, 1, 0, 0, 3, 0, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 178 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 178 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 179/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 5, 1, 1, 6, 8, 1, 0, 4, 2, 1, 0, 8, 2, 1, 0, 5, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 4, 26, 2, 0, 4, 96, 2, 0, 0, 15, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 179 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 179 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 180/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 2, 0, 0, 0, 0, 10, 1, 0, 8, 1, 2, 0, 4, 48, 1, 0, 2, 1, 0, 0, 0, 10, 0, 3, 4, 46, 3, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 4, 80, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 180 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 180 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 181/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 7, 0, 2, 4, 29, 1, 0, 8, 3, 1, 0, 1, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 8, 2, 1, 0, 6, 12, 1, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 46, 1, 0, 4, 69, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 181 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 18ms/step\n",
      "Modelo 181 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 182/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 9, 1, 2, 5, 0, 0, 0, 0, 15, 1, 3, 7, 0, 0, 0, 8, 1, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 182 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 182 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 183/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 0, 0, 0, 0, 14, 0, 1, 5, 0, 0, 0, 0, 11, 1, 1, 2, 0, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 0, 8, 1, 0, 2, 0, 0, 0, 4, 98, 1, 0, 7, 0, 0, 0, 4, 61, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 183 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 183 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 184/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 9, 0, 2, 5, 0, 0, 0, 5, 0, 0, 0, 0, 12, 0, 2, 6, 12, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 4, 1, 1, 0, 6, 6, 1, 0, 1, 0, 0, 0, 0, 14, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 184 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 184 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 185/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 4, 77, 1, 0, 4, 69, 1, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 13, 0, 3, 1, 0, 0, 0, 6, 5, 1, 3, 1, 0, 0, 0, 3, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 185 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 27ms/step\n",
      "Modelo 185 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 186/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 1, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0, 0, 15, 0, 0, 4, 29, 3, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 16, 0, 3, 4, 49, 2, 0, 7, 0, 0, 0, 3, 3, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 186 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 15ms/step\n",
      "Modelo 186 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 187/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 1, 2, 0, 0, 14, 0, 2, 2, 1, 0, 0, 3, 3, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 8, 2, 2, 0, 0, 7, 0, 0, 2, 0, 0, 0, 0, 10, 1, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 187 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 187 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 188/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 0, 16, 1, 0, 7, 0, 0, 0, 8, 1, 1, 0, 8, 3, 2, 0, 7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 188 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 188 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 189/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 4, 79, 2, 0, 2, 1, 0, 0, 0, 15, 1, 0, 6, 6, 1, 0, 8, 3, 1, 0, 0, 10, 1, 0, 6, 10, 0, 1, 5, 0, 0, 0, 8, 1, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 189 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 189 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 190/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 15, 0, 0, 6, 9, 0, 0, 7, 0, 0, 0, 4, 2, 3, 0, 5, 0, 0, 0, 8, 2, 2, 0, 0, 14, 1, 3, 3, 2, 0, 0, 0, 7, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 190 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 190 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 191/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 3, 1, 0, 4, 84, 1, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 127, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 12, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 191 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 31ms/step\n",
      "Modelo 191 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 192/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 10, 1, 0, 1, 0, 0, 0, 0, 11, 0, 0, 3, 0, 0, 0, 8, 2, 2, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 6, 4, 1, 3, 3, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 192 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 192 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 193/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 2, 0, 0, 0, 6, 1, 2, 6, 10, 0, 0, 4, 69, 1, 0, 8, 2, 1, 0, 7, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 6, 6, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 193 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 193 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 194/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 1, 0, 4, 127, 1, 0, 0, 6, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 6, 6, 1, 2, 3, 2, 0, 0, 8, 1, 2, 0, 2, 0, 0, 0, 6, 9, 1, 3, 3, 1, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 194 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 28ms/step\n",
      "Modelo 194 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 195/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 15, 1, 2, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 11, 0, 1, 0, 10, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 4, 124, 1, 0, 1, 0, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 195 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 195 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 196/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 13, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 4, 84, 3, 0, 1, 0, 0, 0, 2, 1, 0, 0, 6, 4, 0, 2, 2, 1, 0, 0, 7, 0, 0, 0, 8, 1, 1, 0, 6, 9, 0, 0, 6, 16, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 196 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 21ms/step\n",
      "Modelo 196 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 197/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 2, 1, 0, 0, 4, 32, 0, 0, 4, 16, 3, 0, 2, 1, 0, 0, 6, 13, 0, 1, 5, 0, 0, 0, 8, 1, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 197 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 197 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 198/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 2, 0, 0, 0, 8, 2, 1, 0, 4, 66, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 6, 7, 1, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 198 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 21ms/step\n",
      "Modelo 198 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 199/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 0, 6, 9, 1, 3, 8, 3, 2, 0, 8, 3, 1, 0, 5, 0, 0, 0, 0, 8, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 199 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 199 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 200/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 4, 66, 0, 0, 0, 6, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 4, 33, 2, 0, 3, 2, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 6, 16, 0, 2]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 200 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 15ms/step\n",
      "Modelo 200 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 201/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 2, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 3, 3, 0, 0, 3, 2, 0, 0, 4, 112, 2, 0, 6, 6, 0, 2, 3, 1, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 201 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 201 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 202/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 7, 1, 2, 0, 7, 0, 1, 4, 70, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 6, 11, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 4, 9, 1, 0, 4, 122, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 202 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 7ms/step\n",
      "Modelo 202 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 203/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 65, 3, 0, 4, 100, 2, 0, 6, 6, 1, 2, 4, 26, 0, 0, 8, 3, 2, 0, 3, 2, 0, 0, 1, 0, 0, 0, 6, 14, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 6, 14, 1, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 203 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 23ms/step\n",
      "Modelo 203 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 204/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 3, 1, 0, 0, 0, 4, 0, 2, 3, 3, 0, 0, 3, 0, 0, 0, 4, 102, 1, 0, 4, 50, 2, 0, 0, 5, 1, 2, 1, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 204 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 20ms/step\n",
      "Modelo 204 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 205/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 3, 1, 0, 0, 3, 2, 0, 0, 4, 102, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 8, 2, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 205 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 13ms/step\n",
      "Modelo 205 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 206/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 3, 2, 0, 0, 2, 1, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 4, 1, 2, 0, 6, 4, 1, 1, 0, 4, 0, 3, 4, 54, 2, 0, 1, 0, 0, 0, 6, 4, 0, 1, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 206 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 206 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 207/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 5, 1, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 6, 16, 0, 0, 1, 0, 0, 0, 4, 99, 3, 0, 1, 0, 0, 0, 8, 1, 1, 0, 0, 15, 0, 2, 7, 0, 0, 0, 0, 15, 1, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 207 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 207 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 208/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 36, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 4, 67, 2, 0, 5, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 208 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 30ms/step\n",
      "Modelo 208 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 209/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 7, 1, 0, 4, 78, 2, 0, 0, 15, 1, 3, 5, 0, 0, 0, 8, 2, 1, 0, 5, 0, 0, 0, 8, 1, 1, 0, 6, 4, 1, 1, 7, 0, 0, 0, 5, 0, 0, 0, 6, 14, 0, 0, 6, 9, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 209 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 209 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 210/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 15, 1, 2, 1, 0, 0, 0, 2, 1, 0, 0, 0, 13, 0, 3, 6, 14, 0, 3, 6, 8, 0, 1, 8, 1, 1, 0, 6, 15, 0, 3, 2, 1, 0, 0, 0, 7, 0, 1, 7, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 210 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 210 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 211/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 5, 0, 0, 0, 6, 8, 1, 2, 4, 15, 2, 0, 2, 1, 0, 0, 8, 2, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0, 8, 3, 1, 0, 8, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 211 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 11ms/step\n",
      "Modelo 211 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 212/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 10, 1, 2, 0, 4, 1, 3, 3, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 5, 1, 0, 3, 3, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 212 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 212 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 213/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 8, 1, 1, 0, 0, 10, 0, 2, 8, 2, 2, 0, 3, 0, 0, 0, 0, 7, 0, 3, 8, 2, 2, 0, 1, 0, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 213 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 213 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 214/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 4, 113, 3, 0, 3, 0, 0, 0, 8, 2, 1, 0, 0, 5, 1, 3, 8, 1, 1, 0, 3, 0, 0, 0, 4, 104, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 214 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 214 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 215/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 4, 118, 0, 0, 5, 0, 0, 0, 0, 7, 1, 0, 4, 57, 0, 0, 7, 0, 0, 0, 2, 0, 0, 0, 8, 3, 2, 0, 3, 3, 0, 0, 5, 0, 0, 0, 8, 3, 1, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 215 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 21ms/step\n",
      "Modelo 215 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 216/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 1, 0, 0, 11, 0, 2, 8, 1, 1, 0, 7, 0, 0, 0, 5, 0, 0, 0, 4, 124, 1, 0, 4, 54, 0, 0, 0, 10, 1, 2, 6, 8, 1, 1, 5, 0, 0, 0, 8, 1, 2, 0, 4, 48, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 216 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 216 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 217/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 7, 0, 1, 6, 14, 0, 3, 8, 2, 2, 0, 7, 0, 0, 0, 8, 2, 2, 0, 3, 1, 0, 0, 4, 94, 2, 0, 8, 3, 2, 0, 8, 2, 1, 0, 0, 9, 0, 0, 0, 16, 1, 3, 0, 13, 1, 3]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 217 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 58ms/step\n",
      "Modelo 217 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 218/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 4, 65, 3, 0, 2, 1, 0, 0, 0, 14, 1, 1, 2, 1, 0, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 0, 13, 0, 0, 4, 124, 2, 0, 5, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 218 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 218 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 219/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 6, 8, 1, 1, 6, 14, 0, 2, 2, 1, 0, 0, 2, 0, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0, 0, 14, 1, 1, 8, 1, 1, 0, 7, 0, 0, 0, 6, 7, 0, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 219 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 219 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 220/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 3, 1, 0, 0, 8, 1, 2, 0, 3, 3, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 4, 38, 2, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 220 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 220 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 221/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 1, 0, 1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 6, 0, 2, 1, 0, 0, 0, 8, 2, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 15, 1, 1, 6, 13, 0, 1, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 221 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 11ms/step\n",
      "Modelo 221 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 222/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 10, 1, 2, 0, 9, 0, 1, 5, 0, 0, 0, 5, 0, 0, 0, 6, 15, 0, 2, 3, 3, 0, 0, 8, 2, 2, 0, 4, 37, 0, 0, 0, 7, 0, 2, 7, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 222 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 222 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 223/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 10, 0, 2, 0, 14, 0, 1, 2, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 6, 10, 0, 2, 2, 1, 0, 0, 6, 5, 0, 2, 7, 0, 0, 0, 4, 72, 3, 0, 6, 14, 1, 3, 4, 16, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 223 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 12ms/step\n",
      "Modelo 223 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 224/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 1, 0, 4, 81, 3, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 16, 0, 3, 7, 0, 0, 0, 0, 6, 0, 2, 1, 0, 0, 0, 4, 111, 0, 0, 4, 128, 1, 0, 1, 0, 0, 0, 3, 2, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 224 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 2s 46ms/step\n",
      "Modelo 224 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 225/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 2, 0, 5, 0, 0, 0, 5, 0, 0, 0, 4, 11, 1, 0, 3, 0, 0, 0, 4, 112, 2, 0, 2, 0, 0, 0, 8, 1, 1, 0, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 225 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 31ms/step\n",
      "Modelo 225 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 226/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 7, 0, 3, 6, 9, 1, 2, 3, 1, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 4, 115, 2, 0, 0, 12, 1, 0, 1, 0, 0, 0, 8, 2, 2, 0, 4, 127, 3, 0, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 226 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 11ms/step\n",
      "Modelo 226 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 227/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 7, 1, 1, 4, 122, 2, 0, 4, 24, 1, 0, 5, 0, 0, 0, 0, 5, 1, 1, 5, 0, 0, 0, 2, 1, 0, 0, 8, 1, 1, 0, 6, 4, 1, 3, 4, 7, 2, 0, 4, 124, 1, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 227 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 227 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 228/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 12, 1, 2, 2, 0, 0, 0, 4, 38, 3, 0, 1, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 8, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 228 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 228 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 229/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 12, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 6, 8, 1, 1, 3, 2, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 4, 54, 3, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 229 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 15ms/step\n",
      "Modelo 229 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 230/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 12, 0, 2, 8, 1, 2, 0, 1, 0, 0, 0, 7, 0, 0, 0, 6, 6, 0, 3, 0, 6, 1, 2, 3, 3, 0, 0, 1, 0, 0, 0, 0, 6, 1, 1, 0, 10, 0, 2, 2, 0, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 230 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 230 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 231/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 16, 1, 3, 5, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 4, 100, 2, 0, 5, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 8, 3, 1, 0, 0, 16, 1, 2, 2, 1, 0, 0, 0, 9, 0, 1]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 231 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 8ms/step\n",
      "Modelo 231 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 232/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 3, 2, 0, 6, 9, 1, 3, 5, 0, 0, 0, 2, 1, 0, 0, 0, 8, 1, 3, 4, 74, 0, 0, 6, 8, 1, 0, 8, 2, 2, 0, 8, 1, 2, 0, 4, 11, 2, 0, 0, 12, 1, 2, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 232 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 12ms/step\n",
      "Modelo 232 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 233/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 10, 1, 2, 4, 20, 3, 0, 4, 5, 0, 0, 0, 11, 0, 0, 5, 0, 0, 0, 0, 15, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 12, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 233 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 233 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 234/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 2, 1, 0, 0, 7, 0, 0, 0, 8, 3, 1, 0, 2, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 4, 61, 0, 0, 3, 0, 0, 0, 4, 71, 3, 0, 2, 1, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 234 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 10ms/step\n",
      "Modelo 234 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 235/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [2, 1, 0, 0, 8, 3, 1, 0, 2, 0, 0, 0, 8, 3, 1, 0, 6, 11, 0, 2, 2, 1, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 6, 10, 0, 2, 7, 0, 0, 0, 3, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 235 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 235 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 236/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 0, 0, 0, 0, 8, 1, 0, 0, 5, 1, 2, 6, 13, 1, 2, 3, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 3, 3, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 236 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 236 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 237/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 2, 0, 7, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 3, 2, 0, 0, 6, 15, 0, 1, 0, 8, 0, 2, 0, 14, 0, 0, 0, 5, 1, 2, 1, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 237 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 13ms/step\n",
      "Modelo 237 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 238/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [5, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 8, 1, 2, 0, 4, 3, 2, 0, 6, 5, 0, 1, 1, 0, 0, 0, 0, 9, 0, 3, 2, 0, 0, 0, 8, 3, 1, 0, 5, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 238 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 4ms/step\n",
      "Modelo 238 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 239/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 6, 10, 1, 1, 3, 3, 0, 0, 3, 1, 0, 0, 8, 3, 1, 0, 7, 0, 0, 0, 2, 0, 0, 0, 4, 64, 0, 0, 6, 11, 1, 3, 6, 6, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 239 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 239 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 240/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [6, 6, 1, 1, 7, 0, 0, 0, 2, 1, 0, 0, 4, 42, 0, 0, 8, 1, 2, 0, 0, 7, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 12, 1, 1, 4, 26, 3, 0, 0, 15, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 240 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 240 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 241/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 4, 8, 3, 0, 3, 3, 0, 0, 1, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 3, 0, 0, 0, 4, 122, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 241 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 19ms/step\n",
      "Modelo 241 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 242/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 2, 1, 0, 7, 0, 0, 0, 3, 0, 0, 0, 0, 10, 1, 0, 0, 13, 1, 3, 0, 16, 1, 2, 7, 0, 0, 0, 6, 6, 1, 1, 8, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 242 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 242 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 243/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 3, 0, 0, 4, 71, 0, 0, 4, 44, 1, 0, 3, 1, 0, 0, 3, 2, 0, 0, 5, 0, 0, 0, 0, 11, 1, 1, 0, 5, 0, 0, 6, 14, 1, 0, 0, 13, 1, 3, 8, 1, 1, 0, 2, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 243 sin K-Fold Cross Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 12ms/step\n",
      "Modelo 243 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 244/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [7, 0, 0, 0, 2, 1, 0, 0, 0, 4, 1, 1, 2, 1, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 8, 3, 2, 0, 5, 0, 0, 0, 1, 0, 0, 0, 4, 19, 2, 0, 6, 7, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 244 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 244 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 245/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [1, 0, 0, 0, 8, 2, 2, 0, 3, 2, 0, 0, 8, 3, 2, 0, 1, 0, 0, 0, 3, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 6, 6, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 245 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 13ms/step\n",
      "Modelo 245 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 246/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [8, 2, 1, 0, 8, 3, 2, 0, 0, 8, 1, 0, 0, 10, 1, 1, 3, 1, 0, 0, 6, 8, 0, 3, 4, 50, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 6, 13, 0, 0, 3, 1, 0, 0, 5, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 246 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 16ms/step\n",
      "Modelo 246 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 247/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 15, 1, 0, 1, 0, 0, 0, 0, 5, 1, 1, 3, 2, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 3, 0, 0, 0, 0, 8, 0, 3, 0, 7, 0, 0, 0, 7, 1, 2, 1, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 247 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Modelo 247 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 248/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [0, 14, 0, 1, 5, 0, 0, 0, 2, 0, 0, 0, 7, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 6, 7, 0, 1, 8, 2, 2, 0, 5, 0, 0, 0, 8, 3, 1, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 248 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Modelo 248 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 249/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [4, 2, 3, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 11, 1, 3, 4, 58, 3, 0, 2, 0, 0, 0, 0, 11, 0, 2, 2, 0, 0, 0, 6, 10, 1, 0, 6, 10, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 249 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 6ms/step\n",
      "Modelo 249 completado y resultados almacenados.\n",
      "\n",
      "Procesando modelo 250/250...\n",
      "Generando y codificando arquitectura aleatoria...\n",
      "Final Encoded Model: [3, 1, 0, 0, 3, 2, 0, 0, 2, 1, 0, 0, 0, 12, 1, 1, 6, 6, 1, 0, 0, 8, 1, 3, 0, 14, 1, 1, 1, 0, 0, 0, 7, 0, 0, 0, 8, 2, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "Reparando y decodificando la arquitectura...\n",
      "Entrenando modelo 250 sin K-Fold Cross Validation...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "Modelo 250 completado y resultados almacenados.\n",
      "Resultados guardados en 'model_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torchaudio\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Resizing, Conv2D, Dropout, BatchNormalization, MaxPooling2D, MaxPool2D, Flatten, Dense, Input, LeakyReLU\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Importar funciones previamente definidas para codificar, decodificar y reparar arquitecturas\n",
    "# Y otras dependencias específicas como `build_tf_model_from_dict`, `generate_random_architecture`, etc.\n",
    "\n",
    "# Configuración de parámetros\n",
    "class Config:\n",
    "    def __init__(self, architecture='random', epochs=50, sample_rate=None, time=5, n_splits=5, window_size=5):\n",
    "        self.architecture = architecture\n",
    "        self.epochs = epochs\n",
    "        self.sample_rate = sample_rate\n",
    "        self.time = time\n",
    "        self.n_splits = n_splits\n",
    "        self.window_size = window_size\n",
    "\n",
    "# Cargar datos de audio\n",
    "def load_audio_data(directory, window_size, sample_rate):\n",
    "    audio_dict = {}\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            waveform, sr = torchaudio.load(os.path.join(directory, file_name))\n",
    "            if sample_rate is None:\n",
    "                sample_rate = sr\n",
    "            num_windows = int(waveform.shape[1] / (window_size * sample_rate))\n",
    "            for i in range(num_windows):\n",
    "                start = i * window_size * sample_rate\n",
    "                end = (i + 1) * window_size * sample_rate\n",
    "                audio_dict[f\"{file_name}_{i}\"] = waveform[:, start:end].numpy()\n",
    "    return audio_dict, sample_rate\n",
    "\n",
    "# Preprocesar datos de audio\n",
    "def preprocess_audio(audio_dict, sample_rate):\n",
    "    audio_dict = copy.deepcopy(audio_dict)\n",
    "    n_mels = 128\n",
    "    n_fft = int(sample_rate * 0.029)\n",
    "    hop_length = int(sample_rate * 0.010)\n",
    "    win_length = int(sample_rate * 0.025)\n",
    "\n",
    "    for filename, waveform in tqdm(audio_dict.items(), desc='MELSPECTROGRAM'):\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mels, hop_length=hop_length, win_length=win_length)(waveform)\n",
    "        spec = torchaudio.transforms.AmplitudeToDB()(spec)\n",
    "        spec = spec.numpy()\n",
    "        spec = (spec - spec.min()) / (spec.max() - spec.min())\n",
    "        audio_dict[filename] = spec\n",
    "    return audio_dict\n",
    "\n",
    "# Padding de los espectrogramas\n",
    "def pad_and_crop_spectrograms(spectrograms, target_shape=(128, 128)):\n",
    "    padded_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        if spec.shape[0] > target_shape[0]:\n",
    "            spec = spec[:target_shape[0], :]\n",
    "        if spec.shape[1] > target_shape[1]:\n",
    "            spec = spec[:, :target_shape[1]]\n",
    "        \n",
    "        pad_width = [(0, max(0, target_shape[0] - spec.shape[0])), \n",
    "                     (0, max(0, target_shape[1] - spec.shape[1]))]\n",
    "        \n",
    "        padded_spec = np.pad(spec, pad_width, mode='constant')\n",
    "        padded_spectrograms.append(padded_spec)\n",
    "    return np.array(padded_spectrograms)\n",
    "\n",
    "# Split de audio en train y test\n",
    "def train_test_split_audio(audio_dict):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID', 'PHQ-9 Score'], dtype={1: str})\n",
    "    df['labels'] = np.zeros([len(df),], dtype=int)\n",
    "    df.loc[df['PHQ-9 Score'] < 10, 'labels'] = 0\n",
    "    df.loc[df['PHQ-9 Score'] >= 10, 'labels'] = 1\n",
    "\n",
    "    labels = df.set_index('Participant_ID').to_dict()['labels']\n",
    "\n",
    "    X, Y = [], []\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        if ID in labels:\n",
    "            dep = 0 if labels[ID] == 0 else 1\n",
    "            [X.append(x) for x in data]\n",
    "            [Y.append(dep) for x in data]\n",
    "\n",
    "    X = pad_and_crop_spectrograms(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = X[..., np.newaxis]\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# Función de especificidad\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Entrenamiento y evaluación de cada arquitectura decodificada\n",
    "def train_and_evaluate_model(model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config):\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\", 'Precision', 'Recall'])\n",
    "    model.fit(X_train, Y_train, epochs=config.epochs, validation_data=(X_val, Y_val), verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    # Obtener predicciones para métricas adicionales\n",
    "    Y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = results[1]\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    specificity = specificity_score(Y_test, Y_pred)\n",
    "\n",
    "    return [results[0], accuracy, precision, recall, f1, specificity]\n",
    "\n",
    "# Pipeline para generar, decodificar y entrenar modelos\n",
    "def generate_and_train_models(num_models, directory='./SM-27', target_shape=(128, 128, 1), use_kfold=True):\n",
    "    \"\"\"\n",
    "    Genera, entrena y evalúa múltiples modelos con arquitecturas aleatorias, \n",
    "    y guarda los resultados de cada uno en un archivo CSV.\n",
    "    \n",
    "    Parameters:\n",
    "        num_models (int): Número de modelos a generar y entrenar.\n",
    "        directory (str): Directorio con archivos de audio.\n",
    "        target_shape (tuple): Forma objetivo de los espectrogramas.\n",
    "        use_kfold (bool): Si es True, se usa K-Fold Cross Validation; si no, solo un split para entrenamiento y validación.\n",
    "    \"\"\"\n",
    "    # Configuración inicial\n",
    "    results_data = []\n",
    "    config = Config(architecture='random', epochs=50)\n",
    "    \n",
    "    # Cargar y preprocesar datos de audio\n",
    "    print(\"Cargando y preprocesando datos de audio...\")\n",
    "    audio_dict, sample_rate = load_audio_data(directory, config.window_size, config.sample_rate)\n",
    "    audio_dict = preprocess_audio(audio_dict, sample_rate)\n",
    "    X, Y = train_test_split_audio(audio_dict)\n",
    "    X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Configuración de KFold para validación cruzada si se usa\n",
    "    if use_kfold:\n",
    "        kfold = KFold(n_splits=config.n_splits, shuffle=True)\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        print(f\"\\nProcesando modelo {i + 1}/{num_models}...\")\n",
    "        \n",
    "        # Generar una arquitectura aleatoria y codificada\n",
    "        print(\"Generando y codificando arquitectura aleatoria...\")\n",
    "        random_architecture = generate_random_architecture()\n",
    "        encoded_architecture = encode_model_architecture(random_architecture)\n",
    "        \n",
    "        # Decodificar y reparar la arquitectura\n",
    "        print(\"Reparando y decodificando la arquitectura...\")\n",
    "        repaired_architecture = fixArch(encoded_architecture)  # Reparar si es necesario\n",
    "        decoded_model_dict = decode_model_architecture(repaired_architecture)\n",
    "        \n",
    "        # Almacenar la codificación y los resultados de evaluación\n",
    "        model_results = [encoded_architecture]\n",
    "\n",
    "        # Si `use_kfold` es True, se realiza K-Fold Cross Validation\n",
    "        if use_kfold:\n",
    "            fold_results = []\n",
    "            for fold, (train_index, val_index) in enumerate(kfold.split(X_train_val)):\n",
    "                print(f\"Entrenando fold {fold + 1}/{config.n_splits} del modelo {i + 1}...\")\n",
    "                X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "                Y_train, Y_val = Y_train_val[train_index], Y_train_val[val_index]\n",
    "                \n",
    "                # Construir y entrenar el modelo\n",
    "                tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "                fold_results.append(train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config))\n",
    "                print(f\"Fold {fold + 1} completado para modelo {i + 1}.\")\n",
    "\n",
    "            # Promediar los resultados de los pliegues\n",
    "            avg_results = np.mean(fold_results, axis=0)\n",
    "            model_results.extend(avg_results)\n",
    "        \n",
    "        else:\n",
    "            # Entrenamiento sin K-Fold Cross Validation\n",
    "            print(f\"Entrenando modelo {i + 1} sin K-Fold Cross Validation...\")\n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=42)\n",
    "            tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "            single_run_results = train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config)\n",
    "            model_results.extend(single_run_results)\n",
    "            print(f\"Modelo {i + 1} completado y resultados almacenados.\")\n",
    "\n",
    "        results_data.append(model_results)\n",
    "    \n",
    "    # Guardar resultados en CSV\n",
    "    columns = [\"Encoded Architecture\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\"]\n",
    "    results_df = pd.DataFrame(results_data, columns=columns)\n",
    "    results_df.to_csv(\"./model_results_200.csv\", index=False)\n",
    "    print(\"Resultados guardados en 'model_results.csv'\")\n",
    "\n",
    "# Ejecutar la generación y entrenamiento de modelos sin K-Fold Cross Validation\n",
    "generate_and_train_models(num_models=250, target_shape=(128, 128, 1),  use_kfold=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para Loss...\n",
      "MSE para Loss: 23.083759998043448\n",
      "Entrenando modelo para Accuracy...\n",
      "MSE para Accuracy: 0.004411367683333119\n",
      "Entrenando modelo para Precision...\n",
      "MSE para Precision: 0.10011947601730091\n",
      "Entrenando modelo para Recall...\n",
      "MSE para Recall: 0.13314729103012565\n",
      "Entrenando modelo para F1...\n",
      "MSE para F1: 0.09112849451760346\n",
      "Entrenando modelo para Specificity...\n",
      "MSE para Specificity: 0.0880968583336883\n",
      "Modelos entrenados y guardados.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib  # Para guardar los modelos\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('./model_results_250_50.csv')\n",
    "\n",
    "# Convertir la columna 'Encoded Architecture' de strings a listas de enteros\n",
    "data['Encoded Architecture'] = data['Encoded Architecture'].apply(eval)\n",
    "\n",
    "# Expandir 'Encoded Architecture' en múltiples columnas\n",
    "X = pd.DataFrame(data['Encoded Architecture'].tolist())\n",
    "y_metrics = data[['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_metrics, test_size=0.2, random_state=42)\n",
    "\n",
    "# Diccionario para almacenar modelos y resultados\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Entrenar un modelo XGBoost para cada métrica en y_metrics\n",
    "for metric in y_metrics.columns:\n",
    "    print(f\"Entrenando modelo para {metric}...\")\n",
    "    \n",
    "    # Crear y entrenar el modelo\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train[metric])\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test[metric], y_pred)\n",
    "    print(f\"MSE para {metric}: {mse}\")\n",
    "    \n",
    "    # Guardar el modelo y resultados\n",
    "    models[metric] = model\n",
    "    results[metric] = mse\n",
    "\n",
    "    # Guardar el modelo entrenado en disco\n",
    "    joblib.dump(model, f\"{metric}_surrogate_model.pkl\")\n",
    "\n",
    "print(\"Modelos entrenados y guardados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando arquitectura 1...\n",
      "Final Encoded Model: [4, 53, 2, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 0, 8, 1, 3, 2, 1, 0, 0, 0, 9, 1, 0, 8, 3, 1, 0, 8, 2, 2, 0, 2, 0, 0, 0, 3, 2, 0, 0, 3, 3, 0, 0]\n",
      "Arquitectura de ejemplo: [[ 4 53  2  0  1  0  0  0  2  1  0  0  7  0  0  0  0  8  1  3  2  1  0  0\n",
      "   0  9  1  0  8  3  1  0  8  2  2  0  2  0  0  0  3  2  0  0  3  3  0  0]]\n",
      "Predicción de Loss para la arquitectura 1: 0.7078891396522522\n",
      "Predicción de Accuracy para la arquitectura 1: 0.5194331407546997\n",
      "Predicción de Precision para la arquitectura 1: 0.4024452865123749\n",
      "Predicción de Recall para la arquitectura 1: 0.426135778427124\n",
      "Predicción de F1 para la arquitectura 1: 0.12071824073791504\n",
      "Predicción de Specificity para la arquitectura 1: 0.6441644430160522\n",
      "\n",
      "Generando arquitectura 2...\n",
      "Final Encoded Model: [8, 2, 2, 0, 2, 1, 0, 0, 8, 1, 2, 0, 4, 60, 3, 0, 4, 64, 2, 0, 8, 1, 2, 0, 5, 0, 0, 0, 4, 53, 2, 0, 2, 1, 0, 0, 1, 0, 0, 0, 8, 1, 2, 0, 8, 3, 1, 0]\n",
      "Ajustando alcance de repetición de 2 a 0 debido a falta de capas.\n",
      "Arquitectura de ejemplo: [[ 8  0  2  0  2  1  0  0  8  1  2  0  4 60  3  0  4 64  2  0  8  1  2  0\n",
      "   5  0  0  0  4 53  2  0  7  0  0  0  1  0  0  0  8  1  2  0  8  3  1  0]]\n",
      "Predicción de Loss para la arquitectura 2: 0.9031813740730286\n",
      "Predicción de Accuracy para la arquitectura 2: 0.6157361268997192\n",
      "Predicción de Precision para la arquitectura 2: 0.5145900249481201\n",
      "Predicción de Recall para la arquitectura 2: 0.49672049283981323\n",
      "Predicción de F1 para la arquitectura 2: 0.40510597825050354\n",
      "Predicción de Specificity para la arquitectura 2: 0.6375025510787964\n",
      "\n",
      "Generando arquitectura 3...\n",
      "Final Encoded Model: [0, 16, 1, 0, 8, 2, 1, 0, 5, 0, 0, 0, 5, 0, 0, 0, 4, 123, 2, 0, 0, 12, 1, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 14, 1, 1, 5, 0, 0, 0, 0, 10, 1, 2, 4, 66, 3, 0]\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "Arquitectura de ejemplo: [[  0  16   1   0   8   1   1   0   7   0   0   0   7   0   0   0   4 123\n",
      "    2   0   0  12   1   3   1   0   0   0   1   0   0   0   0  14   1   1\n",
      "    5   0   0   0   7   0   0   0   4  66   3   0]]\n",
      "Predicción de Loss para la arquitectura 3: 0.7076255679130554\n",
      "Predicción de Accuracy para la arquitectura 3: 0.5589463114738464\n",
      "Predicción de Precision para la arquitectura 3: 0.5998307466506958\n",
      "Predicción de Recall para la arquitectura 3: 0.18938499689102173\n",
      "Predicción de F1 para la arquitectura 3: 0.3328455984592438\n",
      "Predicción de Specificity para la arquitectura 3: 0.8085334300994873\n",
      "\n",
      "Generando arquitectura 4...\n",
      "Final Encoded Model: [4, 39, 0, 0, 0, 5, 1, 2, 5, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 8, 3, 1, 0, 6, 11, 1, 0, 2, 0, 0, 0, 4, 75, 3, 0, 1, 0, 0, 0, 4, 108, 2, 0]\n",
      "Arquitectura de ejemplo: [[  4  39   0   0   0   5   1   2   7   0   0   0   7   0   0   0   1   0\n",
      "    0   0   5   0   0   0   8   3   1   0   7   0   0   0   7   0   0   0\n",
      "    4  75   3   0   1   0   0   0   4 108   2   0]]\n",
      "Predicción de Loss para la arquitectura 4: 0.7061278223991394\n",
      "Predicción de Accuracy para la arquitectura 4: 0.5521804094314575\n",
      "Predicción de Precision para la arquitectura 4: 0.43844524025917053\n",
      "Predicción de Recall para la arquitectura 4: -0.008633260615170002\n",
      "Predicción de F1 para la arquitectura 4: 0.39309245347976685\n",
      "Predicción de Specificity para la arquitectura 4: 0.7304865717887878\n",
      "\n",
      "Generando arquitectura 5...\n",
      "Final Encoded Model: [0, 8, 1, 0, 6, 5, 0, 3, 3, 0, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 0, 0, 12, 1, 2, 2, 0, 0, 0]\n",
      "Arquitectura de ejemplo: [[0 8 1 0 6 5 0 3 3 0 0 0 8 2 2 0 5 0 0 0 3 1 0 0 1 0 0 0 7 0 0 0 7 0 0 0\n",
      "  7 0 0 0 7 0 0 0 7 0 0 0]]\n",
      "Predicción de Loss para la arquitectura 5: 0.6489980816841125\n",
      "Predicción de Accuracy para la arquitectura 5: 0.5623677968978882\n",
      "Predicción de Precision para la arquitectura 5: 0.16525311768054962\n",
      "Predicción de Recall para la arquitectura 5: 0.5034480690956116\n",
      "Predicción de F1 para la arquitectura 5: 0.4326712191104889\n",
      "Predicción de Specificity para la arquitectura 5: 0.8459272980690002\n",
      "\n",
      "Generando arquitectura 6...\n",
      "Final Encoded Model: [5, 0, 0, 0, 0, 12, 1, 1, 5, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 6, 11, 0, 1, 5, 0, 0, 0, 6, 6, 1, 2, 6, 7, 0, 2, 0, 12, 0, 3, 4, 124, 1, 0, 2, 0, 0, 0]\n",
      "Arquitectura de ejemplo: [[  7   0   0   0   0  12   1   1   7   0   0   0   7   0   0   0   7   0\n",
      "    0   0   6  11   0   1   5   0   0   0   7   0   0   0   7   0   0   0\n",
      "    7   0   0   0   4 124   1   0   7   0   0   0]]\n",
      "Predicción de Loss para la arquitectura 6: 0.6713988184928894\n",
      "Predicción de Accuracy para la arquitectura 6: 0.6351274251937866\n",
      "Predicción de Precision para la arquitectura 6: 0.25669991970062256\n",
      "Predicción de Recall para la arquitectura 6: 0.044442273676395416\n",
      "Predicción de F1 para la arquitectura 6: 0.41856616735458374\n",
      "Predicción de Specificity para la arquitectura 6: 0.8475292325019836\n",
      "\n",
      "Generando arquitectura 7...\n",
      "Final Encoded Model: [0, 8, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 3, 1, 0, 0, 7, 0, 0, 0, 3, 0, 0, 0, 5, 0, 0, 0, 4, 85, 0, 0, 4, 95, 1, 0, 4, 49, 0, 0]\n",
      "Arquitectura de ejemplo: [[ 0  8  0  3  1  0  0  0  1  0  0  0  7  0  0  0  7  0  0  0  3  1  0  0\n",
      "   7  0  0  0  3  0  0  0  5  0  0  0  4 85  0  0  4 95  1  0  4 49  0  0]]\n",
      "Predicción de Loss para la arquitectura 7: 0.6206872463226318\n",
      "Predicción de Accuracy para la arquitectura 7: 0.67979896068573\n",
      "Predicción de Precision para la arquitectura 7: 0.6322932839393616\n",
      "Predicción de Recall para la arquitectura 7: 0.40558740496635437\n",
      "Predicción de F1 para la arquitectura 7: 0.4124613404273987\n",
      "Predicción de Specificity para la arquitectura 7: 0.7389593720436096\n",
      "\n",
      "Generando arquitectura 8...\n",
      "Final Encoded Model: [8, 3, 1, 0, 0, 15, 1, 1, 6, 16, 1, 1, 8, 2, 1, 0, 0, 14, 0, 2, 3, 2, 0, 0, 4, 23, 1, 0, 7, 0, 0, 0, 6, 13, 0, 2, 2, 0, 0, 0, 5, 0, 0, 0, 8, 1, 1, 0]\n",
      "Ajustando alcance de repetición de 3 a 0 debido a falta de capas.\n",
      "Arquitectura de ejemplo: [[ 8  0  1  0  0 15  1  1  6 16  1  1  8  2  1  0  0 14  0  2  3  2  0  0\n",
      "   4 23  1  0  7  0  0  0  6 13  0  2  2  0  0  0  5  0  0  0  8  1  1  0]]\n",
      "Predicción de Loss para la arquitectura 8: 1.3288569450378418\n",
      "Predicción de Accuracy para la arquitectura 8: 0.5339561104774475\n",
      "Predicción de Precision para la arquitectura 8: -0.02727304771542549\n",
      "Predicción de Recall para la arquitectura 8: 0.05821462720632553\n",
      "Predicción de F1 para la arquitectura 8: 0.15329597890377045\n",
      "Predicción de Specificity para la arquitectura 8: 0.9207659363746643\n",
      "\n",
      "Generando arquitectura 9...\n",
      "Final Encoded Model: [5, 0, 0, 0, 6, 5, 1, 1, 4, 1, 3, 0, 3, 3, 0, 0, 8, 2, 2, 0, 6, 5, 1, 0, 6, 5, 1, 2, 5, 0, 0, 0, 5, 0, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 4, 3, 2, 0]\n",
      "Arquitectura de ejemplo: [[7 0 0 0 6 5 1 1 4 1 3 0 3 3 0 0 8 2 2 0 6 5 1 0 6 5 1 2 5 0 0 0 7 0 0 0\n",
      "  3 1 0 0 3 0 0 0 4 3 2 0]]\n",
      "Predicción de Loss para la arquitectura 9: 0.6740346550941467\n",
      "Predicción de Accuracy para la arquitectura 9: 0.5418204069137573\n",
      "Predicción de Precision para la arquitectura 9: 0.07510403543710709\n",
      "Predicción de Recall para la arquitectura 9: 0.1491633951663971\n",
      "Predicción de F1 para la arquitectura 9: 0.05111662298440933\n",
      "Predicción de Specificity para la arquitectura 9: 0.8448325395584106\n",
      "\n",
      "Generando arquitectura 10...\n",
      "Final Encoded Model: [4, 22, 1, 0, 8, 3, 1, 0, 2, 1, 0, 0, 0, 10, 0, 2, 0, 6, 1, 1, 5, 0, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 54, 0, 0, 6, 9, 0, 1]\n",
      "Ajustando alcance de repetición de 3 a 1 debido a falta de capas.\n",
      "Arquitectura de ejemplo: [[ 4 22  1  0  8  1  1  0  2  1  0  0  0 10  0  2  0  6  1  1  5  0  0  0\n",
      "   7  0  0  0  3  1  0  0  1  0  0  0  7  0  0  0  4 54  0  0  7  0  0  0]]\n",
      "Predicción de Loss para la arquitectura 10: 0.6953796148300171\n",
      "Predicción de Accuracy para la arquitectura 10: 0.5079851746559143\n",
      "Predicción de Precision para la arquitectura 10: 0.4725838601589203\n",
      "Predicción de Recall para la arquitectura 10: 0.38434168696403503\n",
      "Predicción de F1 para la arquitectura 10: 0.2415296733379364\n",
      "Predicción de Specificity para la arquitectura 10: 0.7749441862106323\n",
      "\n",
      "Tabla de predicciones para las 10 arquitecturas generadas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 53, 2, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0,...</td>\n",
       "      <td>0.707889</td>\n",
       "      <td>0.519433</td>\n",
       "      <td>0.402445</td>\n",
       "      <td>0.426136</td>\n",
       "      <td>0.120718</td>\n",
       "      <td>0.644164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[8, 0, 2, 0, 2, 1, 0, 0, 8, 1, 2, 0, 4, 60, 3,...</td>\n",
       "      <td>0.903181</td>\n",
       "      <td>0.615736</td>\n",
       "      <td>0.514590</td>\n",
       "      <td>0.496720</td>\n",
       "      <td>0.405106</td>\n",
       "      <td>0.637503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 16, 1, 0, 8, 1, 1, 0, 7, 0, 0, 0, 7, 0, 0,...</td>\n",
       "      <td>0.707626</td>\n",
       "      <td>0.558946</td>\n",
       "      <td>0.599831</td>\n",
       "      <td>0.189385</td>\n",
       "      <td>0.332846</td>\n",
       "      <td>0.808533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 39, 0, 0, 0, 5, 1, 2, 7, 0, 0, 0, 7, 0, 0,...</td>\n",
       "      <td>0.706128</td>\n",
       "      <td>0.552180</td>\n",
       "      <td>0.438445</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>0.393092</td>\n",
       "      <td>0.730487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 8, 1, 0, 6, 5, 0, 3, 3, 0, 0, 0, 8, 2, 2, ...</td>\n",
       "      <td>0.648998</td>\n",
       "      <td>0.562368</td>\n",
       "      <td>0.165253</td>\n",
       "      <td>0.503448</td>\n",
       "      <td>0.432671</td>\n",
       "      <td>0.845927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[7, 0, 0, 0, 0, 12, 1, 1, 7, 0, 0, 0, 7, 0, 0,...</td>\n",
       "      <td>0.671399</td>\n",
       "      <td>0.635127</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.044442</td>\n",
       "      <td>0.418566</td>\n",
       "      <td>0.847529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 8, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, ...</td>\n",
       "      <td>0.620687</td>\n",
       "      <td>0.679799</td>\n",
       "      <td>0.632293</td>\n",
       "      <td>0.405587</td>\n",
       "      <td>0.412461</td>\n",
       "      <td>0.738959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[8, 0, 1, 0, 0, 15, 1, 1, 6, 16, 1, 1, 8, 2, 1...</td>\n",
       "      <td>1.328857</td>\n",
       "      <td>0.533956</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>0.058215</td>\n",
       "      <td>0.153296</td>\n",
       "      <td>0.920766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[7, 0, 0, 0, 6, 5, 1, 1, 4, 1, 3, 0, 3, 3, 0, ...</td>\n",
       "      <td>0.674035</td>\n",
       "      <td>0.541820</td>\n",
       "      <td>0.075104</td>\n",
       "      <td>0.149163</td>\n",
       "      <td>0.051117</td>\n",
       "      <td>0.844833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[4, 22, 1, 0, 8, 1, 1, 0, 2, 1, 0, 0, 0, 10, 0...</td>\n",
       "      <td>0.695380</td>\n",
       "      <td>0.507985</td>\n",
       "      <td>0.472584</td>\n",
       "      <td>0.384342</td>\n",
       "      <td>0.241530</td>\n",
       "      <td>0.774944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Architecture      Loss  Accuracy  \\\n",
       "0  [4, 53, 2, 0, 1, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0,...  0.707889  0.519433   \n",
       "1  [8, 0, 2, 0, 2, 1, 0, 0, 8, 1, 2, 0, 4, 60, 3,...  0.903181  0.615736   \n",
       "2  [0, 16, 1, 0, 8, 1, 1, 0, 7, 0, 0, 0, 7, 0, 0,...  0.707626  0.558946   \n",
       "3  [4, 39, 0, 0, 0, 5, 1, 2, 7, 0, 0, 0, 7, 0, 0,...  0.706128  0.552180   \n",
       "4  [0, 8, 1, 0, 6, 5, 0, 3, 3, 0, 0, 0, 8, 2, 2, ...  0.648998  0.562368   \n",
       "5  [7, 0, 0, 0, 0, 12, 1, 1, 7, 0, 0, 0, 7, 0, 0,...  0.671399  0.635127   \n",
       "6  [0, 8, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 7, 0, 0, ...  0.620687  0.679799   \n",
       "7  [8, 0, 1, 0, 0, 15, 1, 1, 6, 16, 1, 1, 8, 2, 1...  1.328857  0.533956   \n",
       "8  [7, 0, 0, 0, 6, 5, 1, 1, 4, 1, 3, 0, 3, 3, 0, ...  0.674035  0.541820   \n",
       "9  [4, 22, 1, 0, 8, 1, 1, 0, 2, 1, 0, 0, 0, 10, 0...  0.695380  0.507985   \n",
       "\n",
       "   Precision    Recall        F1  Specificity  \n",
       "0   0.402445  0.426136  0.120718     0.644164  \n",
       "1   0.514590  0.496720  0.405106     0.637503  \n",
       "2   0.599831  0.189385  0.332846     0.808533  \n",
       "3   0.438445 -0.008633  0.393092     0.730487  \n",
       "4   0.165253  0.503448  0.432671     0.845927  \n",
       "5   0.256700  0.044442  0.418566     0.847529  \n",
       "6   0.632293  0.405587  0.412461     0.738959  \n",
       "7  -0.027273  0.058215  0.153296     0.920766  \n",
       "8   0.075104  0.149163  0.051117     0.844833  \n",
       "9   0.472584  0.384342  0.241530     0.774944  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar todos los modelos de métricas\n",
    "metric_models = {}\n",
    "metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']\n",
    "\n",
    "for metric in metrics:\n",
    "    metric_models[metric] = joblib.load(f\"{metric}_surrogate_model.pkl\")\n",
    "\n",
    "# Lista para almacenar resultados de predicciones\n",
    "results = []\n",
    "\n",
    "# Generar 10 arquitecturas y predecir métricas para cada una\n",
    "for i in range(10):\n",
    "    print(f\"\\nGenerando arquitectura {i+1}...\")\n",
    "    \n",
    "    # Generar una arquitectura de ejemplo\n",
    "    model_dict = generate_random_architecture()\n",
    "    encoded_model = encode_model_architecture(model_dict, max_alleles=48)\n",
    "    fixed_model = fixArch(encoded_model, verbose=True)\n",
    "    \n",
    "    # Preparar arquitectura para predicción\n",
    "    example_architecture = np.array(fixed_model).reshape(1, -1)\n",
    "    print(f\"Arquitectura de ejemplo: {example_architecture}\")\n",
    "    \n",
    "    # Predicciones para cada métrica\n",
    "    predictions = {'Architecture': fixed_model}\n",
    "    for metric, model in metric_models.items():\n",
    "        predicted_value = model.predict(example_architecture)[0]\n",
    "        predictions[metric] = predicted_value\n",
    "        print(f\"Predicción de {metric} para la arquitectura {i+1}: {predicted_value}\")\n",
    "    \n",
    "    # Agregar predicciones al conjunto de resultados\n",
    "    results.append(predictions)\n",
    "\n",
    "# Crear un DataFrame de pandas con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nTabla de predicciones para las 10 arquitecturas generadas:\")\n",
    "(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
