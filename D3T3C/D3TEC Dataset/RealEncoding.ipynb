{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, DepthwiseConv2D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codificación real de Conv2D: [0, 16, 0, 0]\n",
      "Decodificación Conv2D: {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Dropout: [3, 1, 0, 0]\n",
      "Decodificación Dropout: {'type': 'Dropout', 'rate': 0.3}\n",
      "\n",
      "Codificación real de Dense: [4, 128, 0, 0]\n",
      "Decodificación Dense: {'type': 'Dense', 'units': 128, 'activation': 'relu'}\n",
      "\n",
      "Codificación real de Repetition: [8, 3, 5, 0]\n",
      "Decodificación Repetition: {'type': 'Repetition', 'repetition_layers': 3, 'repetition_count': 5}\n"
     ]
    }
   ],
   "source": [
    "# Opciones de decodificación para otros parámetros\n",
    "layer_type_options = {\n",
    "    0: 'Conv2D', \n",
    "    1: 'BatchNorm', \n",
    "    2: 'MaxPooling', \n",
    "    3: 'Dropout', \n",
    "    4: 'Dense', \n",
    "    5: 'Flatten',\n",
    "    6: 'DepthwiseConv2D',  \n",
    "    7: 'DontCare',  \n",
    "    8: 'Repetition'\n",
    "}\n",
    "stride_options = {0: 1, 1: 2}\n",
    "dropout_options = {0: 0.2, 1: 0.3, 2: 0.4, 3: 0.5}\n",
    "activation_options = {0: 'relu', 1: 'leaky_relu', 2: 'sigmoid', 3: 'tanh'}\n",
    "\n",
    "# Función para codificar los parámetros de la capa\n",
    "def encode_layer_params(layer_type_idx, param1=0, param2=0, param3=0):\n",
    "    \"\"\"\n",
    "    Codifica una capa en una lista en función del tipo de capa y sus parámetros.\n",
    "    \n",
    "    layer_type_idx : int : índice del tipo de capa según layer_type_options.\n",
    "    param1         : int/float : filtros, neuronas, capas de repetición, etc.\n",
    "    param2         : int : stride, número de repeticiones, etc.\n",
    "    param3         : int : índice de activación o tasa de dropout.\n",
    "    \"\"\"\n",
    "    return [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "# Función para decodificar los parámetros de la capa\n",
    "def decode_layer_params(encoded_params):\n",
    "    \"\"\"\n",
    "    Decodifica una capa desde su representación codificada en parámetros interpretables.\n",
    "    \n",
    "    encoded_params : list : [tipo de capa, param1, param2, param3].\n",
    "    \"\"\"\n",
    "    layer_type_idx = encoded_params[0]\n",
    "    layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "    \n",
    "    # Decodificar en función del tipo de capa\n",
    "    if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "        filters = max(4, min(encoded_params[1], 32))  # Limitar filtros entre 4 y 32\n",
    "        strides = stride_options.get(encoded_params[2], 1)\n",
    "        activation = activation_options.get(encoded_params[3], 'relu')\n",
    "        return {\n",
    "            'type': layer_type,\n",
    "            'filters': filters,\n",
    "            'strides': strides,\n",
    "            'activation': activation\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {'type': 'BatchNorm'}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        strides = stride_options.get(encoded_params[1], 1)\n",
    "        return {'type': 'MaxPooling', 'strides': strides}\n",
    "    elif layer_type == 'Dropout':\n",
    "        rate = dropout_options.get(encoded_params[1], 0.2)\n",
    "        return {'type': 'Dropout', 'rate': rate}\n",
    "    elif layer_type == 'Dense':\n",
    "        units = max(1, min(encoded_params[1], 512))  # Limitar unidades entre 1 y 512\n",
    "        activation = activation_options.get(encoded_params[2], 'relu')\n",
    "        return {'type': 'Dense', 'units': units, 'activation': activation}\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {'type': 'Flatten'}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            'type': 'Repetition',\n",
    "            'repetition_layers': int(encoded_params[1]),\n",
    "            'repetition_count': int(encoded_params[2])\n",
    "        }\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {'type': \"DontCare\"}\n",
    "\n",
    "    return None\n",
    "\n",
    "# Ejemplos de codificación y decodificación\n",
    "encoded_conv2d = encode_layer_params(0, 16, 0, 0)  # Conv2D con 16 filtros, stride 1 y activación ReLU\n",
    "decoded_conv2d = decode_layer_params(encoded_conv2d)\n",
    "print(f\"\\nCodificación real de Conv2D: {encoded_conv2d}\")\n",
    "print(f\"Decodificación Conv2D: {decoded_conv2d}\")\n",
    "\n",
    "encoded_dropout = encode_layer_params(3, 1)  # Dropout con tasa de 0.3\n",
    "decoded_dropout = decode_layer_params(encoded_dropout)\n",
    "print(f\"\\nCodificación real de Dropout: {encoded_dropout}\")\n",
    "print(f\"Decodificación Dropout: {decoded_dropout}\")\n",
    "\n",
    "encoded_dense = encode_layer_params(4, 128, 0)  # Dense con 128 neuronas y activación ReLU\n",
    "decoded_dense = decode_layer_params(encoded_dense)\n",
    "print(f\"\\nCodificación real de Dense: {encoded_dense}\")\n",
    "print(f\"Decodificación Dense: {decoded_dense}\")\n",
    "\n",
    "encoded_repetition = encode_layer_params(8, 3, 5)  # Repetition para repetir las últimas 3 capas 5 veces\n",
    "decoded_repetition = decode_layer_params(encoded_repetition)\n",
    "print(f\"\\nCodificación real de Repetition: {encoded_repetition}\")\n",
    "print(f\"Decodificación Repetition: {decoded_repetition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete archs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para capas neutrales 'DontCare'\n",
    "class DontCareLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(DontCareLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_model_architecture(model_dict, max_alleles=48):\n",
    "    \"\"\"\n",
    "    Codifica la arquitectura del modelo en una lista de valores con un máximo de `max_alleles`.\n",
    "    Cada capa se codifica en función de sus parámetros.\n",
    "    \"\"\"\n",
    "    encoded_layers = []\n",
    "    total_alleles = 0\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Repetition':  # Codificar capa de repetición\n",
    "            encoded_layer = encode_layer_params(\n",
    "                layer_type_idx=8,  # índice para 'Repetition'\n",
    "                param1=layer.get('repetition_layers', 0),\n",
    "                param2=layer.get('repetition_count', 1)\n",
    "            )\n",
    "        else:\n",
    "            layer_type_idx = next(\n",
    "                key for key, value in layer_type_options.items() if value == layer['type']\n",
    "            )\n",
    "            \n",
    "            # Codificar parámetros específicos de cada tipo de capa\n",
    "            if layer['type'] in ['Conv2D', 'DepthwiseConv2D']:  \n",
    "                # Limitar filtros dentro del rango [4, 32]\n",
    "                param1 = max(4, min(layer.get('filters', 8), 32))  \n",
    "                param2 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                param3 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, param3]\n",
    "\n",
    "            elif layer['type'] == 'Dense':\n",
    "                # Limitar neuronas dentro del rango [1, 512]\n",
    "                param1 = max(1, min(layer.get('units', 1), 512))\n",
    "                param2 = next((key for key, value in activation_options.items() if value == layer.get('activation', 'relu')), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, param2, 0]\n",
    "\n",
    "            elif layer['type'] == 'MaxPooling':\n",
    "                param1 = next((key for key, value in stride_options.items() if value == layer.get('strides', 1.0)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Dropout':\n",
    "                param1 = next((key for key, value in dropout_options.items() if value == layer.get('rate', 0.2)), 0)\n",
    "                encoded_layer = [layer_type_idx, param1, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'BatchNorm':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'Flatten':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "            elif layer['type'] == 'DontCare':\n",
    "                encoded_layer = [layer_type_idx, 0, 0, 0]\n",
    "\n",
    "        # Añadir la codificación de la capa a la lista de alelos\n",
    "        encoded_layers.extend(encoded_layer)\n",
    "        total_alleles += len(encoded_layer)\n",
    "\n",
    "    # Rellenar con 'DontCare' si el total de alelos es menor que `max_alleles`\n",
    "    while total_alleles < max_alleles:\n",
    "        dont_care_encoding = encode_layer_params(7)  # índice de 'DontCare'\n",
    "        encoded_layers.extend(dont_care_encoding)\n",
    "        total_alleles += len(dont_care_encoding)\n",
    "\n",
    "    # Recortar si excede `max_alleles`\n",
    "    final_encoding = encoded_layers[:max_alleles]\n",
    "    print(f\"Final Encoded Model: {final_encoding}\")\n",
    "    \n",
    "    return final_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fixArch(encoded_model, verbose=False):\n",
    "    \"\"\"\n",
    "    Corrige la arquitectura codificada del modelo, asegurando que:\n",
    "    - Se evite la presencia de capas incompatibles después de una capa Flatten.\n",
    "    - En caso de una capa de Repetition, se ajuste el alcance de repetición si no hay suficientes capas anteriores.\n",
    "\n",
    "    Parameters:\n",
    "        encoded_model (list): Lista codificada de la arquitectura del modelo.\n",
    "        verbose (bool): Si es True, muestra las correcciones realizadas.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista con la arquitectura corregida, truncada a un máximo de 48 alelos.\n",
    "    \"\"\"\n",
    "\n",
    "    fixed_layers = []  # Lista que almacenará la arquitectura corregida\n",
    "    input_is_flattened = False  # Indicador para saber si ya hay una capa Flatten en el modelo\n",
    "    index = 0  # Índice para recorrer el modelo codificado\n",
    "\n",
    "    # Procesar cada capa en el modelo sin forzar la primera capa a ser específica\n",
    "    while index < len(encoded_model) and len(fixed_layers) < 48:\n",
    "        layer_type = int(encoded_model[index])  # Obtener el tipo de capa actual\n",
    "\n",
    "        # Procesar la capa de Repetition\n",
    "        if layer_type == 8:\n",
    "            repetition_layers = int(encoded_model[index + 1])  # Número de capas a repetir\n",
    "            repetition_count = min(max(int(encoded_model[index + 2]), 0), 32)  # Cantidad de repeticiones\n",
    "\n",
    "            # Verificar si hay suficientes capas para la repetición solicitada\n",
    "            actual_layers_to_repeat = min(repetition_layers, len(fixed_layers) // 4)\n",
    "\n",
    "            if actual_layers_to_repeat != repetition_layers:\n",
    "                if verbose:\n",
    "                    print(f\"Ajustando alcance de repetición de {repetition_layers} a {actual_layers_to_repeat} debido a falta de capas.\")\n",
    "                repetition_layers = actual_layers_to_repeat\n",
    "\n",
    "            # Añadir la capa de repetición sin modificar su estructura\n",
    "            fixed_layers.extend([layer_type, repetition_layers, repetition_count, 0])\n",
    "            index += 4\n",
    "            continue\n",
    "\n",
    "        # Procesar cada tipo de capa normal con sus restricciones\n",
    "        if layer_type == 0:  # Conv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "\n",
    "        elif layer_type == 6:  # DepthwiseConv2D\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                # Limitar el número de filtros entre 4 y 32\n",
    "                filters = min(max(int(encoded_model[index + 1]), 4), 32)\n",
    "                stride_idx = min(max(int(encoded_model[index + 2]), 0), 1)\n",
    "                activation_idx = min(max(int(encoded_model[index + 3]), 0), 3)\n",
    "                fixed_layers.extend([layer_type, filters, stride_idx, activation_idx])\n",
    "\n",
    "        elif layer_type == 2:  # MaxPooling\n",
    "            if input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                stride_idx = min(max(int(encoded_model[index + 1]), 0), 1)\n",
    "                fixed_layers.extend([layer_type, stride_idx, 0, 0])\n",
    "\n",
    "        elif layer_type == 3:  # Dropout\n",
    "            rate_idx = min(max(int(encoded_model[index + 1]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, rate_idx, 0, 0])\n",
    "\n",
    "        elif layer_type == 4:  # Dense\n",
    "            # Limitar el número de neuronas entre 1 y 512\n",
    "            neurons = min(max(int(encoded_model[index + 1]), 1), 512)\n",
    "            activation_idx = min(max(int(encoded_model[index + 2]), 0), 3)\n",
    "            fixed_layers.extend([layer_type, neurons, activation_idx, 0])\n",
    "\n",
    "        elif layer_type == 1:  # BatchNorm\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        elif layer_type == 5:  # Flatten\n",
    "            if len(fixed_layers) < 16:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            elif input_is_flattened:\n",
    "                fixed_layers.extend([7, 0, 0, 0])  # DontCare\n",
    "            else:\n",
    "                fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "                input_is_flattened = True  # Marcar que ya hay un Flatten\n",
    "\n",
    "        elif layer_type == 7:  # DontCare\n",
    "            fixed_layers.extend([layer_type, 0, 0, 0])\n",
    "\n",
    "        else: # DontCare\n",
    "          fixed_layers.extend([7, 0, 0, 0])\n",
    "\n",
    "        index += 4  # Avanzar al siguiente grupo de parámetros\n",
    "\n",
    "    return fixed_layers[:48]  # Limitar a 48 alelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ejemplo 1 ---\n",
      "Modelo Original: 48 alelos\n",
      "[0, 3, 0, 0, 2, 1, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 1, 1, 0, 6, 1, 1, 0, 5, 0, 0, 0, 4, 3, 2, 0, 4, 1, 3, 0, 4, 1, 2, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 0, 0, 2, 1, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 4, 1, 0, 6, 4, 1, 0, 5, 0, 0, 0, 4, 3, 2, 0, 4, 1, 3, 0, 4, 1, 2, 0]\n",
      "\n",
      "--- Ejemplo 2 ---\n",
      "Modelo Original: 48 alelos\n",
      "[5, 0, 0, 0, 0, 2, 1, 1, 2, 1, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 2, 1, 0, 4, 2, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 4, 3, 3, 0, 7, 0, 0, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[7, 0, 0, 0, 0, 4, 1, 1, 2, 1, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 6, 4, 1, 0, 4, 2, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 4, 3, 3, 0, 7, 0, 0, 0]\n",
      "\n",
      "--- Ejemplo 3 ---\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "Modelo Original: 48 alelos\n",
      "[0, 1, 0, 0, 8, 2, 2, 0, 5, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 2, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 0, 0, 8, 1, 2, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 4, 1, 0, 0, 4, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "\n",
      "--- Ejemplo 4 ---\n",
      "Modelo Original: 48 alelos\n",
      "[0, 4, 2, 1, 3, 5, 0, 0, 4, 5, 3, 0, 6, 4, 2, 0, 1, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 4, 3, 1, 0, 7, 0, 0, 0, 4, 1, 2, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 1, 1, 3, 3, 0, 0, 4, 5, 3, 0, 6, 4, 1, 0, 1, 0, 0, 0, 3, 3, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 3, 1, 0, 7, 0, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "--- Ejemplo 5 ---\n",
      "Ajustando alcance de repetición de 2 a 1 debido a falta de capas.\n",
      "Modelo Original: 48 alelos\n",
      "[0, 2, 1, 0, 8, 2, 3, 0, 5, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 2, 1, 0, 0, 3, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n",
      "Modelo Corregido: 48 alelos\n",
      "[0, 4, 1, 0, 8, 1, 3, 0, 7, 0, 0, 0, 2, 1, 0, 0, 3, 1, 0, 0, 6, 4, 1, 0, 0, 4, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 2, 1, 0, 7, 0, 0, 0, 3, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar ejemplos de prueba para la función fixArch con arquitecturas de 12 capas (48 valores en total)\n",
    "\n",
    "# Ejemplo 1: Arquitectura sin Flatten antes de Dense y con capas adicionales\n",
    "encoded_model_1 = [\n",
    "    0, 3, 0, 0,    # Conv2D, 32 filtros, stride 1, activación relu\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu (sin Flatten antes)\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    3, 2, 0, 0,    # Dropout, tasa 0.4\n",
    "    0, 1, 1, 0,    # Conv2D, 16 filtros, stride 2, activación relu\n",
    "    6, 1, 1, 0,    # DepthwiseConv2D, 16 filtros, stride 2, activación relu\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    4, 3, 2, 0,    # Dense, 256 neuronas, activación sigmoid\n",
    "    4, 1, 3, 0,    # Dense, 32 neuronas, activación tanh\n",
    "    4, 1, 2, 0     # Dense, 32 neuronas, activación sigmoid\n",
    "]\n",
    "\n",
    "# Ejemplo 2: Arquitectura con Flatten al inicio (inválido) y sin Dense al final\n",
    "encoded_model_2 = [\n",
    "    5, 0, 0, 0,    # Flatten (inválido al inicio)\n",
    "    0, 2, 1, 1,    # Conv2D, 30 filtros, stride 2, activación leaky_relu\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    3, 1, 0, 0,    # Dropout, tasa 0.3\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    0, 1, 0, 0,    # Conv2D, 16 filtros, stride 1, activación relu\n",
    "    6, 2, 1, 0,    # DepthwiseConv2D, 30 filtros, stride 2, activación relu\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu\n",
    "    3, 0, 0, 0,    # Dropout, tasa 0.2\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    4, 3, 3, 0,    # Dense, 256 neuronas, activación tanh\n",
    "    7, 0, 0, 0     # DontCare\n",
    "]\n",
    "\n",
    "# Ejemplo 3: Arquitectura con Repetition y sin Dense al final\n",
    "encoded_model_3 = [\n",
    "    0, 1, 0, 0,    # Conv2D, 16 filtros, stride 1, activación relu\n",
    "    8, 2, 2, 0,    # Repetition, repite las últimas 2 capas 2 veces\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    3, 1, 0, 0,    # Dropout, tasa 0.3\n",
    "    6, 2, 1, 0,    # DepthwiseConv2D, 30 filtros, stride 2, activación relu\n",
    "    0, 3, 0, 1,    # Conv2D, 32 filtros, stride 1, activación leaky_relu\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    3, 2, 0, 0     # Dropout, tasa 0.4\n",
    "]\n",
    "\n",
    "# Ejemplo 4: Arquitectura con parámetros fuera de límite\n",
    "encoded_model_4 = [\n",
    "    0, 4, 2, 1,    # Conv2D, 64 filtros (fuera de límite), stride 2, activación leaky_relu\n",
    "    3, 5, 0, 0,    # Dropout, tasa 0.6 (fuera de límite)\n",
    "    4, 5, 3, 0,    # Dense, 512 neuronas (fuera de límite), activación sigmoid\n",
    "    6, 4, 2, 0,    # DepthwiseConv2D, 64 filtros (fuera de límite), stride 2, activación relu\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    3, 3, 0, 0,    # Dropout, tasa 0.5\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    0, 1, 0, 0,    # Conv2D, 16 filtros, stride 1, activación relu\n",
    "    4, 3, 1, 0,    # Dense, 256 neuronas, activación leaky_relu\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    4, 1, 2, 0     # Dense, 32 neuronas, activación sigmoid\n",
    "]\n",
    "# Ejemplo 5: Arquitectura con capa de Repetition que repite las últimas capas\n",
    "encoded_model_5 = [\n",
    "    0, 2, 1, 0,    # Conv2D, 30 filtros, stride 2, activación relu\n",
    "    8, 2, 3, 0,    # Repetition, repite las últimas 2 capas 3 veces\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    2, 1, 0, 0,    # MaxPooling, stride 2\n",
    "    3, 1, 0, 0,    # Dropout, tasa 0.3\n",
    "    6, 2, 1, 0,    # DepthwiseConv2D, 30 filtros, stride 2, activación relu\n",
    "    0, 3, 0, 1,    # Conv2D, 32 filtros, stride 1, activación leaky_relu\n",
    "    1, 0, 0, 0,    # BatchNorm\n",
    "    5, 0, 0, 0,    # Flatten\n",
    "    4, 2, 1, 0,    # Dense, 128 neuronas, activación leaky_relu\n",
    "    7, 0, 0, 0,    # DontCare\n",
    "    3, 2, 0, 0     # Dropout, tasa 0.4\n",
    "]\n",
    "\n",
    "# Lista de modelos para probar\n",
    "model_examples = [encoded_model_1, encoded_model_2, encoded_model_3, encoded_model_4, encoded_model_5]\n",
    "\n",
    "# Ejecución de pruebas\n",
    "for i, model in enumerate(model_examples, 1):\n",
    "    print(f\"\\n--- Ejemplo {i} ---\")\n",
    "    fixed_model = fixArch(model, verbose=True)\n",
    "    print(f\"Modelo Original: {len(model)} alelos\\n{model}\") \n",
    "    print(f\"Modelo Corregido: {len(fixed_model)} alelos\\n{fixed_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_model_architecture(encoded_model):\n",
    "    \"\"\"\n",
    "    Decodifica la arquitectura del modelo a partir de la lista codificada de valores (índices),\n",
    "    aplicando las reglas de repetición y asegurando la inclusión de una capa convolucional inicial.\n",
    "    \"\"\"\n",
    "    model_dict = {'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}]}  # Inserta Conv2D inicial\n",
    "    index = 0\n",
    "\n",
    "    while index < len(encoded_model):\n",
    "        layer_type = int(encoded_model[index])\n",
    "        param1 = encoded_model[index + 1]\n",
    "        param2 = encoded_model[index + 2]\n",
    "        param3 = encoded_model[index + 3]\n",
    "\n",
    "        if layer_type == 8:  # Capa de Repetition\n",
    "            repetition_layers = int(param1)\n",
    "            repetition_count = int(param2)\n",
    "            # Selecciona solo el grupo válido de capas para la repetición\n",
    "            layers_to_repeat = select_group_for_repetition(model_dict['layers'], repetition_layers)\n",
    "            \n",
    "            if len(layers_to_repeat) > 0:\n",
    "                for _ in range(repetition_count):\n",
    "                    model_dict['layers'].extend(layers_to_repeat)\n",
    "\n",
    "        else:\n",
    "            decoded_layer = {}\n",
    "\n",
    "            if layer_type == 0:  # Conv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'Conv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 6:  # DepthwiseConv2D\n",
    "                decoded_layer = {\n",
    "                    'type': 'DepthwiseConv2D',\n",
    "                    'filters': max(4, min(param1, 32)),  # Limita `filters` entre 4 y 32\n",
    "                    'strides': stride_options.get(param2, 1),\n",
    "                    'activation': activation_options.get(param3, 'relu')\n",
    "                }\n",
    "            elif layer_type == 2:  # MaxPooling\n",
    "                decoded_layer = {\n",
    "                    'type': 'MaxPooling',\n",
    "                    'strides': stride_options.get(param1, 1)\n",
    "                }\n",
    "            elif layer_type == 3:  # Dropout\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dropout',\n",
    "                    'rate': dropout_options.get(param1, 0.2)\n",
    "                }\n",
    "            elif layer_type == 4:  # Dense\n",
    "                decoded_layer = {\n",
    "                    'type': 'Dense',\n",
    "                    'units': max(1, min(param1, 512)),  # Limita `units` entre 1 y 512\n",
    "                    'activation': activation_options.get(param2, 'relu')\n",
    "                }\n",
    "            elif layer_type == 1:  # BatchNorm\n",
    "                decoded_layer = {'type': 'BatchNorm'}\n",
    "            elif layer_type == 5:  # Flatten\n",
    "                decoded_layer = {'type': 'Flatten'}\n",
    "            elif layer_type == 7:  # DontCare\n",
    "                decoded_layer = {'type': 'DontCare'}\n",
    "\n",
    "            model_dict['layers'].append(decoded_layer)\n",
    "\n",
    "        index += 4\n",
    "\n",
    "    # Asegura que haya una capa Flatten antes de la capa Dense final, si no ya existe una Flatten\n",
    "    if model_dict['layers'][-1]['type'] != 'Flatten':\n",
    "        model_dict['layers'].append({'type': 'Flatten'})\n",
    "        \n",
    "    # Añade la capa Dense final obligatoria\n",
    "    model_dict['layers'].append({'type': 'Dense', 'units': 1, 'activation': 'sigmoid'})\n",
    "\n",
    "    return model_dict\n",
    "\n",
    "def select_group_for_repetition(layers, repetition_layers):\n",
    "    \"\"\"\n",
    "    Selecciona el primer grupo válido para repetición en función de las reglas de compatibilidad.\n",
    "\n",
    "    Parameters:\n",
    "        layers (list): Lista de capas ya procesadas, donde cada capa es un diccionario.\n",
    "        repetition_layers (int): Número de capas hacia atrás para considerar en la repetición.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de capas compatibles para repetición.\n",
    "    \"\"\"\n",
    "    valid_layers = []\n",
    "    group_type = None\n",
    "\n",
    "    # Retrocede desde el final de `layers` para encontrar el grupo válido\n",
    "    for layer in reversed(layers[-repetition_layers:]):\n",
    "        if group_type is None:\n",
    "            # Determina el tipo de grupo\n",
    "            if layer['type'] in ['Flatten', 'Dense']:\n",
    "                group_type = 'dense'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling']:\n",
    "                group_type = 'convolutional'\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif layer['type'] in ['BatchNorm', 'DontCare']:  # BatchNorm y DontCare son compatibles con ambos grupos\n",
    "                valid_layers.insert(0, layer)\n",
    "        else:\n",
    "            # Agrega solo capas compatibles con el grupo seleccionado\n",
    "            if group_type == 'dense' and layer['type'] in ['Flatten', 'Dense', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "            elif group_type == 'convolutional' and layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling', 'BatchNorm', 'DontCare']:\n",
    "                valid_layers.insert(0, layer)\n",
    "\n",
    "    return valid_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reparar cada ejemplo con fixArch y luego decodificar con decode_model_architecture\n",
    "# repaired_and_decoded_models = []\n",
    "\n",
    "# for i, encoded_model in enumerate([encoded_model_1, encoded_model_2, encoded_model_3, encoded_model_4, encoded_model_5], 1):\n",
    "#     # Reparar el modelo\n",
    "#     repaired_model = fixArch(encoded_model, verbose=True)\n",
    "#     # Decodificar el modelo reparado\n",
    "#     decoded_model = decode_model_architecture(repaired_model)\n",
    "#     # Guardar el modelo decodificado\n",
    "#     repaired_and_decoded_models.append(decoded_model)\n",
    "#     print(f\"\\n--- Modelo {i} Decodificado ---\")\n",
    "#     print(decoded_model)\n",
    "\n",
    "# # Opcional: Mostrar todos los modelos decodificados juntos\n",
    "# print(\"\\n--- Todos los Modelos Decodificados ---\")\n",
    "# for i, model in enumerate(repaired_and_decoded_models, 1):\n",
    "#     print(f\"Modelo {i} Decodificado:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization, DepthwiseConv2D\n",
    "\n",
    "\n",
    "\n",
    "def build_tf_model_from_dict(model_dict, input_shape=(28, 28, 3)):\n",
    "    \"\"\"\n",
    "    Construye un modelo de TensorFlow a partir de un diccionario JSON expandido.\n",
    "    \"\"\"\n",
    "    print(\"\\nConstruyendo el modelo en TensorFlow desde el JSON expandido...\")\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Conv2D':\n",
    "            model.add(Conv2D(filters=layer['filters'], kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "        \n",
    "        elif layer['type'] == 'DepthwiseConv2D':\n",
    "            model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=int(layer['strides']), padding='same', activation=layer['activation']))\n",
    "        \n",
    "        elif layer['type'] == 'BatchNorm':\n",
    "            model.add(BatchNormalization())\n",
    "        \n",
    "        elif layer['type'] == 'MaxPooling':\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=int(layer['strides']), padding='same'))\n",
    "        \n",
    "        elif layer['type'] == 'Flatten':\n",
    "            model.add(Flatten())\n",
    "        \n",
    "        elif layer['type'] == 'Dense':\n",
    "            model.add(Dense(units=int(layer['units']), activation=layer['activation']))\n",
    "        \n",
    "        elif layer['type'] == 'Dropout':\n",
    "            model.add(Dropout(rate=layer['rate']))\n",
    "        \n",
    "        elif layer['type'] == 'DontCare':\n",
    "            model.add(DontCareLayer())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: build_CNN_LF_model\n",
    "model_CNN_LF = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 30, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},  # Revisar 'filters'\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.3},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 2: build_reduced_model\n",
    "model_reduced = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 3: build_Spectro_CNN_model\n",
    "model_spectro_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2}, \n",
    "         \n",
    "         \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "         {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "         {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "    {\"type\":\"Flatten\"},\n",
    "    {\"type\":\"Dense\",\"units\":256,\"activation\":\"relu\"},   \n",
    "    {\"type\":\"Dropout\",\"rate\":0.5},\n",
    "                \n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo corregido: build_Spectro_CNN_model con capas de repetición\n",
    "model_spectro_CNN_with_repetition = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2}, \n",
    "        # Aquí indicamos que las siguientes 10 capas (5 Conv2D + 5 BatchNorm) se repiten 10 veces\n",
    "        {\"type\": \"Repetition\", \"repetition_layers\": 3, \"repetition_count\": 31},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Ejemplo 4: Simple Conv2D model\n",
    "model_simple_conv = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 5: Simple Dense model\n",
    "model_dense_only = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 6: Small CNN model with Dropout\n",
    "model_small_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 7: Deep CNN model\n",
    "model_deep_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 10, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 8: Basic Dense with Dropout\n",
    "model_dense_dropout = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "model_with_depthwise = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"DepthwiseConv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"sigmoid\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_pipeline(model_dict, input_shape=(28, 28, 3), verbose=False):\n",
    "    \"\"\"\n",
    "    Procesa el pipeline de creación del modelo desde el JSON inicial hasta el modelo de TensorFlow.\n",
    "    \n",
    "    Parameters:\n",
    "        model_dict (dict): Modelo en formato JSON.\n",
    "        input_shape (tuple): Forma de entrada para el modelo.\n",
    "        verbose (bool): Si es True, muestra los detalles de cada etapa del proceso.\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: El modelo de TensorFlow construido a partir del JSON procesado.\n",
    "    \"\"\"\n",
    "    # Codificar el modelo\n",
    "    encoded_model = encode_model_architecture(model_dict, max_alleles=48)\n",
    "    if verbose:\n",
    "        print(f\"\\nModelo codificado: {encoded_model}\")\n",
    "\n",
    "    # Reparar el modelo codificado\n",
    "    fixed_model = fixArch(encoded_model, verbose=verbose)\n",
    "    if verbose:\n",
    "        print(f\"\\nModelo codificado y reparado: {fixed_model}\")\n",
    "\n",
    "    # Decodificar el modelo reparado\n",
    "    decoded_model = decode_model_architecture(fixed_model)\n",
    "    if verbose:\n",
    "        print(f\"\\nModelo decodificado:\\n{decoded_model}\")\n",
    "\n",
    "    # Construir el modelo de TensorFlow\n",
    "    tf_model = build_tf_model_from_dict(decoded_model, input_shape=input_shape)\n",
    "    if verbose:\n",
    "        print(\"\\nModelo de TensorFlow construido.\")\n",
    "        tf_model.summary()\n",
    "    \n",
    "    return tf_model\n",
    "\n",
    "\n",
    "# Ejemplo de uso con un modelo y verbose activado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifications:\n",
      "\n",
      "Model 1: CNN_LF\n",
      "Final Encoded Model: [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "Modelo codificado: [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 30, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 16, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 1, 0, 0, 4, 1, 2, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 30, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 30)        8670      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 30)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 30)       120       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 30)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 16)        4336      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,305\n",
      "Trainable params: 215,213\n",
      "Non-trainable params: 92\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 2: Reduced\n",
      "Final Encoded Model: [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [1, 0, 0, 0, 0, 16, 0, 1, 1, 0, 0, 0, 0, 8, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 4, 32, 1, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'leaky_relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 16)        4624      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                200736    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " dont_care_layer (DontCareLa  (None, 1)                0         \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " dont_care_layer_1 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_2 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_3 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,675\n",
      "Trainable params: 207,563\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 3: Spectro CNN\n",
      "Final Encoded Model: [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 2, 1, 0, 0, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0, 0, 32, 0, 1, 0, 32, 0, 1, 1, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,417\n",
      "Trainable params: 72,161\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 3.5 Spectro CNN with repetition\n",
      "Final Encoded Model: [0, 32, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 8, 3, 31, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 3, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 32, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 8, 3, 31, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 3, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 32, 0, 1, 1, 0, 0, 0, 2, 1, 0, 0, 8, 3, 31, 0, 5, 0, 0, 0, 4, 256, 0, 0, 3, 3, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 14, 14, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 7, 7, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 4, 4, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 2, 2, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      " dont_care_layer_4 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_5 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_6 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_7 (DontCare  (None, 1)                0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,635\n",
      "Trainable params: 307,587\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 4: Simple Conv2D\n",
      "Final Encoded Model: [0, 16, 0, 0, 5, 0, 0, 0, 4, 128, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 16, 0, 0, 5, 0, 0, 0, 4, 128, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 16, 0, 0, 7, 0, 0, 0, 4, 128, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_47 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 16)        4624      \n",
      "                                                                 \n",
      " dont_care_layer_8 (DontCare  (None, 28, 28, 16)       0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 28, 28, 128)       2176      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 28, 28, 1)         129       \n",
      "                                                                 \n",
      " dont_care_layer_9 (DontCare  (None, 28, 28, 1)        0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " dont_care_layer_10 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_11 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_12 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_13 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_14 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_15 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_16 (DontCar  (None, 28, 28, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 785       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,610\n",
      "Trainable params: 8,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 5: Dense Only\n",
      "Final Encoded Model: [5, 0, 0, 0, 4, 256, 0, 0, 4, 128, 0, 0, 4, 256, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [5, 0, 0, 0, 4, 256, 0, 0, 4, 128, 0, 0, 4, 256, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [7, 0, 0, 0, 4, 256, 0, 0, 4, 128, 0, 0, 4, 256, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_49 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " dont_care_layer_17 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 28, 28, 256)       8448      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 28, 28, 128)       32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 28, 28, 256)       33024     \n",
      "                                                                 \n",
      " dont_care_layer_18 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_19 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_20 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_21 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_22 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_23 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_24 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_25 (DontCar  (None, 28, 28, 256)      0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 200704)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 200705    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,969\n",
      "Trainable params: 275,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 6: Small CNN\n",
      "Final Encoded Model: [0, 8, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 8, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 8, 0, 0, 3, 0, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 4, 32, 0, 0, 4, 1, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_50 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 28, 28, 8)         2312      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 14, 14, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dont_care_layer_26 (DontCar  (None, 14, 14, 8)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 14, 14, 32)        288       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 14, 14, 1)         33        \n",
      "                                                                 \n",
      " dont_care_layer_27 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_28 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_29 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_30 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_31 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_32 (DontCar  (None, 14, 14, 1)        0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 196)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 197       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,726\n",
      "Trainable params: 3,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 7: Deep CNN\n",
      "Final Encoded Model: [0, 32, 0, 0, 0, 32, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 10, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [0, 32, 0, 0, 0, 32, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 4, 32, 0, 0, 4, 10, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [0, 32, 0, 0, 0, 32, 0, 0, 2, 1, 0, 0, 7, 0, 0, 0, 4, 32, 0, 0, 4, 10, 2, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 10, 'activation': 'sigmoid'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dont_care_layer_33 (DontCar  (None, 14, 14, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 14, 14, 32)        1056      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 14, 14, 10)        330       \n",
      "                                                                 \n",
      " dont_care_layer_34 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_35 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_36 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_37 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_38 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_39 (DontCar  (None, 14, 14, 10)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 1960)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 1961      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,739\n",
      "Trainable params: 22,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 8: Dense with Dropout\n",
      "Final Encoded Model: [5, 0, 0, 0, 4, 128, 0, 0, 3, 3, 0, 0, 4, 32, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado: [5, 0, 0, 0, 4, 128, 0, 0, 3, 3, 0, 0, 4, 32, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo codificado y reparado: [7, 0, 0, 0, 4, 128, 0, 0, 3, 3, 0, 0, 4, 32, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Modelo decodificado:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 32, 'activation': 'tanh'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "\n",
      "Modelo de TensorFlow construido.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " dont_care_layer_40 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 28, 28, 128)       4224      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 28, 28, 32)        4128      \n",
      "                                                                 \n",
      " dont_care_layer_41 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_42 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_43 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_44 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_45 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_46 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_47 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " dont_care_layer_48 (DontCar  (None, 28, 28, 32)       0         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 25089     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,337\n",
      "Trainable params: 34,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model with DepthwiseConv2D\n",
      "Final Encoded Model: [6, 16, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 4, 128, 2, 0, 4, 1, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0]\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verificación de los modelos\n",
    "print(\"Verifications:\")\n",
    "\n",
    "print(\"\\nModel 1: CNN_LF\")\n",
    "tf_model_example = process_model_pipeline(model_CNN_LF, verbose=True)  # Ejemplo 1\n",
    "\n",
    "print(\"\\nModel 2: Reduced\")\n",
    "tf_model_example = process_model_pipeline(model_reduced, verbose=True)  # Ejemplo 2\n",
    "\n",
    "print(\"\\nModel 3: Spectro CNN\")\n",
    "tf_model_example = process_model_pipeline(model_spectro_CNN, verbose=True)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 3.5 Spectro CNN with repetition\")\n",
    "tf_model_example = process_model_pipeline(model_spectro_CNN_with_repetition, verbose=True)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 4: Simple Conv2D\")\n",
    "tf_model_example = process_model_pipeline(model_simple_conv, verbose=True)  # Ejemplo 4\n",
    "\n",
    "print(\"\\nModel 5: Dense Only\")\n",
    "tf_model_example = process_model_pipeline(model_dense_only, verbose=True)  # Ejemplo 5\n",
    "\n",
    "print(\"\\nModel 6: Small CNN\")\n",
    "tf_model_example = process_model_pipeline(model_small_CNN, verbose=True)  # Ejemplo 6\n",
    "\n",
    "print(\"\\nModel 7: Deep CNN\")\n",
    "tf_model_example = process_model_pipeline(model_deep_CNN, verbose=True)  # Ejemplo 7\n",
    "\n",
    "print(\"\\nModel 8: Dense with Dropout\")\n",
    "tf_model_example = process_model_pipeline(model_dense_dropout, verbose=True)  # Ejemplo 8\n",
    "\n",
    "print(\"\\nModel with DepthwiseConv2D\")\n",
    "tf_model_example = process_model_pipeline(model_with_depthwise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing random generated architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from pyDOE2 import lhs\n",
    "\n",
    "# Función para generar un hipercubo latino con rangos normalizados [0, 1]\n",
    "def generate_latin_hypercube_samples(num_samples, dimensions):\n",
    "    return lhs(dimensions, samples=num_samples)\n",
    "\n",
    "# Validar si los parámetros generados están dentro del rango esperado\n",
    "def validate_latin_hypercube(num_models=100):\n",
    "    dimensions = 12 * 3  # 12 capas, 3 parámetros por capa\n",
    "    latin_samples = generate_latin_hypercube_samples(num_models, dimensions)\n",
    "    \n",
    "    # Validar cada muestra generada\n",
    "    for sample_idx, sample in enumerate(latin_samples):\n",
    "        reshaped_sample = sample.reshape(12, 3)  # Cada modelo tiene 12 capas\n",
    "        \n",
    "        for layer_idx, layer_params in enumerate(reshaped_sample):\n",
    "            # Validar parámetros individuales\n",
    "            type_idx = int(layer_params[0] * 9)  # 9 tipos de capas\n",
    "            param1 = layer_params[1]\n",
    "            param2 = layer_params[2]\n",
    "\n",
    "            # Verificar tipo de capa\n",
    "            if type_idx not in range(9):\n",
    "                print(f\"ERROR en Modelo {sample_idx + 1}, Capa {layer_idx + 1}: Tipo inválido {type_idx}\")\n",
    "                return False\n",
    "\n",
    "            # Verificar rangos específicos según el tipo de capa\n",
    "            layer_mapping = ['Conv2D', 'DepthwiseConv2D', 'BatchNorm', 'MaxPooling', \n",
    "                             'Dropout', 'Dense', 'Flatten', 'DontCare', 'Repetition']\n",
    "            layer_type = layer_mapping[type_idx]\n",
    "\n",
    "            if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "                filters = int(param1 * (32 - 4) + 4)  # Filtros entre [4, 32]\n",
    "                if not (4 <= filters <= 32):\n",
    "                    print(f\"ERROR en Modelo {sample_idx + 1}, Capa {layer_idx + 1}: Filtros fuera de rango {filters}\")\n",
    "                    return False\n",
    "\n",
    "            elif layer_type == 'Dropout':\n",
    "                rate = param1 * (0.5 - 0.2) + 0.2  # Tasa de dropout entre [0.2, 0.5]\n",
    "                if not (0.2 <= rate <= 0.5):\n",
    "                    print(f\"ERROR en Modelo {sample_idx + 1}, Capa {layer_idx + 1}: Dropout fuera de rango {rate}\")\n",
    "                    return False\n",
    "\n",
    "            elif layer_type == 'Dense':\n",
    "                units = int(param1 * (512 - 1) + 1)  # Unidades entre [1, 512]\n",
    "                if not (1 <= units <= 512):\n",
    "                    print(f\"ERROR en Modelo {sample_idx + 1}, Capa {layer_idx + 1}: Unidades fuera de rango {units}\")\n",
    "                    return False\n",
    "\n",
    "    print(\"Validación completada: Todas las muestras están dentro de los rangos esperados.\")\n",
    "    return True\n",
    "\n",
    "# Guardar el encoding generado en un archivo CSV\n",
    "def save_encoded_models_to_csv(num_models, filename, max_alleles=48):\n",
    "    # Generar muestras de hipercubo latino\n",
    "    latin_samples = generate_latin_hypercube_samples(num_models, 12 * 3)  # 12 capas, 3 parámetros por capa\n",
    "\n",
    "    # Crear el archivo CSV\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Escribir encabezados\n",
    "        writer.writerow([\"Model\", \"Encoded Chromosome\"])\n",
    "\n",
    "        for model_idx in range(num_models):\n",
    "            # Cada modelo tiene 12 capas\n",
    "            model_samples = latin_samples[model_idx].reshape(12, 3)\n",
    "\n",
    "            # Mapear cada muestra a un modelo (JSON)\n",
    "            model_dict = {\n",
    "                \"layers\": [\n",
    "                    map_to_architecture_params(sample) for sample in model_samples\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            # Realizar el encoding del modelo\n",
    "            encoded_chromosome = encode_model_architecture(model_dict, max_alleles=max_alleles)\n",
    "\n",
    "            # Guardar en el archivo CSV\n",
    "            writer.writerow([model_idx + 1, encoded_chromosome])\n",
    "\n",
    "    print(f\"Cromosomas codificados guardados en {filename}\")\n",
    "    \n",
    "\n",
    "# Mapear valores normalizados a arquitecturas\n",
    "def map_to_architecture_params(latin_hypercube_sample):\n",
    "    layer_type = int(latin_hypercube_sample[0] * 9)  # 9 tipos de capas\n",
    "    layer_mapping = ['Conv2D', 'DepthwiseConv2D', 'BatchNorm', 'MaxPooling', \n",
    "                     'Dropout', 'Dense', 'Flatten', 'DontCare', 'Repetition']\n",
    "\n",
    "    layer_type_name = layer_mapping[layer_type]\n",
    "\n",
    "    if layer_type_name == 'Conv2D':\n",
    "        return {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"filters\": int(latin_hypercube_sample[1] * (16 - 4) + 4),  # [4, 16]\n",
    "            \"strides\": 1 if latin_hypercube_sample[2] < 0.5 else 2,\n",
    "            \"activation\": \"relu\"\n",
    "        }\n",
    "    elif layer_type_name == 'DepthwiseConv2D':\n",
    "        return {\n",
    "            \"type\": \"DepthwiseConv2D\",\n",
    "            \"filters\": int(latin_hypercube_sample[1] * (16 - 4) + 4),\n",
    "            \"strides\": 1 if latin_hypercube_sample[2] < 0.5 else 2,\n",
    "            \"activation\": \"relu\"\n",
    "        }\n",
    "    elif layer_type_name == 'BatchNorm':\n",
    "        return {\"type\": \"BatchNorm\"}\n",
    "    elif layer_type_name == 'MaxPooling':\n",
    "        return {\"type\": \"MaxPooling\", \"strides\": 1 if latin_hypercube_sample[1] < 0.5 else 2}\n",
    "    elif layer_type_name == 'Dropout':\n",
    "        return {\"type\": \"Dropout\", \"rate\": latin_hypercube_sample[1] * (0.5 - 0.2) + 0.2}\n",
    "    elif layer_type_name == 'Dense':\n",
    "        return {\n",
    "            \"type\": \"Dense\",\n",
    "            \"units\": int(latin_hypercube_sample[1] * (128 - 1) + 1),\n",
    "            \"activation\": \"relu\"\n",
    "        }\n",
    "    elif layer_type_name == 'Flatten':\n",
    "        return {\"type\": \"Flatten\"}\n",
    "    elif layer_type_name == 'DontCare':\n",
    "        return {\"type\": \"DontCare\"}\n",
    "    elif layer_type_name == 'Repetition':\n",
    "        return {\n",
    "            \"type\": \"Repetition\",\n",
    "            \"repetition_layers\": int(latin_hypercube_sample[1] * 3 + 1),\n",
    "            \"repetition_count\": int(latin_hypercube_sample[2] * 2 + 1)\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "# Ejecutar validación\n",
    "# if validate_latin_hypercube(num_models=100):\n",
    "#     # Guardar los cromosomas codificados en un archivo CSV si la validación pasa\n",
    "#     save_encoded_models_to_csv(num_models=1000, filename=\"EncodedChromosomes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función para cargar el CSV y extraer las muestras normalizadas\n",
    "def load_and_plot_samples(filename):\n",
    "    # Cargar el archivo CSV\n",
    "    data = pd.read_csv(filename)\n",
    "\n",
    "    # Asegurarse de que las muestras están en una columna separada correctamente\n",
    "    # Convertir la columna \"Encoded Chromosome\" de string a listas\n",
    "    data['Encoded Chromosome'] = data['Encoded Chromosome'].apply(\n",
    "        lambda x: [int(i) for i in x.strip(\"[]\").split(\",\")]\n",
    "    )\n",
    "\n",
    "    # Para este ejemplo, asumiremos que los parámetros 1 y 2 corresponden a las dimensiones de interés\n",
    "    # Extraer dimensiones de interés de los cromosomas codificados\n",
    "    dimension_1 = [chromosome[0] for chromosome in data['Encoded Chromosome']]  # Tipo de la primera capa\n",
    "    dimension_2 = [chromosome[1] for chromosome in data['Encoded Chromosome']]  # Número de filtros/unidades\n",
    "\n",
    "    # Normalizar dimensiones para que caigan en [0, 1]\n",
    "    dimension_1 = np.array(dimension_1) / max(dimension_1)\n",
    "    dimension_2 = np.array(dimension_2) / max(dimension_2)\n",
    "\n",
    "    # Crear un histograma bidimensional (mapa de calor)\n",
    "    heatmap, xedges, yedges = np.histogram2d(dimension_1, dimension_2, bins=20, range=[[0, 1], [0, 1]])\n",
    "\n",
    "    # Configurar la figura\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "    # Dibujar el mapa de calor\n",
    "    cbar = ax.imshow(heatmap.T, extent=extent, origin='lower', cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(cbar, label=\"Densidad de muestras\")\n",
    "    ax.set_title(\"Mapa de calor del espacio de búsqueda\")\n",
    "    ax.set_xlabel(\"Tipo de capa normalizado (Dimensión 1)\")\n",
    "    ax.set_ylabel(\"Número de filtros/unidades normalizado (Dimensión 2)\")\n",
    "\n",
    "    # Mostrar la figura\n",
    "    plt.show()\n",
    "\n",
    "# Llamar a la función con el archivo generado\n",
    "load_and_plot_samples(\"EncodedChromosomes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando el modelo surogado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint cargado: {'last_completed': 190}\n",
      "Cargando y preprocesando datos de audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MELSPECTROGRAM: 100%|██████████| 5890/5890 [00:18<00:00, 311.16it/s]\n",
      "LABEL: 100%|██████████| 5890/5890 [00:00<00:00, 589056.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5890, 128, 128, 1), Y shape: (5890,)\n",
      "\n",
      "Evaluando arquitectura 192/1000...\n",
      "Entrenando fold 1/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 1 completado.\n",
      "Entrenando fold 2/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 2 completado.\n",
      "Entrenando fold 3/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 3 completado.\n",
      "Entrenando fold 4/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 6ms/step\n",
      "Fold 4 completado.\n",
      "Entrenando fold 5/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 5ms/step\n",
      "Fold 5 completado.\n",
      "Resultados guardados en: ./model_results_loaded_architectures.csv\n",
      "Checkpoint guardado: {'last_completed': 191}\n",
      "\n",
      "Evaluando arquitectura 193/1000...\n",
      "Entrenando fold 1/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 12ms/step\n",
      "Fold 1 completado.\n",
      "Entrenando fold 2/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 12ms/step\n",
      "Fold 2 completado.\n",
      "Entrenando fold 3/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 13ms/step\n",
      "Fold 3 completado.\n",
      "Entrenando fold 4/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 18ms/step\n",
      "Fold 4 completado.\n",
      "Entrenando fold 5/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 12ms/step\n",
      "Fold 5 completado.\n",
      "Resultados guardados en: ./model_results_loaded_architectures.csv\n",
      "Checkpoint guardado: {'last_completed': 192}\n",
      "\n",
      "Evaluando arquitectura 194/1000...\n",
      "Entrenando fold 1/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 1 completado.\n",
      "Entrenando fold 2/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 2 completado.\n",
      "Entrenando fold 3/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 8ms/step\n",
      "Fold 3 completado.\n",
      "Entrenando fold 4/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 4 completado.\n",
      "Entrenando fold 5/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 0s 9ms/step\n",
      "Fold 5 completado.\n",
      "Resultados guardados en: ./model_results_loaded_architectures.csv\n",
      "Checkpoint guardado: {'last_completed': 193}\n",
      "\n",
      "Evaluando arquitectura 195/1000...\n",
      "Entrenando fold 1/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 15ms/step\n",
      "Fold 1 completado.\n",
      "Entrenando fold 2/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 15ms/step\n",
      "Fold 2 completado.\n",
      "Entrenando fold 3/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n",
      "37/37 [==============================] - 1s 14ms/step\n",
      "Fold 3 completado.\n",
      "Entrenando fold 4/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 15ms/step\n",
      "Fold 4 completado.\n",
      "Entrenando fold 5/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 14ms/step\n",
      "Fold 5 completado.\n",
      "Resultados guardados en: ./model_results_loaded_architectures.csv\n",
      "Checkpoint guardado: {'last_completed': 194}\n",
      "\n",
      "Evaluando arquitectura 196/1000...\n",
      "Entrenando fold 1/5...\n",
      "\n",
      "Construyendo el modelo en TensorFlow desde el JSON expandido...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torchaudio\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Resizing, Conv2D, Dropout, BatchNormalization, MaxPooling2D, MaxPool2D, Flatten, Dense, Input, LeakyReLU\n",
    "from tqdm import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Configuración de parámetros\n",
    "class Config:\n",
    "    def __init__(self, architecture='random', epochs=50, sample_rate=None, time=5, n_splits=5, window_size=5, checkpoint_file=\"training_checkpoint.json\"):\n",
    "        self.architecture = architecture\n",
    "        self.epochs = epochs\n",
    "        self.sample_rate = sample_rate\n",
    "        self.time = time\n",
    "        self.n_splits = n_splits\n",
    "        self.window_size = window_size\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "\n",
    "# Crear o cargar checkpoint\n",
    "def load_checkpoint(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "            print(f\"Checkpoint cargado: {checkpoint}\")\n",
    "            return checkpoint\n",
    "    return {\"last_completed\": -1}\n",
    "\n",
    "def save_checkpoint(file_path, architecture_index):\n",
    "    checkpoint = {\"last_completed\": architecture_index}\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(checkpoint, f)\n",
    "    print(f\"Checkpoint guardado: {checkpoint}\")\n",
    "\n",
    "# Cargar datos de audio\n",
    "def load_audio_data(directory, window_size, sample_rate):\n",
    "    audio_dict = {}\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            waveform, sr = torchaudio.load(os.path.join(directory, file_name))\n",
    "            if sample_rate is None:\n",
    "                sample_rate = sr\n",
    "            num_windows = int(waveform.shape[1] / (window_size * sample_rate))\n",
    "            for i in range(num_windows):\n",
    "                start = i * window_size * sample_rate\n",
    "                end = (i + 1) * window_size * sample_rate\n",
    "                audio_dict[f\"{file_name}_{i}\"] = waveform[:, start:end].numpy()\n",
    "    return audio_dict, sample_rate\n",
    "\n",
    "# Preprocesar datos de audio\n",
    "def preprocess_audio(audio_dict, sample_rate):\n",
    "    audio_dict = copy.deepcopy(audio_dict)\n",
    "    n_mels = 128\n",
    "    n_fft = int(sample_rate * 0.029)\n",
    "    hop_length = int(sample_rate * 0.010)\n",
    "    win_length = int(sample_rate * 0.025)\n",
    "\n",
    "    for filename, waveform in tqdm(audio_dict.items(), desc='MELSPECTROGRAM'):\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mels, hop_length=hop_length, win_length=win_length)(waveform)\n",
    "        spec = torchaudio.transforms.AmplitudeToDB()(spec)\n",
    "        spec = spec.numpy()\n",
    "        spec = (spec - spec.min()) / (spec.max() - spec.min())\n",
    "        audio_dict[filename] = spec\n",
    "    return audio_dict\n",
    "\n",
    "# Padding de los espectrogramas\n",
    "def pad_and_crop_spectrograms(spectrograms, target_shape=(128, 128)):\n",
    "    padded_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        if spec.shape[0] > target_shape[0]:\n",
    "            spec = spec[:target_shape[0], :]\n",
    "        if spec.shape[1] > target_shape[1]:\n",
    "            spec = spec[:, :target_shape[1]]\n",
    "        \n",
    "        pad_width = [(0, max(0, target_shape[0] - spec.shape[0])), \n",
    "                     (0, max(0, target_shape[1] - spec.shape[1]))]\n",
    "        \n",
    "        padded_spec = np.pad(spec, pad_width, mode='constant')\n",
    "        padded_spectrograms.append(padded_spec)\n",
    "    return np.array(padded_spectrograms)\n",
    "\n",
    "# Split de audio en train y test\n",
    "def train_test_split_audio(audio_dict):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID', 'PHQ-9 Score'], dtype={1: str})\n",
    "    df['labels'] = np.zeros([len(df),], dtype=int)\n",
    "    df.loc[df['PHQ-9 Score'] < 10, 'labels'] = 0\n",
    "    df.loc[df['PHQ-9 Score'] >= 10, 'labels'] = 1\n",
    "\n",
    "    labels = df.set_index('Participant_ID').to_dict()['labels']\n",
    "\n",
    "    X, Y = [], []\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        if ID in labels:\n",
    "            dep = 0 if labels[ID] == 0 else 1\n",
    "            [X.append(x) for x in data]\n",
    "            [Y.append(dep) for x in data]\n",
    "\n",
    "    X = pad_and_crop_spectrograms(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    X = X[..., np.newaxis]\n",
    "    print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "    return X, Y\n",
    "\n",
    "# Guardar resultados en CSV (append)\n",
    "def append_results_to_csv(file_path, model_results):\n",
    "    columns = [\"Encoded Architecture\", \"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\"]\n",
    "\n",
    "    # Convertir arquitectura a cadena para guardar\n",
    "    model_results = [str(model_results[0])] + model_results[1:]\n",
    "\n",
    "    # Verificar si el archivo ya existe\n",
    "    if not os.path.exists(file_path):\n",
    "        # Crear archivo con encabezados si no existe\n",
    "        with open(file_path, mode='w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(columns)\n",
    "\n",
    "    # Escribir resultados en el archivo\n",
    "    with open(file_path, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(model_results)\n",
    "    print(f\"Resultados guardados en: {file_path}\")\n",
    "\n",
    "# Función de especificidad\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Entrenar y evaluar modelo\n",
    "def train_and_evaluate_model(model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config):\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=[\"accuracy\", 'Precision', 'Recall'])\n",
    "    model.fit(X_train, Y_train, epochs=config.epochs, validation_data=(X_val, Y_val), verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    # Obtener predicciones para métricas adicionales\n",
    "    Y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = results[1]\n",
    "    precision = precision_score(Y_test, Y_pred)\n",
    "    recall = recall_score(Y_test, Y_pred)\n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    specificity = specificity_score(Y_test, Y_pred)\n",
    "\n",
    "    return [results[0], accuracy, precision, recall, f1, specificity]\n",
    "\n",
    "# Evaluar y almacenar resultados\n",
    "def evaluate_and_store_model(architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, stratified_kfold, target_shape, results_file):\n",
    "    repaired_architecture = fixArch(architecture)\n",
    "    decoded_model_dict = decode_model_architecture(repaired_architecture)\n",
    "    model_results = [repaired_architecture]\n",
    "\n",
    "    if use_kfold:\n",
    "        fold_results = []\n",
    "        for fold, (train_index, val_index) in enumerate(stratified_kfold.split(X_train_val, Y_train_val)):\n",
    "            print(f\"Entrenando fold {fold + 1}/{config.n_splits}...\")\n",
    "            X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "            Y_train, Y_val = Y_train_val[train_index], Y_train_val[val_index]\n",
    "            tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "            fold_results.append(train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config))\n",
    "            print(f\"Fold {fold + 1} completado.\")\n",
    "\n",
    "        avg_results = np.mean(fold_results, axis=0)\n",
    "        model_results.extend(avg_results)\n",
    "\n",
    "    else:\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=42)\n",
    "        tf_model = build_tf_model_from_dict(decoded_model_dict, input_shape=(target_shape[0], target_shape[1], 1))\n",
    "        single_run_results = train_and_evaluate_model(tf_model, X_train, Y_train, X_val, Y_val, X_test, Y_test, config)\n",
    "        model_results.extend(single_run_results)\n",
    "        print(\"Modelo evaluado sin K-Fold Cross Validation.\")\n",
    "\n",
    "    # Guardar métricas de la arquitectura actual en el archivo CSV\n",
    "    append_results_to_csv(results_file, model_results)\n",
    "\n",
    "# Cargar arquitecturas desde un archivo CSV\n",
    "def load_architectures_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    architectures = df['Encoded Chromosome'].apply(lambda x: [int(i) for i in x.strip(\"[]\").split(\",\")])\n",
    "    return architectures.tolist()\n",
    "\n",
    "# Entrenar los modelos cargados\n",
    "def train_loaded_models(csv_path, directory='./SM-27', target_shape=(128, 128, 1), use_kfold=True, epochs=50, n_splits=5, checkpoint_file=\"training_checkpoint.json\", results_file=\"./model_results_loaded_architectures.csv\"):\n",
    "    config = Config(epochs=epochs, n_splits=n_splits, checkpoint_file=checkpoint_file)\n",
    "    \n",
    "    # Cargar checkpoint\n",
    "    checkpoint = load_checkpoint(config.checkpoint_file)\n",
    "\n",
    "    # Cargar y preprocesar datos de audio\n",
    "    print(\"Cargando y preprocesando datos de audio...\")\n",
    "    audio_dict, sample_rate = load_audio_data(directory, config.window_size, config.sample_rate)\n",
    "    audio_dict = preprocess_audio(audio_dict, sample_rate)\n",
    "    X, Y = train_test_split_audio(audio_dict)\n",
    "    X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if use_kfold:\n",
    "        stratified_kfold = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Cargar arquitecturas desde el archivo CSV\n",
    "    architectures = load_architectures_from_csv(csv_path)\n",
    "\n",
    "    # Entrenar y evaluar las arquitecturas desde el último punto\n",
    "    for i, architecture in enumerate(architectures):\n",
    "        if i <= checkpoint[\"last_completed\"]:\n",
    "            continue  # Saltar arquitecturas ya completadas\n",
    "\n",
    "        print(f\"\\nEvaluando arquitectura {i + 1}/{len(architectures)}...\")\n",
    "        evaluate_and_store_model(architecture, X_train_val, X_test, Y_train_val, Y_test, config, use_kfold, stratified_kfold, target_shape, results_file)\n",
    "\n",
    "        # Guardar checkpoint\n",
    "        save_checkpoint(config.checkpoint_file, i)\n",
    "\n",
    "# Ejecutar\n",
    "train_loaded_models(csv_path=\"EncodedChromosomes.csv\", target_shape=(128, 128, 1), use_kfold=True, epochs=18, n_splits=5, results_file=\"./model_results_loaded_architectures.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisando distribucion del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el dataset desde el archivo CSV\n",
    "file_path = './model_results_combined.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Especificar las métricas a graficar\n",
    "metrics = [\"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"Specificity\"]\n",
    "\n",
    "# Crear un único plot con subplots para cada métrica\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    row, col = divmod(i, 3)\n",
    "    axes[row, col].hist(df[metric], bins=10, alpha=0.7, color=\"blue\", edgecolor=\"black\")\n",
    "    axes[row, col].set_title(metric)\n",
    "    axes[row, col].set_xlabel(metric)\n",
    "    axes[row, col].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('./model_results_combined.csv')\n",
    "\n",
    "# Convertir la columna 'Encoded Architecture' de strings a listas de enteros\n",
    "data['Encoded Architecture'] = data['Encoded Architecture'].apply(eval)\n",
    "\n",
    "# Expandir 'Encoded Architecture' en múltiples columnas\n",
    "X = pd.DataFrame(data['Encoded Architecture'].tolist())\n",
    "y_metrics = data[['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_metrics, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la métrica de evaluación\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Espacios de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "results = {}\n",
    "\n",
    "# Optimización y evaluación para cada métrica en y_metrics\n",
    "for metric in y_metrics.columns:\n",
    "    print(f\"\\nOptimización del modelo para {metric}...\")\n",
    "\n",
    "    # Crear modelo base\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "    \n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model, \n",
    "        param_grid=param_grid,\n",
    "        scoring=scorer, \n",
    "        cv=10, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train[metric])\n",
    "    best_grid_model = grid_search.best_estimator_\n",
    "    best_grid_score = -grid_search.best_score_\n",
    "    best_grid_params = grid_search.best_params_\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model, \n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20, \n",
    "        scoring=scorer, \n",
    "        cv=10, \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train, y_train[metric])\n",
    "    best_random_model = random_search.best_estimator_\n",
    "    best_random_score = -random_search.best_score_\n",
    "    best_random_params = random_search.best_params_\n",
    "\n",
    "    print(f\"\\nResultados para {metric} - GridSearchCV:\")\n",
    "    print(f\"Mejor MSE: {best_grid_score}\")\n",
    "    print(f\"Mejores hiperparámetros: {best_grid_params}\")\n",
    "\n",
    "    print(f\"\\nResultados para {metric} - RandomizedSearchCV:\")\n",
    "    print(f\"Mejor MSE: {best_random_score}\")\n",
    "    print(f\"Mejores hiperparámetros: {best_random_params}\")\n",
    "    \n",
    "    # Evaluación del mejor modelo de cada método\n",
    "    for search_type, best_model, best_params, best_score in [\n",
    "        (\"GridSearchCV\", best_grid_model, best_grid_params, best_grid_score),\n",
    "        (\"RandomizedSearchCV\", best_random_model, best_random_params, best_random_score)\n",
    "    ]:\n",
    "        # Predecir en el conjunto de prueba\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test[metric], y_pred)\n",
    "        variance = np.var(y_test[metric] - y_pred)\n",
    "\n",
    "        # Almacenar resultados\n",
    "        results[(metric, search_type)] = {\n",
    "            'best_score': best_score,\n",
    "            'best_params': best_params,\n",
    "            'test_mse': mse,\n",
    "            'variance': variance,\n",
    "            'real_values': y_test[metric].values,\n",
    "            'predicted_values': y_pred\n",
    "        }\n",
    "\n",
    "        # Guardar el modelo optimizado en disco\n",
    "        joblib.dump(best_model, f\"{metric}_{search_type}_optimized_surrogate_model.pkl\")\n",
    "\n",
    "# Crear una tabla resumen con los resultados de MSE y varianza\n",
    "summary = []\n",
    "for (metric, search_type), result in results.items():\n",
    "    summary.append({\n",
    "        'Metric': metric,\n",
    "        'Search Type': search_type,\n",
    "        'Best Score (Cross-Validated)': result['best_score'],\n",
    "        'Test MSE': result['test_mse'],\n",
    "        'Variance': result['variance'],\n",
    "        'Best Params': result['best_params']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "print(\"\\nResumen de los resultados de optimización:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Visualizar las predicciones reales y esperadas para cada métrica en el conjunto de prueba\n",
    "for (metric, search_type), result in results.items():\n",
    "    print(f\"\\nPredicciones para {metric} ({search_type}):\")\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Real': result['real_values'],\n",
    "        'Predicted': result['predicted_values']\n",
    "    })\n",
    "    print(comparison_df.head())\n",
    "    print(f\"Varianza de las predicciones para {metric}: {result['variance']}\")\n",
    "    print(f\"MSE en el conjunto de prueba para {metric}: {result['test_mse']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRobar aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_layer(layer_type):\n",
    "    if layer_type == 'Conv2D':\n",
    "        return {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'DepthwiseConv2D':\n",
    "        return {\n",
    "            \"type\": \"DepthwiseConv2D\",\n",
    "            \"filters\": random.randint(4, 16),  # Rango reducido para filtros\n",
    "            \"strides\": random.choice([1, 2]),\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        return {\"type\": \"BatchNorm\"}\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        return {\n",
    "            \"type\": \"MaxPooling\",\n",
    "            \"strides\": random.choice([1, 2])\n",
    "        }\n",
    "    elif layer_type == 'Dropout':\n",
    "        return {\n",
    "            \"type\": \"Dropout\",\n",
    "            \"rate\": random.choice([0.2, 0.3, 0.4, 0.5])\n",
    "        }\n",
    "    elif layer_type == 'Dense':\n",
    "        return {\n",
    "            \"type\": \"Dense\",\n",
    "            \"units\": random.randint(1, 128),  # Rango reducido para unidades\n",
    "            \"activation\": random.choice([\"relu\", \"leaky_relu\", \"sigmoid\", \"tanh\"])\n",
    "        }\n",
    "    elif layer_type == 'Flatten':\n",
    "        return {\"type\": \"Flatten\"}\n",
    "    elif layer_type == 'DontCare':\n",
    "        return {\"type\": \"DontCare\"}\n",
    "    elif layer_type == 'Repetition':\n",
    "        return {\n",
    "            \"type\": \"Repetition\",\n",
    "            \"repetition_layers\": random.randint(1, 3),  # Limitar el número de capas para repetir\n",
    "            \"repetition_count\": random.randint(1, 2)  # Limitar el conteo de repeticiones\n",
    "        }\n",
    "    return {}\n",
    "\n",
    "\n",
    "def generate_random_architecture():\n",
    "    num_layers = 12\n",
    "    layers = []\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        layer_type = random.choice([\n",
    "            'Conv2D', 'DepthwiseConv2D', 'BatchNorm', 'MaxPooling', 'Dropout',\n",
    "            'Dense', 'Flatten', 'DontCare', 'Repetition'\n",
    "        ])\n",
    "        layers.append(generate_layer(layer_type))\n",
    "    return {\"layers\": layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar los modelos ganadores para cada métrica\n",
    "metric_models = {}\n",
    "metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']\n",
    "\n",
    "for metric in metrics:\n",
    "    metric_models[metric] = joblib.load(f\"{metric}_best_model.pkl\")\n",
    "\n",
    "# Lista para almacenar resultados de predicciones\n",
    "results = []\n",
    "\n",
    "\n",
    "\n",
    "# Generar 10 arquitecturas y predecir métricas para cada una usando los modelos ganadores\n",
    "for i in range(10):\n",
    "    print(f\"\\nGenerando arquitectura {i+1}...\")\n",
    "    \n",
    "    # Generar una arquitectura de ejemplo\n",
    "    model_dict = generate_random_architecture()\n",
    "    encoded_model = encode_model_architecture(model_dict, max_alleles=48)\n",
    "    fixed_model = fixArch(encoded_model, verbose=False)\n",
    "    \n",
    "    # Preparar arquitectura para predicción\n",
    "    example_architecture = np.array(fixed_model).reshape(1, -1)\n",
    "    print(f\"Arquitectura de ejemplo: {example_architecture}\")\n",
    "    \n",
    "    # Predicciones para cada métrica usando el modelo ganador correspondiente\n",
    "    predictions = {'Architecture': fixed_model}\n",
    "    for metric, model in metric_models.items():\n",
    "        predicted_value = model.predict(example_architecture)[0]\n",
    "        predictions[metric] = predicted_value\n",
    "        print(f\"Predicción de {metric} para la arquitectura {i+1}: {predicted_value}\")\n",
    "    \n",
    "    # Agregar predicciones al conjunto de resultados\n",
    "    results.append(predictions)\n",
    "\n",
    "# Crear un DataFrame de pandas con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nTabla de predicciones para las 10 arquitecturas generadas:\")\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas de comparacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Cargar los resultados reales del CSV de experimentos completados\n",
    "real_results = pd.read_csv('experiment_results.csv')\n",
    "\n",
    "# Filtrar los resultados reales para considerar solo Splits=10, Epochs=50, y Window Size=5\n",
    "filtered_real_results = real_results[\n",
    "    (real_results['Splits'] == 10) &\n",
    "    (real_results['Epochs'] == 50) &\n",
    "    (real_results['Window Size'] == 5)\n",
    "]\n",
    "\n",
    "# Renombrar la columna F1-score para coincidir con las métricas de los modelos predichos\n",
    "filtered_real_results.rename(columns={'F1-score': 'F1'}, inplace=True)\n",
    "\n",
    "# Cargar los modelos ganadores para cada métrica\n",
    "metric_models = {}\n",
    "metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']\n",
    "for metric in metrics:\n",
    "    metric_models[metric] = joblib.load(f\"{metric}_best_model.pkl\")\n",
    "\n",
    "# Diccionario de modelos a verificar\n",
    "models_to_test = {\n",
    "    \"CNN_LF\": model_CNN_LF,\n",
    "    \"reduced_model\": model_reduced,\n",
    "    \"Spectro_CNN\": model_spectro_CNN,\n",
    "}\n",
    "\n",
    "# Lista para almacenar predicciones\n",
    "predictions = []\n",
    "\n",
    "# Generar predicciones usando los modelos ganadores\n",
    "for model_name, model_architecture in models_to_test.items():\n",
    "    # Codificar el modelo\n",
    "    encoded_architecture = encode_model_architecture(model_architecture, max_alleles=48)\n",
    "    fixed_architecture = fixArch(encoded_architecture, verbose=False)\n",
    "    example_architecture = np.array(fixed_architecture).reshape(1, -1)\n",
    "\n",
    "    # Predicciones para cada métrica\n",
    "    pred_result = {'Architecture': model_name}\n",
    "    for metric, model in metric_models.items():\n",
    "        predicted_value = model.predict(example_architecture)[0]\n",
    "        pred_result[metric] = predicted_value\n",
    "    \n",
    "    # Agregar predicciones a la lista\n",
    "    predictions.append(pred_result)\n",
    "\n",
    "# Convertir predicciones en DataFrame\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Combinar los resultados reales filtrados y las predicciones para el análisis comparativo\n",
    "df_comparison = pd.merge(filtered_real_results, df_predictions, on='Architecture', suffixes=('_real', '_pred'))\n",
    "\n",
    "# Crear un DataFrame para mostrar tanto el valor real como el predicho lado a lado\n",
    "comparative_columns = []\n",
    "for metric in metrics:\n",
    "    comparative_columns.extend([f\"{metric}_real\", f\"{metric}_pred\"])\n",
    "\n",
    "df_comparison = df_comparison[['Architecture'] + comparative_columns]\n",
    "\n",
    "# Calcular métricas de evaluación para cada métrica de rendimiento\n",
    "comparison_metrics = []\n",
    "for metric in metrics:\n",
    "    real_values = df_comparison[f\"{metric}_real\"]\n",
    "    predicted_values = df_comparison[f\"{metric}_pred\"]\n",
    "    \n",
    "    mse = mean_squared_error(real_values, predicted_values)\n",
    "    mae = mean_absolute_error(real_values, predicted_values)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((real_values - predicted_values) / real_values)) * 100\n",
    "    r2 = r2_score(real_values, predicted_values)\n",
    "    \n",
    "    comparison_metrics.append({\n",
    "        'Metric': metric,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE (%)': mape,\n",
    "        'R^2': r2\n",
    "    })\n",
    "\n",
    "# Crear DataFrame de métricas comparativas\n",
    "df_comparison_metrics = pd.DataFrame(comparison_metrics)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"\\nTabla de comparación de valores reales y predichos para cada métrica:\")\n",
    "df_comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMétricas de evaluación entre predicciones y valores reales:\")\n",
    "df_comparison_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos\n",
    "print(\"Cargando los datos...\")\n",
    "data = pd.read_csv('./model_results_combined.csv')\n",
    "print(f\"Datos cargados. Número de filas: {data.shape[0]}, columnas: {data.shape[1]}\")\n",
    "\n",
    "# Convertir la columna 'Encoded Architecture' de strings a listas de enteros\n",
    "print(\"Procesando la columna 'Encoded Architecture'...\")\n",
    "data['Encoded Architecture'] = data['Encoded Architecture'].apply(eval)\n",
    "\n",
    "# Expandir 'Encoded Architecture' en múltiples columnas\n",
    "print(\"Expandiendo 'Encoded Architecture' en columnas separadas...\")\n",
    "X = pd.DataFrame(data['Encoded Architecture'].tolist())\n",
    "y_metrics = data[['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "print(\"Dividiendo datos en conjuntos de entrenamiento y prueba...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_metrics, test_size=0.2, random_state=42)\n",
    "print(f\"Datos divididos: {X_train.shape[0]} para entrenamiento, {X_test.shape[0]} para prueba.\")\n",
    "\n",
    "# Definir la métrica de evaluación\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Espacios de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar los resultados\n",
    "results = {}\n",
    "\n",
    "# Optimización y evaluación para cada métrica en y_metrics\n",
    "for metric in y_metrics.columns:\n",
    "    print(f\"\\nOptimización del modelo para {metric}...\")\n",
    "\n",
    "    # Crear modelo base\n",
    "    model = SVR()\n",
    "\n",
    "    # GridSearchCV\n",
    "    print(f\"Comenzando GridSearchCV para {metric}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model, \n",
    "        param_grid=param_grid,\n",
    "        scoring=scorer, \n",
    "        cv=5, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train[metric])\n",
    "    print(f\"GridSearchCV completado para {metric}.\")\n",
    "    best_grid_model = grid_search.best_estimator_\n",
    "    best_grid_score = -grid_search.best_score_\n",
    "    best_grid_params = grid_search.best_params_\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    print(f\"Comenzando RandomizedSearchCV para {metric}...\")\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model, \n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10, \n",
    "        scoring=scorer, \n",
    "        cv=5, \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train, y_train[metric])\n",
    "    print(f\"RandomizedSearchCV completado para {metric}.\")\n",
    "    best_random_model = random_search.best_estimator_\n",
    "    best_random_score = -random_search.best_score_\n",
    "    best_random_params = random_search.best_params_\n",
    "\n",
    "    print(f\"\\nResultados para {metric} - GridSearchCV:\")\n",
    "    print(f\"Mejor MSE: {best_grid_score}\")\n",
    "    print(f\"Mejores hiperparámetros: {best_grid_params}\")\n",
    "\n",
    "    print(f\"\\nResultados para {metric} - RandomizedSearchCV:\")\n",
    "    print(f\"Mejor MSE: {best_random_score}\")\n",
    "    print(f\"Mejores hiperparámetros: {best_random_params}\")\n",
    "    \n",
    "    # Evaluación del mejor modelo de cada método\n",
    "    for search_type, best_model, best_params, best_score in [\n",
    "        (\"GridSearchCV\", best_grid_model, best_grid_params, best_grid_score),\n",
    "        (\"RandomizedSearchCV\", best_random_model, best_random_params, best_random_score)\n",
    "    ]:\n",
    "        print(f\"Evaluando el modelo {search_type} para {metric}...\")\n",
    "        # Predecir en el conjunto de prueba\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test[metric], y_pred)\n",
    "        variance = np.var(y_test[metric] - y_pred)\n",
    "\n",
    "        # Almacenar resultados\n",
    "        results[(metric, search_type)] = {\n",
    "            'best_score': best_score,\n",
    "            'best_params': best_params,\n",
    "            'test_mse': mse,\n",
    "            'variance': variance,\n",
    "            'real_values': y_test[metric].values,\n",
    "            'predicted_values': y_pred\n",
    "        }\n",
    "        print(f\"Evaluación completada. Test MSE: {mse}, Varianza: {variance}\")\n",
    "\n",
    "        # Guardar el modelo optimizado en disco\n",
    "        model_path = f\"{metric}_{search_type}_optimized_svm_model.pkl\"\n",
    "        joblib.dump(best_model, model_path)\n",
    "        print(f\"Modelo guardado en {model_path}\")\n",
    "\n",
    "# Crear una tabla resumen con los resultados de MSE y varianza\n",
    "print(\"\\nCreando tabla resumen de resultados...\")\n",
    "summary = []\n",
    "for (metric, search_type), result in results.items():\n",
    "    summary.append({\n",
    "        'Metric': metric,\n",
    "        'Search Type': search_type,\n",
    "        'Best Score (Cross-Validated)': result['best_score'],\n",
    "        'Test MSE': result['test_mse'],\n",
    "        'Variance': result['variance'],\n",
    "        'Best Params': result['best_params']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "print(\"\\nResumen de los resultados de optimización:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Visualizar las predicciones reales y esperadas para cada métrica en el conjunto de prueba\n",
    "for (metric, search_type), result in results.items():\n",
    "    print(f\"\\nPredicciones para {metric} ({search_type}):\")\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Real': result['real_values'],\n",
    "        'Predicted': result['predicted_values']\n",
    "    })\n",
    "    print(comparison_df.head())\n",
    "    print(f\"Varianza de las predicciones para {metric}: {result['variance']}\")\n",
    "    print(f\"MSE en el conjunto de prueba para {metric}: {result['test_mse']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Cargar los resultados reales del CSV de experimentos completados\n",
    "real_results = pd.read_csv('experiment_results.csv')\n",
    "\n",
    "# Filtrar los resultados reales para considerar solo Splits=10, Epochs=50, y Window Size=5\n",
    "filtered_real_results = real_results[\n",
    "    (real_results['Splits'] == 10) & \n",
    "    (real_results['Epochs'] == 50) & \n",
    "    (real_results['Window Size'] == 5)\n",
    "]\n",
    "\n",
    "# Renombrar la columna F1-score para coincidir con las métricas de los modelos predichos\n",
    "filtered_real_results.rename(columns={'F1-score': 'F1'}, inplace=True)\n",
    "\n",
    "# Cargar los modelos ganadores para cada métrica usando SVM\n",
    "metric_models = {}\n",
    "metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']\n",
    "for metric in metrics:\n",
    "    metric_models[metric] = joblib.load(f\"{metric}_RandomizedSearchCV_optimized_svm_model.pkl\")\n",
    "\n",
    "# Diccionario de modelos a verificar\n",
    "models_to_test = {\n",
    "    \"CNN_LF\": model_CNN_LF,\n",
    "    \"reduced_model\": model_reduced,\n",
    "    \"Spectro_CNN\": model_spectro_CNN,\n",
    "}\n",
    "\n",
    "# Lista para almacenar predicciones\n",
    "predictions = []\n",
    "\n",
    "# Generar predicciones usando los modelos ganadores\n",
    "for model_name, model_architecture in models_to_test.items():\n",
    "    # Codificar el modelo\n",
    "    encoded_architecture = encode_model_architecture(model_architecture, max_alleles=48)\n",
    "    fixed_architecture = fixArch(encoded_architecture, verbose=False)\n",
    "    example_architecture = np.array(fixed_architecture).reshape(1, -1)\n",
    "\n",
    "    # Predicciones para cada métrica\n",
    "    pred_result = {'Architecture': model_name}\n",
    "    for metric, model in metric_models.items():\n",
    "        predicted_value = model.predict(example_architecture)[0]\n",
    "        pred_result[metric] = predicted_value\n",
    "\n",
    "    # Agregar predicciones a la lista\n",
    "    predictions.append(pred_result)\n",
    "\n",
    "# Convertir predicciones en DataFrame\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "# Combinar los resultados reales filtrados y las predicciones para el análisis comparativo\n",
    "df_comparison = pd.merge(filtered_real_results, df_predictions, on='Architecture', suffixes=('_real', '_pred'))\n",
    "\n",
    "# Crear un DataFrame para mostrar tanto el valor real como el predicho lado a lado\n",
    "comparative_columns = []\n",
    "for metric in metrics:\n",
    "    comparative_columns.extend([f\"{metric}_real\", f\"{metric}_pred\"])\n",
    "\n",
    "df_comparison = df_comparison[['Architecture'] + comparative_columns]\n",
    "\n",
    "# Calcular métricas de evaluación para cada métrica de rendimiento\n",
    "comparison_metrics = []\n",
    "for metric in metrics:\n",
    "    real_values = df_comparison[f\"{metric}_real\"]\n",
    "    predicted_values = df_comparison[f\"{metric}_pred\"]\n",
    "\n",
    "    mse = mean_squared_error(real_values, predicted_values)\n",
    "    mae = mean_absolute_error(real_values, predicted_values)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((real_values - predicted_values) / real_values)) * 100\n",
    "    r2 = r2_score(real_values, predicted_values)\n",
    "\n",
    "    comparison_metrics.append({\n",
    "        'Metric': metric,\n",
    "        'MSE': mse,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE (%)': mape,\n",
    "        'R^2': r2\n",
    "    })\n",
    "\n",
    "# Crear DataFrame de métricas comparativas\n",
    "df_comparison_metrics = pd.DataFrame(comparison_metrics)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"\\nTabla de comparación de valores reales y predichos para cada métrica:\")\n",
    "df_comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResumen de las métricas de evaluación:\")\n",
    "df_comparison_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_synflow_scores(model, input_size):\n",
    "    \"\"\"\n",
    "    Calcula el puntaje SynFlow de un modelo dado un tamaño de entrada.\n",
    "    \"\"\"\n",
    "    # Crear una entrada ficticia (ones) del tamaño especificado\n",
    "    input_tensor = tf.ones(input_size)\n",
    "    \n",
    "    # Registrar gradientes\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_tensor)\n",
    "        output = model(input_tensor)  # Salida del modelo\n",
    "        objective = tf.ones_like(output)  # Objetivo ficticio\n",
    "    # Calcular gradientes\n",
    "    gradients = tape.gradient(output, model.trainable_weights, output_gradients=objective)\n",
    "    \n",
    "    # Puntuación de SynFlow como suma de los pesos y gradientes absolutos\n",
    "    scores = [tf.reduce_sum(tf.abs(w * g)) for w, g in zip(model.trainable_weights, gradients)]\n",
    "    total_score = tf.reduce_sum(scores)\n",
    "    \n",
    "    return total_score.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparar cada ejemplo con fixArch y luego decodificar con decode_model_architecture\n",
    "repaired_and_decoded_models = []\n",
    "\n",
    "for i, encoded_model in enumerate([encoded_model_1, encoded_model_2, encoded_model_3, encoded_model_4, encoded_model_5], 1):\n",
    "    # Reparar el modelo\n",
    "    repaired_model = fixArch(encoded_model, verbose=True)\n",
    "    # Decodificar el modelo reparado\n",
    "    decoded_model = decode_model_architecture(repaired_model)\n",
    "    tf_model = build_tf_model_from_dict(decoded_model, input_shape=(128, 128, 1))\n",
    "    synflow_score = compute_synflow_scores(tf_model, input_size=(1, 128, 128, 1))  # Espectrograma como entrada\n",
    "    print(f\"SynFlow Score para el modelo {i}: {synflow_score}\")\n",
    "    # Guardar el modelo decodificado\n",
    "    repaired_and_decoded_models.append(decoded_model)\n",
    "    print(f\"\\n--- Modelo {i} Decodificado ---\")\n",
    "    print(decoded_model)\n",
    "\n",
    "# Opcional: Mostrar todos los modelos decodificados juntos\n",
    "print(\"\\n--- Todos los Modelos Decodificados ---\")\n",
    "for i, model in enumerate(repaired_and_decoded_models, 1):\n",
    "    print(f\"Modelo {i} Decodificado:\", model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisar significancia de synflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "import ast  # Para convertir la arquitectura en una lista\n",
    "\n",
    "\n",
    "# Leer el dataset\n",
    "dataset_path = \"./model_results_combined.csv\"  # Cambia esto a la ruta de tu archivo\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Generar SynFlow y calcular correlaciones\n",
    "synflow_scores = []\n",
    "for idx, row in df.iterrows():\n",
    "    # Convertir arquitectura de texto a lista\n",
    "    encoded_architecture = ast.literal_eval(row['Encoded Architecture'])\n",
    "    \n",
    "    # Construir modelo desde la arquitectura\n",
    "    model = decode_model_architecture(encoded_architecture)\n",
    "    model = build_tf_model_from_dict(model, input_shape=(128, 128, 1))\n",
    "    \n",
    "    # Calcular SynFlow\n",
    "    synflow_score = compute_synflow_scores(model, input_size=(1, 128, 128, 1))\n",
    "    synflow_scores.append(synflow_score)\n",
    "\n",
    "# Agregar SynFlow al dataset\n",
    "df['SynFlow'] = synflow_scores\n",
    "\n",
    "# Correlaciones con métricas\n",
    "metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']\n",
    "correlations = {}\n",
    "for metric in metrics:\n",
    "    correlations[metric] = r2_score(df[metric], df['SynFlow'])\n",
    "\n",
    "# Mostrar correlaciones\n",
    "for metric, corr in correlations.items():\n",
    "    print(f\"Correlación (R²) entre SynFlow y {metric}: {corr}\")\n",
    "\n",
    "# Guardar resultados\n",
    "df.to_csv(\"./dataset_with_synflow.csv\", index=False)\n",
    "print(\"Dataset actualizado con SynFlow guardado como 'dataset_with_synflow.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Función para calcular todas las métricas de correlación\n",
    "def compute_correlations(x, y):\n",
    "    r2 = r2_score(y, x)\n",
    "    pearson_corr, _ = pearsonr(x, y)\n",
    "    spearman_corr, _ = spearmanr(x, y)\n",
    "    kendall_corr, _ = kendalltau(x, y)\n",
    "    return r2, pearson_corr, spearman_corr, kendall_corr\n",
    "\n",
    "# Leer el dataset con SynFlow ya calculado\n",
    "dataset_path = \"dataset_with_synflow.csv\"  # Cambia esto a tu ruta\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Calcular correlaciones para cada métrica\n",
    "metrics = ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity']\n",
    "correlations = []\n",
    "\n",
    "for metric in metrics:\n",
    "    r2, pearson, spearman, kendall = compute_correlations(df['SynFlow'], df[metric])\n",
    "    correlations.append([metric, r2, pearson, spearman, kendall])\n",
    "\n",
    "# Crear un DataFrame para las correlaciones\n",
    "correlation_df = pd.DataFrame(correlations, columns=['Metric', 'R2', 'Pearson', 'Spearman', 'Kendall'])\n",
    "\n",
    "# Mostrar las correlaciones\n",
    "print(\"Correlaciones entre SynFlow y métricas:\")\n",
    "print(correlation_df)\n",
    "\n",
    "# Graficar las relaciones\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='SynFlow', y=metric, data=df)\n",
    "    plt.title(f\"SynFlow vs {metric}\")\n",
    "    plt.xlabel(\"SynFlow\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Graficar un heatmap de las correlaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "heatmap_data = correlation_df.set_index('Metric').drop(columns='R2')\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlaciones entre SynFlow y métricas\")\n",
    "plt.show()\n",
    "\n",
    "# Histogramas de SynFlow\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['SynFlow'], kde=True, bins=30)\n",
    "plt.title(\"Distribución de SynFlow\")\n",
    "plt.xlabel(\"SynFlow\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_real_dom(num, domain):\n",
    "  min_i, max_i = domain\n",
    "  r = (num - min_i) / (max_i - min_i)\n",
    "  return r\n",
    "\n",
    "def real_to_int_dom(num, domain):\n",
    "  min_i, max_i = domain\n",
    "  value = min_i + num * (max_i - min_i)\n",
    "  if isinstance(min_i, int) and isinstance(max_i, int):\n",
    "      value = int(round(value))\n",
    "  return value\n",
    "\n",
    "def convert_individual(ind, to_real=True):\n",
    "    real_rep = []\n",
    "    N = max(layer_type_options.keys())\n",
    "    for i in range(0, len(ind), 4):\n",
    "        layer_type_idx = ind[i]\n",
    "        domain_layer_type = [0, N]\n",
    "        if to_real:\n",
    "            real_rep.append(int_to_real_dom(layer_type_idx, domain_layer_type))\n",
    "            layer_type = layer_type_options.get(layer_type_idx, 'DontCare')\n",
    "        else:\n",
    "            real_rep.append(real_to_int_dom(layer_type_idx, domain_layer_type))\n",
    "            layer_type = layer_type_options.get(real_rep[i], 'DontCare')\n",
    "\n",
    "        # Decode based on layer type\n",
    "        if layer_type in ['Conv2D', 'DepthwiseConv2D']:\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [4, 32]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [0, 1]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 3], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [4, 32]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [0, 1]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 3], [0, 3]))\n",
    "        elif layer_type == 'BatchNorm':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "        elif layer_type == 'MaxPooling':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [0, 1]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [0, 1]))\n",
    "            real_rep.extend([0, 0])\n",
    "        elif layer_type == 'Dropout':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [0, 3]))\n",
    "            real_rep.extend([0, 0])\n",
    "        elif layer_type == 'Dense':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [1, 512]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [0, 3]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [1, 512]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [0, 3]))\n",
    "            real_rep.append(0)\n",
    "        elif layer_type == 'Flatten':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "        elif layer_type == 'Repetition':\n",
    "            if to_real:\n",
    "                real_rep.append(int_to_real_dom(ind[i + 1], [1, 4]))\n",
    "                real_rep.append(int_to_real_dom(ind[i + 2], [1, 32]))\n",
    "            else:\n",
    "                real_rep.append(real_to_int_dom(ind[i + 1], [1, 4]))\n",
    "                real_rep.append(real_to_int_dom(ind[i + 2], [1, 32]))\n",
    "            real_rep.append(0)\n",
    "        elif layer_type == 'DontCare':\n",
    "            real_rep.extend([0, 0, 0])\n",
    "    return real_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_succ_m(parents, children):\n",
    "  # Count if mutation was successful than the average parent fitness\n",
    "  parent_fitness = [parent['fitness'] for parent in parents]\n",
    "  avg_fitness = np.mean(parent_fitness)\n",
    "\n",
    "  succ_m_count = sum(1 for child in children if child['fitness'] < avg_fitness)\n",
    "\n",
    "  return succ_m_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cr_points(rp, n):\n",
    "  indexes = list(range(n))\n",
    "  j_star = random.sample(indexes, n // 2)\n",
    "\n",
    "  for j in range(n):\n",
    "    if random.random() < rp and j not in j_star:\n",
    "      j_star.append(j)\n",
    "\n",
    "  return j_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_gen(num_models, max_alleles=48):\n",
    "    \"\"\"\n",
    "    Genera una población inicial utilizando el hipercubo latino y las funciones existentes.\n",
    "\n",
    "    Args:\n",
    "        num_models: int - Número de individuos a generar.\n",
    "        max_alleles: int - Número máximo de alelos en los cromosomas.\n",
    "\n",
    "    Returns:\n",
    "        list - Lista de diccionarios con individuos y su fitness inicializado a 0.\n",
    "    \"\"\"\n",
    "    archs = []\n",
    "    dimensions = 12 * 3  # 12 capas, 3 parámetros por capa\n",
    "\n",
    "    # Generar muestras del hipercubo latino\n",
    "    latin_samples = generate_latin_hypercube_samples(num_models, dimensions)\n",
    "\n",
    "    for sample in latin_samples:\n",
    "        # Transformar cada muestra en una arquitectura\n",
    "        model_samples = sample.reshape(12, 3)\n",
    "        model_dict = {\n",
    "            \"layers\": [map_to_architecture_params(layer_sample) for layer_sample in model_samples]\n",
    "        }\n",
    "\n",
    "        # Codificar el modelo y repararlo\n",
    "        encoded_chromosome = encode_model_architecture(model_dict, max_alleles=max_alleles)\n",
    "        repaired_architecture = fixArch(encoded_chromosome)\n",
    "\n",
    "        # Añadir a la población\n",
    "        archs.append({'individual': repaired_architecture, 'fitness': 0})\n",
    "\n",
    "    return archs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def es(target_func, mu=10, lamb=1, F=2, rp=0.5, gens=100, n=10, auto_adapt=False):\n",
    "    # Initialize parent population\n",
    "    pop = pop_gen(mu)\n",
    "    succ_m_count = 0\n",
    "    best_fitness_per_gen = []\n",
    "    Fs = []\n",
    "\n",
    "    # Barra de progreso para generaciones\n",
    "    with tqdm(total=gens, desc=\"Generations\", leave=False) as pbar_gens:\n",
    "        for gen in range(gens):\n",
    "            children = []\n",
    "\n",
    "            # Calc fitness and select best element\n",
    "            pop = [{'individual': parent['individual'], 'fitness': target_func(parent['individual'])} for parent in pop]\n",
    "            best_parent = max(pop, key=lambda x: x['fitness'])\n",
    "\n",
    "            for i in range(lamb):\n",
    "                parent = pop[i]['individual']\n",
    "\n",
    "                # Map individuals to real values\n",
    "                parent_unit = convert_individual(parent)\n",
    "                best_parent_c = convert_individual(best_parent['individual'])\n",
    "\n",
    "                # Mutation and repair mechanism\n",
    "                x2, x3 = random.sample(pop, 2)\n",
    "                x2 = convert_individual(x2['individual'])\n",
    "                x3 = convert_individual(x3['individual'])\n",
    "                u = []\n",
    "                for j in range(len(best_parent_c)):\n",
    "                    u.append(best_parent_c[j] + F * (x2[j] - x3[j]))\n",
    "                u = fixArch(convert_individual(u, to_real=False))\n",
    "                u = convert_individual(u)\n",
    "\n",
    "                # Recombination\n",
    "                cr_points = get_cr_points(rp, len(parent))\n",
    "                child = [u[j] if j in cr_points else parent[j] for j in range(len(u))]\n",
    "                child = fixArch(convert_individual(child, to_real=False))\n",
    "\n",
    "                children.append({'individual': child, 'fitness': 0})\n",
    "\n",
    "                # Calc fitness of children\n",
    "                children = [{'individual': child['individual'], 'fitness': target_func(child['individual'])} for child in children]\n",
    "\n",
    "            # Select the best mu elements for next gen\n",
    "            complete_pop = pop + children\n",
    "\n",
    "            if(auto_adapt):\n",
    "                # Count succesful mutations\n",
    "                succ_m_count += get_succ_m(pop, children)\n",
    "\n",
    "                # During each time window (n) self-adapt F\n",
    "                if (gen + 1) % n == 0:\n",
    "                    Fs.append(F)\n",
    "                    ps = succ_m_count / (n * lamb)\n",
    "\n",
    "                    if ps > 1/5:\n",
    "                        F /= 0.817\n",
    "                    elif ps < 1/5:\n",
    "                        F *= 0.817\n",
    "\n",
    "                    succ_m_count = 0\n",
    "\n",
    "                pop = sorted(complete_pop, key=lambda x: x['fitness'], reverse=True)[:mu]\n",
    "                best_fitness_per_gen.append(max(pop, key=lambda x: x['fitness'])['fitness'])\n",
    "\n",
    "            # Actualizar la barra de progreso de generaciones\n",
    "            pbar_gens.update(1)\n",
    "\n",
    "    best_element = max(pop, key=lambda x: x['fitness'])\n",
    "    Fs.append(F)\n",
    "    return best_element, best_fitness_per_gen, Fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def eval_arch(ind):\n",
    "  ind_c = copy.deepcopy(ind)\n",
    "  reshaped_ind_c = np.array(ind_c).reshape(1, -1)\n",
    "  acc = model.predict(reshaped_ind_c)\n",
    "  return acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "best_models = []\n",
    "all_best_fitness = []\n",
    "F_arr = []\n",
    "# Agregar tqdm para mostrar progreso\n",
    "for i in tqdm(range(30), desc=\"Running Experiments\"):\n",
    "\n",
    "    best_model, best_fitness_per_gen, Fs = es(\n",
    "        eval_arch,\n",
    "        gens=1000,\n",
    "        F=0.5,\n",
    "        mu=5000,\n",
    "        auto_adapt=True\n",
    "    )\n",
    "    F_arr.append(Fs)\n",
    "    best_models.append(best_model)\n",
    "    all_best_fitness.append(best_fitness_per_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the maximum number of generations across all runs\n",
    "max_generations = max(len(fitness) for fitness in all_best_fitness)\n",
    "generations = np.arange(1, max_generations + 1)\n",
    "\n",
    "# Initialize a matrix to hold all fitness values, handling varying lengths\n",
    "fitness_matrix = np.full((30, max_generations), np.nan)\n",
    "\n",
    "for i, best_fitness_per_gen in enumerate(all_best_fitness):\n",
    "    fitness_length = len(best_fitness_per_gen)\n",
    "    fitness_matrix[i, :fitness_length] = best_fitness_per_gen\n",
    "\n",
    "# Plot all runs in light gray\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(30):\n",
    "    plt.plot(\n",
    "        generations,\n",
    "        fitness_matrix[i],\n",
    "        linestyle='-',\n",
    "        color='red',\n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "# Compute the mean and standard deviation across runs at each generation\n",
    "mean_fitness = np.nanmean(fitness_matrix, axis=0)\n",
    "std_fitness = np.nanstd(fitness_matrix, axis=0)\n",
    "\n",
    "# Plot the mean best fitness\n",
    "plt.plot(\n",
    "    generations,\n",
    "    mean_fitness,\n",
    "    linestyle='-',\n",
    "    color='blue',\n",
    "    label='Mean Accuracy'\n",
    ")\n",
    "\n",
    "# Fill the area between (mean - std) and (mean + std)\n",
    "plt.fill_between(\n",
    "    generations,\n",
    "    mean_fitness - std_fitness,\n",
    "    mean_fitness + std_fitness,\n",
    "    color='blue',\n",
    "    alpha=0.2,\n",
    "    label='Standard Deviation'\n",
    ")\n",
    "\n",
    "plt.title('Convergence Plot of Accuracy per Generation over 30 Runs')\n",
    "plt.xlabel('Generations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
