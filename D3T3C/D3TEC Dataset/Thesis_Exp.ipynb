{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T23:16:36.750996Z",
     "start_time": "2024-07-13T23:16:36.739508Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchaudio\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping, History\n",
    "from keras.optimizers import Adadelta\n",
    "import os\n",
    "import copy\n",
    "from livelossplot import PlotLossesKeras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow_addons as tfa\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfdb6f1-6921-4d72-9c30-dae1b8fd37e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T23:16:36.870984Z",
     "start_time": "2024-07-13T23:16:36.759589Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD AUDIOS\n",
    "def load_audios(folder_path):\n",
    "    LOADED = {}\n",
    "    samplerate = torchaudio.load(folder_path+'/'+os.listdir(folder_path)[0])[1]\n",
    "\n",
    "    for filename in tqdm(os.listdir(folder_path), desc='LOAD AUDIOS'):\n",
    "        if not filename.startswith('.'):\n",
    "            audio = torchaudio.load(folder_path+'/'+filename, normalize=True)\n",
    "            LOADED[filename] = audio[0][0]\n",
    "        if audio[1] != samplerate:\n",
    "            return 'ERROR: All audios in folder must have the same samplerate.'\n",
    "    return LOADED, samplerate\n",
    "\n",
    "#RESAMPLE\n",
    "def resampling(audio_dict, original_samplerate, new_samplerate):\n",
    "    if (new_samplerate == original_samplerate) or (new_samplerate == None):\n",
    "        return audio_dict, original_samplerate\n",
    "    else:\n",
    "        resample = torchaudio.transforms.Resample(orig_freq=original_samplerate, new_freq=new_samplerate)\n",
    "        for filename, audio in tqdm(audio_dict.items(), desc='RESAMPLING'):\n",
    "            audio_dict[filename] = resample(audio)\n",
    "        return audio_dict, new_samplerate\n",
    "\n",
    "#Fragment audios FILL WITH ZEROS\n",
    "def fragment_audio(audio_dict, samplerate, time=1):\n",
    "    for filename, audio in tqdm(audio_dict.items(),desc='FRAGMENT AUDIOS'):\n",
    "        fill = len(audio)-samplerate*time\n",
    "        if fill >0:\n",
    "            cut_clean = int(len(audio) - len(audio)%(samplerate*time))\n",
    "            audio = audio[:cut_clean]\n",
    "        else:\n",
    "            audio = torch.cat((audio,torch.zeros((abs(fill),))),0)\n",
    "        n_clips = int(len(audio)/(samplerate*time))\n",
    "        audio = audio.reshape([n_clips, int(samplerate*time)])\n",
    "        audio_dict[filename] = np.array(audio)\n",
    "    return audio_dict, time\n",
    "\n",
    "#Convert to Mel Spectrogram\n",
    "def MELspectrogram(audio_dict, samplerate):\n",
    "    audio_dict = copy.deepcopy(audio_dict)\n",
    "    n_mels = 128\n",
    "    n_fft = int(samplerate*0.029)\n",
    "    hop_length = int(samplerate*0.010)\n",
    "    win_length=int(samplerate*0.025)\n",
    "\n",
    "    for filename, waveform in tqdm(audio_dict.items(), desc='MELSPECTROGRAM'):\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "        spec = torchaudio.transforms.MelSpectrogram(sample_rate=samplerate, n_fft=n_fft, n_mels=n_mels, hop_length=hop_length,win_length=win_length)(waveform); waveform\n",
    "\n",
    "        spec = torchaudio.transforms.AmplitudeToDB()(spec);spec\n",
    "        spec = spec.numpy();spec\n",
    "        spec = (spec - spec.min()) / (spec.max() - spec.min()); spec\n",
    "        #spec = spec.astype('uint8'); spec\n",
    "        audio_dict[filename] = spec\n",
    "    return audio_dict\n",
    "\n",
    "#Train Test split AUDIO\n",
    "def train_test(audio_dict):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID','PHQ-9 Score',],dtype={1:str})\n",
    "    df['labels'] = np.zeros([len(df),],dtype=int)\n",
    "    df.loc[df['PHQ-9 Score'] <10, 'labels'] = 0\n",
    "    df.loc[df['PHQ-9 Score'] >=10, 'labels'] = 1\n",
    "    train_labels, test_labels = train_test_split(df, test_size=0.2, train_size=0.8,shuffle=False)\n",
    "\n",
    "    train_labels = train_labels.set_index('Participant_ID').to_dict()['labels']\n",
    "    test_labels =  test_labels.set_index('Participant_ID').to_dict()['labels']\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        if ID in train_labels:\n",
    "            dep = 0 if train_labels[ID]==0 else 1\n",
    "            [X_train.append(x) for x in data]\n",
    "            [Y_train.append(dep) for x in data]\n",
    "        if ID in test_labels:\n",
    "            dep = 0 if test_labels[ID]==0 else 1\n",
    "            [X_test.append(x) for x in data]\n",
    "            [Y_test.append(dep) for x in data]\n",
    "\n",
    "    X_train = tf.convert_to_tensor(X_train)\n",
    "    Y_train = tf.convert_to_tensor(Y_train)\n",
    "    X_test = tf.convert_to_tensor(X_test)\n",
    "    Y_test = tf.convert_to_tensor(Y_test)\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "def train_test2(audio_dict):\n",
    "    train_set = {116: 1, 148: 5, 112: 5, 152: 5, 5: 7, 149: 12, 3: 3, 128: 11, 138: 14, 9: 21, 134: 6, 106: 24, 142: 4, 139: 8, 114: 23, 146: 10, 151: 4, 118: 8, 130: 5, 135: 9, 4: 13, 137: 10, 143: 11, 133: 11, 140: 4, 147: 3, 153: 19, 119: 1, 121: 13, 8: 12, 107: 5, 132: 20, 103: 15, 136: 19, 117: 7, 129: 2, 123: 10, 122: 15, 131: 13, 102: 6, 145: 5}\n",
    "\n",
    "    test_set =  {111: 16, 115: 2, 108: 14, 120: 12, 113: 12, 124: 11, 125: 10, 126: 2, 144: 3, 141: 2, 127: 9}\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = int(filename[:3])\n",
    "        if ID in train_set:\n",
    "            dep = 0 if train_set[ID]< 10 else 1\n",
    "            [X_train.append(x) for x in data]\n",
    "            [Y_train.append(dep) for x in data]\n",
    "        if ID in test_set:\n",
    "            dep = 0 if test_set[ID]<10 else 1\n",
    "            [X_test.append(x) for x in data]\n",
    "            [Y_test.append(dep) for x in data]\n",
    "\n",
    "    X_train = tf.convert_to_tensor(X_train)\n",
    "    Y_train = tf.convert_to_tensor(Y_train)\n",
    "    X_test = tf.convert_to_tensor(X_test)\n",
    "    Y_test = tf.convert_to_tensor(Y_test)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "#XY Split Depression\n",
    "def XY_dep(audio_dict, Gender = None):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID','PHQ-9 Score','Gender'],dtype={1:str})\n",
    "    df = df[df.Gender == Gender] if Gender != None else df\n",
    "    df['labels'] = np.zeros([len(df),],dtype=int)\n",
    "    df.loc[df['PHQ-9 Score'] <10, 'labels'] = 0\n",
    "    df.loc[df['PHQ-9 Score'] >=10, 'labels'] = 1\n",
    "\n",
    "    labels = df.set_index('Participant_ID').to_dict()['labels']\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        dep = 0 if labels[ID]==0 else 1\n",
    "        [X.append(x) for x in data]\n",
    "        [Y.append(dep) for x in data]\n",
    "        \n",
    "    X = tf.convert_to_tensor(X)\n",
    "    Y = tf.convert_to_tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "#XY Split by gender\n",
    "def XY_gender(audio_dict, Gender = None):\n",
    "    df = pd.read_csv('Dataset.csv', usecols=['Participant_ID','PHQ-9 Score','Gender'],dtype={1:str})\n",
    "    df['labels'] = np.zeros([len(df),],dtype=int)\n",
    "    df.loc[df['Gender'] =='Male', 'labels'] = 0\n",
    "    df.loc[df['Gender'] == 'Female', 'labels'] = 1\n",
    "\n",
    "    labels = df.set_index('Participant_ID').to_dict()['labels']\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for filename, data in tqdm(audio_dict.items(), 'LABEL'):\n",
    "        ID = filename[:3]\n",
    "        dep = 0 if labels[ID]==0 else 1\n",
    "        [X.append(x) for x in data]\n",
    "        [Y.append(dep) for x in data]\n",
    "\n",
    "    X = tf.convert_to_tensor(X)\n",
    "    Y = tf.convert_to_tensor(Y)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "#Define F1 score as metric\n",
    "F1 = tfa.metrics.F1Score(1, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d98fe8b66454531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T23:16:36.881740Z",
     "start_time": "2024-07-13T23:16:36.877964Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CNN_LF(X_train,Y_train, X_test, Y_test, time, epochs, verbose=0, optimizer= 'adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(Resizing(128, 10 *time,input_shape=X_train[0].shape))\n",
    "    #model.add(Resizing(1, 1 *time,input_shape=X_train[0].shape))\n",
    "    model.add(Conv2D(30, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Conv2D(15, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.2)) #LF\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(units=512, activation=\"relu\"))\n",
    "    model.add(Dense(units=256, activation=\"relu\")) #LF\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\", 'Precision', 'Recall', F1], optimizer=optimizer)\n",
    "\n",
    "    #model.fit(X_train, Y_train, epochs=epochs, verbose=verbose,validation_data= [X_test, Y_test], shuffle=True ,callbacks = EarlyStopping(monitor='val_f1_score', patience=2, start_from_epoch=5, restore_best_weights=True, mode='max'))\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, verbose=verbose,validation_data= [X_test, Y_test], shuffle=True ,callbacks = EarlyStopping(monitor='val_f1_score', patience=2, restore_best_weights=True, mode='max'))\n",
    "\n",
    "    _,accuracy, prec, rec, f1 = model.evaluate(X_test, Y_test)\n",
    "\n",
    "    return accuracy, prec, rec, float(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82fa463ff62753f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T23:16:36.888682Z",
     "start_time": "2024-07-13T23:16:36.884257Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(directory, time, sample_rate):\n",
    "    #LOAD AUDIOS\n",
    "    audio_dict, original_samplerate = load_audios(directory)\n",
    "    #RESAMPLE AUDIOS\n",
    "    audio_dict, samplerate = resampling(audio_dict, original_samplerate, new_samplerate=sample_rate)\n",
    "    #FRAGMENT AUDIOS\n",
    "    audio_dictRAW, time = fragment_audio(audio_dict, samplerate, time=time)\n",
    "    #CONVERT TO MEL SPECTROGRAM\n",
    "    audio_dictMEL = MELspectrogram(audio_dictRAW, samplerate)\n",
    "    #RESHAPE FOR 2D CNN\n",
    "    X_train, Y_train, X_test, Y_test = train_test2(audio_dictMEL)\n",
    "\n",
    "    X_train = tf.reshape(X_train,shape = (-1,X_train.shape[1],X_train.shape[2],1))\n",
    "    X_test  = tf.reshape(X_test, shape = (-1,X_test.shape[1],X_test.shape[2],1))\n",
    "    #print(X.shape)\n",
    "\n",
    "    # X = tf.concat([X_train,X_test], axis=0)\n",
    "    # Y = tf.concat([Y_train,Y_test], axis=0)\n",
    "\n",
    "    #UNCOMMENT TO PLOT SPECTROGRAM\n",
    "    #plt.imshow(np.array(X[0]), interpolation='nearest')\n",
    "    #plt.show()\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebe440dcc4204e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### DEVICE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dd08331148da3b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-13T23:16:36.891305Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cb1df5193749aab18692eb2e9a970a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47a9786fb4b418c9f9c7e9d36bbd349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3a7f91c6a74e21be2c9e7b8c44f8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc310558ac54259a7d0e06b506877d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952ceb4d5b844ef1b0f80796e7e2c723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a5365c4e8f4b9ab662fcc51ba60436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f259fa88bdc48a1bd1b959cb4b73342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113373ede8d04c81bafe040950ac44c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN = SHURE SM-27  |   TEST = SHURE SM-27\n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.5971 - precision: 0.5971 - recall: 1.0000 - f1_score: 0.7478\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "TRAIN = SHURE SM-27  |   TEST = iPhoneSE2020\n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7525 - accuracy: 0.4029 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0000e+00\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "TRAIN = iPhoneSE2020  |   TEST = SHURE SM-27\n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.5721 - precision: 0.6054 - recall: 0.8141 - f1_score: 0.6944\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "TRAIN = iPhoneSE2020  |   TEST = iPhoneSE2020\n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.5416 - precision: 0.5862 - recall: 0.7901 - f1_score: 0.6731\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = [\"SHURE SM-27\", \"iPhoneSE2020\"]\n",
    "test_data = [\"SHURE SM-27\", \"iPhoneSE2020\"]\n",
    "time = 5\n",
    "sample_rate = None\n",
    "experiment_count = 1\n",
    "results_list = []  # This will be a list of dictionaries for easier DataFrame conversion\n",
    "\n",
    "highQuality = preprocess('./SM-27',time,sample_rate)\n",
    "lowQuality  = preprocess('./iPhoneSE2020',time,sample_rate)\n",
    "\n",
    "for train in training_data:\n",
    "    for test in test_data:\n",
    "        X_train, Y_train,_,_ = highQuality if train=='SHURE SM-27' else lowQuality\n",
    "        _,_,X_test,Y_test    = highQuality if test=='SHURE SM-27'     else lowQuality\n",
    "        print('TRAIN = ' + train + '  |   TEST = '+test+ '\\n\\n')\n",
    "    \n",
    "        for i in range(experiment_count):\n",
    "            accuracy, prec, rec, f1 = CNN_LF(X_train, Y_train, X_test, Y_test, time=time, epochs = 50)\n",
    "            # Create a single dictionary for each experiment\n",
    "            experiment_results = {\n",
    "                'Data': \"Train \"+ train+\" / Test: \"+test,\n",
    "                'Tests': 'Ex_' + str(i+1),\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': prec,\n",
    "                'Recall': rec,\n",
    "                'F1_Score': f1\n",
    "            }\n",
    "            results_list.append(experiment_results)\n",
    "        print('\\n---------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "results_MIC = pd.DataFrame(results_list)\n",
    "\n",
    "# Calculate the average of experiments for each training data group, ignoring non-numeric columns\n",
    "average_metrics_MIC = results_MIC.groupby('Data').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3de5c241c523ab8f",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Accuracy  Precision    Recall  \\\n",
      "Data                                                                     \n",
      "Train SHURE SM-27 / Test: SHURE SM-27    0.597135   0.597135  1.000000   \n",
      "Train SHURE SM-27 / Test: iPhoneSE2020   0.402865   0.000000  0.000000   \n",
      "Train iPhoneSE2020 / Test: SHURE SM-27   0.572068   0.605351  0.814093   \n",
      "Train iPhoneSE2020 / Test: iPhoneSE2020  0.541629   0.586207  0.790105   \n",
      "\n",
      "                                         F1_Score  \n",
      "Data                                               \n",
      "Train SHURE SM-27 / Test: SHURE SM-27    0.747758  \n",
      "Train SHURE SM-27 / Test: iPhoneSE2020   0.000000  \n",
      "Train iPhoneSE2020 / Test: SHURE SM-27   0.694373  \n",
      "Train iPhoneSE2020 / Test: iPhoneSE2020  0.673052  \n"
     ]
    }
   ],
   "source": [
    "print(average_metrics_MIC)\n",
    "results_MIC.to_csv('./results_MIC.csv')\n",
    "average_metrics_MIC.to_csv('./average_metrics_MIC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fad088c68027f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SAMPLE RATE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42e0ea5e72653083",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061e75c989a8444e8932c1986a76e84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f6acbe07404f99a30460e39b1a06aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RESAMPLING:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f20477da52498684a488ccecda9d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399b90c905e3472d9ad431ef51790e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (30) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb97719e39b4d3895cd4971f5b53c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE RATE =  2000 \n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.5953 - precision: 0.5964 - recall: 0.9970 - f1_score: 0.7464\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df8c032b32046e7a42c9a4a223d2760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a0c479a1c54a68842eff3961713854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RESAMPLING:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4a697682304cd58b961e505241a186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d9331dea1d499ca01fb6aaf48d89f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (59) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb7b6343d5a4a04a670b19ef4de6eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE RATE =  4000 \n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7640 - accuracy: 0.6007 - precision: 0.6005 - recall: 0.9895 - f1_score: 0.7475\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77a791a75734434b670a2091864ce76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33923227ec514bdc8b7797b803f29ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RESAMPLING:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ce850b996240408542a594a2106ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08c8be7915f48d0878cee1cc81864d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (117) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b169e463f159432599f89735df16724a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE RATE =  8000 \n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.5980 - precision: 0.5977 - recall: 1.0000 - f1_score: 0.7482\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3032ff41f4a485ca29378dc33f00d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f15801ccda478992a2dced2dd8f980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RESAMPLING:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e344c1a3c62c4eeeb282a2be1122cc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5095c8f5d9424ece8e6c54faf473eef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (233) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c368e68820c4a1286b85613af9538ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE RATE =  16000 \n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.6374 - precision: 0.6252 - recall: 0.9805 - f1_score: 0.7636\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e9671e2c95447fb31b70d1c2d321f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LOAD AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deb78aef3504609b33a8681ce7b4d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FRAGMENT AUDIOS:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd282a75c93848939b33b74dd746b661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MELSPECTROGRAM:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedf657be78746218055308edf8b7d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LABEL:   0%|          | 0/1674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE RATE =  44100 \n",
      "\n",
      "\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.6079 - precision: 0.6235 - recall: 0.8666 - f1_score: 0.7252\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = [\"SHURE SM-27\", \"iPhoneSE2020\"]\n",
    "test_data = [\"SHURE SM-27\", \"iPhoneSE2020\"]\n",
    "time = 5\n",
    "sample_rate = [2000, 4000, 8000, 16000, 44100]\n",
    "experiment_count = 1\n",
    "results_list = []  # This will be a list of dictionaries for easier DataFrame conversion\n",
    "\n",
    "for sr in sample_rate:\n",
    "    X_train, Y_train, X_test, Y_test = preprocess('./SM-27',time,sample_rate=sr)\n",
    "\n",
    "    print('SAMPLE RATE = ', sr, '\\n\\n')\n",
    "    for i in range(experiment_count):\n",
    "        accuracy, prec, rec, f1 = CNN_LF(X_train, Y_train, X_test, Y_test, time=time, epochs = 50)\n",
    "        # Create a single dictionary for each experiment\n",
    "        experiment_results = {\n",
    "            'Sample Rate': sr,\n",
    "            'Tests': 'Ex_' + str(i+1),\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1_Score': f1\n",
    "        }\n",
    "        results_list.append(experiment_results)\n",
    "    print('\\n---------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "results_SR = pd.DataFrame(results_list)\n",
    "\n",
    "# Calculate the average of experiments for each training data group, ignoring non-numeric columns\n",
    "average_metrics_SR = results_SR.groupby('Sample Rate').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d97483bd028a825b",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Accuracy  Precision    Recall  F1_Score\n",
      "Sample Rate                                         \n",
      "2000         0.595345   0.596413  0.997002  0.746352\n",
      "4000         0.600716   0.600546  0.989505  0.747452\n",
      "8000         0.598030   0.597670  1.000000  0.748177\n",
      "16000        0.637422   0.625239  0.980510  0.763573\n",
      "44100        0.607878   0.623517  0.866567  0.725220\n"
     ]
    }
   ],
   "source": [
    "print(average_metrics_SR)\n",
    "results_SR.to_csv('./results_SR.csv')\n",
    "average_metrics_SR.to_csv('./average_metrics_SR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba30a61f944dc8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### QUALITY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad21191290953",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "paths = ['44.1_24', '44.1_16', '16_16', 'MP3_320', 'MP3_96', 'OGG']\n",
    "time = 5\n",
    "sample_rate = None\n",
    "experiment_count = 1\n",
    "results_list = []  # This will be a list of dictionaries for easier DataFrame conversion\n",
    "\n",
    "for path in paths:\n",
    "    directory = '/Volumes/SESSIONS_2024 1/Quality_TEST/' + path\n",
    "    X_train, Y_train, X_test, Y_test = preprocess(directory,time,sample_rate)\n",
    "    print('DATA = ' + path+'\\n')\n",
    "    \n",
    "    for i in range(experiment_count):\n",
    "        accuracy, prec, rec, f1 = CNN_LF(X_train, Y_train, X_test, Y_test, time=time, epochs = 50)\n",
    "        # Create a single dictionary for each experiment\n",
    "        experiment_results = {\n",
    "            'Data': path,\n",
    "            'Tests': 'Ex_' + str(i+1),\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1_Score': f1\n",
    "        }\n",
    "        results_list.append(experiment_results)\n",
    "    print('\\n---------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "results_QUALITY = pd.DataFrame(results_list)\n",
    "\n",
    "# Calculate the average of experiments for each training data group, ignoring non-numeric columns\n",
    "average_metrics_QUALITY = results_QUALITY.groupby('Data').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb28c394d92d44c",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(average_metrics_QUALITY)\n",
    "results_QUALITY.to_csv('/Users/luisfebrenes/Desktop/Results/results_QUALITY.csv')\n",
    "average_metrics_QUALITY.to_csv('/Users/luisfebrenes/Desktop/Results/average_metrics_QUALITY.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
