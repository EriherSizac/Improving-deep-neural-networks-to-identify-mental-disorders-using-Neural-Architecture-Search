{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary encoding of Conv2D: 00000000\n",
      "Gray code encoding of Conv2D: 00000000\n",
      "Decoded Conv2D: {'type': 'Conv2D', 'filters': 32, 'kernel_size': (3, 3), 'strides': 1, 'padding': 'same', 'activation': 'relu'}\n",
      "Binary encoding of Dropout: 01101\n",
      "Gray code encoding of Dropout: 01011\n",
      "Decoded Dropout: {'type': 'Dropout', 'rate': 0.3}\n",
      "Binary encoding of Dense: 1000100\n",
      "Gray code encoding of Dense: 1100110\n",
      "Decoded Dense: {'type': 'Dense', 'units': 128, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "# Función para convertir binario a Gray code\n",
    "def binary_to_gray(binary_str):\n",
    "    return binary_str[0] + ''.join(str(int(binary_str[i-1]) ^ int(binary_str[i])) for i in range(1, len(binary_str)))\n",
    "\n",
    "# Función para convertir Gray code a binario\n",
    "def gray_to_binary(gray_str):\n",
    "    binary_str = gray_str[0]\n",
    "    for i in range(1, len(gray_str)):\n",
    "        binary_str += str(int(binary_str[i - 1]) ^ int(gray_str[i]))\n",
    "    return binary_str\n",
    "\n",
    "# Diccionarios para codificación/decodificación\n",
    "layer_type_options = {\n",
    "    'Conv2D': '000', \n",
    "    'BatchNorm': '001', \n",
    "    'MaxPooling': '010', \n",
    "    'Dropout': '011', \n",
    "    'Dense': '100', \n",
    "    'Flatten': '101',\n",
    "    'DepthwiseConv2D': '110',  # Nueva capa Depthwise Conv2D\n",
    "    'GlobalAveragePooling2D': '111'  # Nueva capa GlobalAveragePooling2D\n",
    "}\n",
    "filter_options = {32: '00', 30: '01', 16: '10', 8: '11'}\n",
    "stride_options = {1: '0', 2: '1'}\n",
    "dropout_options = {0.2: '00', 0.3: '01', 0.4: '10', 0.5: '11'}\n",
    "neuron_options = {256: '00', 128: '01', 32: '10', 1: '11'}\n",
    "activation_options = {'relu': '00', 'leaky_relu': '01', 'sigmoid': '10', 'tanh': '11'}\n",
    "\n",
    "# Función para codificar parámetros de las capas\n",
    "def encode_layer_params(layer_type, filters=None, strides=None, dropout=None, neurons=None, activation=None):\n",
    "    binary_representation = layer_type_options.get(layer_type, '000')\n",
    "    \n",
    "    if layer_type == 'Conv2D':\n",
    "        binary_representation += filter_options.get(filters, '00')\n",
    "        binary_representation += stride_options.get(strides, '0')\n",
    "        binary_representation += activation_options.get(activation, '00')\n",
    "    \n",
    "    if layer_type == 'DepthwiseConv2D':\n",
    "        filters_binary = filter_options.get(filters, '00')\n",
    "        strides_binary = stride_options.get(strides, '0')\n",
    "        activation_binary = activation_options.get(activation, '00')\n",
    "        return layer_type_options['DepthwiseConv2D'] + filters_binary + strides_binary + activation_binary\n",
    "    \n",
    "    elif layer_type == 'GlobalAveragePooling2D':\n",
    "        return layer_type_options['GlobalAveragePooling2D']\n",
    "    \n",
    "    elif layer_type == 'MaxPooling':\n",
    "        binary_representation += stride_options.get(strides, '0')\n",
    "    \n",
    "    elif layer_type == 'Dropout':\n",
    "        binary_representation += dropout_options.get(dropout, '00')\n",
    "    \n",
    "    elif layer_type == 'Dense':\n",
    "        binary_representation += neuron_options.get(neurons, '00')\n",
    "        binary_representation += activation_options.get(activation, '00')\n",
    "    \n",
    "    return binary_representation\n",
    "\n",
    "# Función para decodificar parámetros de las capas\n",
    "def decode_layer_params(encoded_gray):\n",
    "    encoded_binary = gray_to_binary(encoded_gray)\n",
    "    layer_type = encoded_binary[:3]\n",
    "    \n",
    "    if layer_type == '000':  # Conv2D\n",
    "        return {\n",
    "            'type': 'Conv2D',\n",
    "            'filters': decode_value(encoded_binary[3:5], filter_options, 32),\n",
    "            'kernel_size': (3, 3),\n",
    "            'strides': decode_value(encoded_binary[5], stride_options, 1),\n",
    "            'padding': 'same',\n",
    "            'activation': decode_value(encoded_binary[6:8], activation_options, 'relu')\n",
    "        }\n",
    "    \n",
    "    elif layer_type == '001':  # BatchNorm\n",
    "        return {'type': 'BatchNorm'}\n",
    "    \n",
    "    elif layer_type == '010':  # MaxPooling\n",
    "        return {'type': 'MaxPooling', 'strides': decode_value(encoded_binary[3], stride_options, 1)}\n",
    "    \n",
    "    elif layer_type == '011':  # Dropout\n",
    "        return {'type': 'Dropout', 'rate': decode_value(encoded_binary[3:5], dropout_options, 0.2)}\n",
    "    \n",
    "    elif layer_type == '100':  # Dense\n",
    "        # Corregir la decodificación de 'units'\n",
    "        return {\n",
    "            'type': 'Dense',\n",
    "            'units': decode_value(encoded_binary[3:5], neuron_options, 256),  # Ajustamos para corregir 'units'\n",
    "            'activation': decode_value(encoded_binary[5:7], activation_options, 'relu')\n",
    "        }\n",
    "    \n",
    "    elif layer_type == '101':  # Flatten\n",
    "        return {'type': 'Flatten'}\n",
    "    \n",
    "    elif layer_type == '110':  # DepthwiseConv2D (nueva capa)\n",
    "        return {\n",
    "            'type': 'DepthwiseConv2D',\n",
    "            'filters': decode_value(encoded_binary[3:5], filter_options, 32),  # Reutilizamos los filtros\n",
    "            'kernel_size': (3, 3),  # Valor constante\n",
    "            'strides': decode_value(encoded_binary[5], stride_options, 1),\n",
    "            'padding': 'same',  # Valor constante\n",
    "            'activation': decode_value(encoded_binary[6:8], activation_options, 'relu')\n",
    "        }\n",
    "    \n",
    "    elif layer_type == '111':  # GlobalAveragePooling2D (nueva capa)\n",
    "        return {'type': 'GlobalAveragePooling2D'}\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Tipo de capa desconocido.\")\n",
    "# Función auxiliar para decodificar valores de las opciones\n",
    "def decode_value(bits, options_dict, default_value):\n",
    "    return {v: k for k, v in options_dict.items()}.get(bits, default_value)\n",
    "\n",
    "# Ejemplo de uso optimizado\n",
    "binary_conv2d = encode_layer_params('Conv2D', filters=32, strides=1, activation='relu')\n",
    "gray_conv2d = binary_to_gray(binary_conv2d)\n",
    "decoded_conv2d = decode_layer_params(gray_conv2d)\n",
    "print(f\"Binary encoding of Conv2D: {binary_conv2d}\")\n",
    "print(f\"Gray code encoding of Conv2D: {gray_conv2d}\")\n",
    "print(f\"Decoded Conv2D: {decoded_conv2d}\")\n",
    "\n",
    "binary_dropout = encode_layer_params('Dropout', dropout=0.3)\n",
    "gray_dropout = binary_to_gray(binary_dropout)\n",
    "decoded_dropout = decode_layer_params(gray_dropout)\n",
    "print(f\"Binary encoding of Dropout: {binary_dropout}\")\n",
    "print(f\"Gray code encoding of Dropout: {gray_dropout}\")\n",
    "print(f\"Decoded Dropout: {decoded_dropout}\")\n",
    "\n",
    "binary_dense = encode_layer_params('Dense', neurons=128, activation='relu')\n",
    "gray_dense = binary_to_gray(binary_dense)\n",
    "decoded_dense = decode_layer_params(gray_dense)\n",
    "print(f\"Binary encoding of Dense: {binary_dense}\")\n",
    "print(f\"Gray code encoding of Dense: {gray_dense}\")\n",
    "print(f\"Decoded Dense: {decoded_dense}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Encoding of Building Blocks for Neural Network Architectures\n",
    "\n",
    "This module implements the **binary encoding** of various building blocks that make up the architecture of a neural network. Each building block (layers like Conv2D, MaxPooling, Dense, etc.) is represented in binary format based on its key parameters (number of filters, kernel size, number of neurons, activations, etc.). This encoding is useful for optimization processes like **NSGA-III** and later conversion to **Gray code**.\n",
    "\n",
    "### Function `encode_layer_params`\n",
    "\n",
    "This function generates the binary representation of the parameters of a given layer, depending on the type of layer and its specific parameters.\n",
    "\n",
    "### Function Parameters\n",
    "\n",
    "- `layer_type`: (str) The type of layer. It can be one of the following:\n",
    "  - `Conv2D`\n",
    "  - `BatchNorm`\n",
    "  - `MaxPooling`\n",
    "  - `Dropout`\n",
    "  - `Dense`\n",
    "  - `Flatten`\n",
    "  \n",
    "- `filters`: (int) [Optional] Number of filters for `Conv2D` layers. Valid options: `32`, `30`, `16`, `8`.\n",
    "\n",
    "- `kernel_size`: (tuple) [Optional] Kernel size for `Conv2D`. Currently, only `(3, 3)` is supported.\n",
    "\n",
    "- `strides`: (int) [Optional] Stride used in `Conv2D` or `MaxPooling`. Valid options: `1` and `2`.\n",
    "\n",
    "- `padding`: (str) [Optional] Padding type in `Conv2D`. Currently, only `'same'` is supported.\n",
    "\n",
    "- `dropout`: (float) [Optional] Dropout rate for `Dropout` layers. Valid options: `0.2`, `0.3`, `0.5`.\n",
    "\n",
    "- `neurons`: (int) [Optional] Number of neurons in `Dense` layers. Valid options: `256`, `128`, `32`.\n",
    "\n",
    "- `activation`: (str) [Optional] Activation function for `Conv2D` or `Dense` layers. Valid options: `'ReLU'`, `'LeakyReLU'`, `'Sigmoid'`.\n",
    "\n",
    "### Return\n",
    "\n",
    "- `binary_representation`: (str) A string of bits representing the layer parameters in binary format.\n",
    "\n",
    "## Layer Type Encoding\n",
    "\n",
    "Each layer type is represented by a specific sequence of bits. The layer types and their corresponding encodings are:\n",
    "\n",
    "- **Conv2D**: `'000'`\n",
    "- **BatchNorm**: `'001'`\n",
    "- **MaxPooling**: `'010'`\n",
    "- **Dropout**: `'011'`\n",
    "- **Dense**: `'100'`\n",
    "- **Flatten**: `'101'`\n",
    "\n",
    "## Parameters Encoded by Layer Type\n",
    "\n",
    "### Conv2D\n",
    "The `Conv2D` layer includes the following encoded parameters:\n",
    "\n",
    "- **Number of filters**:\n",
    "  - `32`: `'00'`\n",
    "  - `30`: `'01'`\n",
    "  - `16`: `'10'`\n",
    "  - `8`: `'11'`\n",
    "\n",
    "- **Kernel size**:\n",
    "  - `(3, 3)`: `'0'` (only this size is supported for now)\n",
    "\n",
    "- **Stride**:\n",
    "  - `1`: `'0'`\n",
    "  - `2`: `'1'`\n",
    "\n",
    "- **Padding**:\n",
    "  - `'same'`: `'0'`\n",
    "\n",
    "- **Activation function**:\n",
    "  - `ReLU`: `'00'`\n",
    "  - `LeakyReLU`: `'01'`\n",
    "\n",
    "### BatchNorm\n",
    "The `BatchNorm` layer has no additional parameters, only its layer type encoding (`'001'`).\n",
    "\n",
    "### MaxPooling\n",
    "The `MaxPooling` layer has a single encoded parameter:\n",
    "\n",
    "- **Stride**:\n",
    "  - `1`: `'0'`\n",
    "  - `2`: `'1'`\n",
    "\n",
    "### Dropout\n",
    "The `Dropout` layer has the following encoded dropout rates:\n",
    "\n",
    "- **Dropout Rate**:\n",
    "  - `0.2`: `'00'`\n",
    "  - `0.3`: `'01'`\n",
    "  - `0.5`: `'10'`\n",
    "\n",
    "### Dense\n",
    "The `Dense` layer has the following encoded parameters:\n",
    "\n",
    "- **Number of neurons**:\n",
    "  - `256`: `'00'`\n",
    "  - `128`: `'01'`\n",
    "  - `32`: `'10'`\n",
    "\n",
    "- **Activation function**:\n",
    "  - `ReLU`: `'00'`\n",
    "  - `LeakyReLU`: `'01'`\n",
    "  - `Sigmoid`: `'10'`\n",
    "\n",
    "### Flatten\n",
    "The `Flatten` layer has no additional parameters, only its layer type encoding (`'101'`).\n",
    "\n",
    "## Gray Code Conversion\n",
    "\n",
    "In addition to binary encoding, this module supports **Gray code** conversion for efficient optimization, where only one bit changes between consecutive values.\n",
    "\n",
    "### Function `binary_to_gray`\n",
    "\n",
    "This function converts a binary string to Gray code using the following logic:\n",
    "- The first bit in Gray code is the same as the first bit in binary.\n",
    "- For each subsequent bit, the Gray code bit is the XOR of the current binary bit and the previous binary bit.\n",
    "\n",
    "### Function Parameters\n",
    "\n",
    "- `binary_str`: (str) A string representing a binary number.\n",
    "\n",
    "### Return\n",
    "\n",
    "- `gray_str`: (str) A string representing the corresponding Gray code.\n",
    "\n",
    "### Function `gray_to_binary`\n",
    "\n",
    "This function converts a Gray code string back to its binary equivalent using the following logic:\n",
    "- The first bit of the binary string is the same as the first bit of the Gray code.\n",
    "- For each subsequent bit, the binary bit is the XOR of the previous binary bit and the current Gray code bit.\n",
    "\n",
    "### Function Parameters\n",
    "\n",
    "- `gray_str`: (str) A string representing a Gray code number.\n",
    "\n",
    "### Return\n",
    "\n",
    "- `binary_str`: (str) A string representing the corresponding binary number.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Encoding: 0000000000101011011000000011111001110\n",
      "Gray Code Encoding: 0000000000101111111100000010001101001\n",
      "Modelo original y decodificado son iguales.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Función para eliminar campos adicionales como 'padding' y 'kernel_size'\n",
    "def clean_decoded_model(model_dict):\n",
    "    # Recorrer cada capa del modelo decodificado\n",
    "    for layer in model_dict['layers']:\n",
    "        # Remover 'kernel_size' y 'padding' si están presentes\n",
    "        if 'kernel_size' in layer:\n",
    "            del layer['kernel_size']\n",
    "        if 'padding' in layer:\n",
    "            del layer['padding']\n",
    "    return model_dict\n",
    "\n",
    "# Función para decodificar la arquitectura del modelo a partir de Gray code\n",
    "def decode_model_architecture(encoded_string_gray):\n",
    "    model_dict = {'layers': []}\n",
    "    index = 0\n",
    "    \n",
    "    while index < len(encoded_string_gray):\n",
    "        # Extraer el resto del Gray code\n",
    "        remaining_gray_code = encoded_string_gray[index:]\n",
    "        \n",
    "        # Decodificar una capa completa usando decode_layer_params\n",
    "        decoded_layer = decode_layer_params(remaining_gray_code)\n",
    "        \n",
    "        # Agregar la capa decodificada al modelo\n",
    "        model_dict['layers'].append(decoded_layer)\n",
    "        \n",
    "        # Obtener los parámetros relevantes de la capa (sin 'type')\n",
    "        layer_type = decoded_layer['type']\n",
    "        layer_params = {\n",
    "            'filters': decoded_layer.get('filters'),\n",
    "            'strides': decoded_layer.get('strides'),\n",
    "            'dropout': decoded_layer.get('rate'),\n",
    "            'neurons': decoded_layer.get('units'),\n",
    "            'activation': decoded_layer.get('activation')\n",
    "        }\n",
    "        \n",
    "        # Obtener la longitud de la codificación binaria para esta capa\n",
    "        binary_code_for_layer = encode_layer_params(layer_type, **layer_params)\n",
    "        gray_code_for_layer = binary_to_gray(binary_code_for_layer)\n",
    "        \n",
    "        # Avanzar el índice según la longitud de la capa decodificada\n",
    "        index += len(gray_code_for_layer)\n",
    "    \n",
    "    return model_dict\n",
    "\n",
    "# Función para codificar la arquitectura del modelo a Gray code\n",
    "def encode_model_architecture(model_dict):\n",
    "    encoded_layers_bin = []\n",
    "    encoded_layers_gray = []\n",
    "    \n",
    "    # Codificar cada capa individualmente\n",
    "    for layer in model_dict['layers']:\n",
    "        binary_encoding = encode_layer_params(\n",
    "            layer_type=layer['type'],\n",
    "            filters=layer.get('filters'),\n",
    "            strides=layer.get('strides'),\n",
    "            dropout=layer.get('rate'),\n",
    "            neurons=layer.get('units'),\n",
    "            activation=layer.get('activation', '').lower()\n",
    "        )\n",
    "        encoded_layers_bin.append(binary_encoding)\n",
    "        \n",
    "        # Convertir a Gray code\n",
    "        gray_encoding = binary_to_gray(binary_encoding)\n",
    "        encoded_layers_gray.append(gray_encoding)\n",
    "    \n",
    "    # Concatenar todas las codificaciones en una sola cadena\n",
    "    final_encoding_bin = ''.join(encoded_layers_bin)\n",
    "    final_encoding_gray = ''.join(encoded_layers_gray)\n",
    "    \n",
    "    print(f\"Binary Encoding: {final_encoding_bin}\")\n",
    "    print(f\"Gray Code Encoding: {final_encoding_gray}\")\n",
    "    \n",
    "    return final_encoding_gray\n",
    "\n",
    "# Función de verificación\n",
    "def verify_model_architecture(original_model):\n",
    "    # Codificar el modelo original\n",
    "    encoded_model = encode_model_architecture(original_model)\n",
    "    \n",
    "    # Decodificar el modelo desde el Gray code\n",
    "    decoded_model = decode_model_architecture(encoded_model)\n",
    "    \n",
    "    # Limpiar el modelo decodificado para quitar 'kernel_size' y 'padding'\n",
    "    decoded_model_cleaned = clean_decoded_model(decoded_model)\n",
    "    \n",
    "    # Verificar si el modelo original y decodificado son iguales\n",
    "    if original_model == decoded_model_cleaned:\n",
    "        print(\"Modelo original y decodificado son iguales.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Original Model:\")\n",
    "        print(original_model)\n",
    "        print(\"\\nDecoded Model (cleaned):\")\n",
    "        print(decoded_model_cleaned)\n",
    "        return False\n",
    "\n",
    "# Ejemplo de uso\n",
    "model_example = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Verificar el modelo\n",
    "print(verify_model_architecture(model_example))\n",
    "\n",
    "# Construcción del modelo en TensorFlow desde el diccionario decodificado\n",
    "# Construcción del modelo en TensorFlow desde el diccionario decodificado\n",
    "def build_tf_model_from_dict(model_dict):\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Conv2D':\n",
    "            model.add(Conv2D(filters=layer['filters'], kernel_size=(3, 3), strides=layer['strides'], padding='same', activation=layer['activation']))\n",
    "        elif layer['type'] == 'BatchNorm':\n",
    "            model.add(BatchNormalization())\n",
    "        elif layer['type'] == 'MaxPooling':\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=layer['strides'], padding='same'))\n",
    "        elif layer['type'] == 'Flatten':\n",
    "            model.add(Flatten())\n",
    "        elif layer['type'] == 'Dense':\n",
    "            model.add(Dense(units=layer['units'], activation=layer['activation']))\n",
    "        elif layer['type'] == 'Dropout':\n",
    "            model.add(Dropout(rate=layer['rate']))\n",
    "    \n",
    "    # Aquí defines el tamaño de entrada para que el modelo se construya\n",
    "    model.build(input_shape=(None, 28, 28, 3))  # Ajusta esto al tamaño de tu entrada\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: build_CNN_LF_model\n",
    "model_CNN_LF = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 30, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},  # Revisar 'filters'\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.3},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 2: build_reduced_model\n",
    "model_reduced = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 3: build_Spectro_CNN_model\n",
    "model_spectro_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 4: Simple Conv2D model\n",
    "model_simple_conv = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 10, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 5: Simple Dense model\n",
    "model_dense_only = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 6: Small CNN model with Dropout\n",
    "model_small_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 7: Deep CNN model\n",
    "model_deep_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 10, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 8: Basic Dense with Dropout\n",
    "model_dense_dropout = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "model_with_depthwise = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"DepthwiseConv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"sigmoid\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "model_with_global_avg_pooling = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"GlobalAveragePooling2D\"},\n",
    "        {\"type\": \"Dense\", \"units\": 64, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionarios para la codificación/decodificación\n",
    "layer_type_options = {\n",
    "    'Conv2D': '000', 'BatchNorm': '001', 'MaxPooling': '010', \n",
    "    'Dropout': '011', 'Dense': '100', 'Flatten': '101'\n",
    "}\n",
    "filter_options = {32: '00', 30: '01', 16: '10', 8: '11'}\n",
    "stride_options = {1: '0', 2: '1'}\n",
    "dropout_options = {0.2: '00', 0.3: '01', 0.4: '10', 0.5: '11'}\n",
    "neuron_options = {256: '00', 128: '01', 32: '10', 1: '11'}\n",
    "activation_options = {'relu': '00', 'leaky_relu': '01', 'sigmoid': '10', 'tanh': '11'}\n",
    "\n",
    "# Función para validar si los valores del modelo son válidos\n",
    "def validate_model_layers(model):\n",
    "    for layer in model['layers']:\n",
    "        layer_type = layer['type']\n",
    "        \n",
    "        if layer_type == 'Conv2D':\n",
    "            filters = layer.get('filters')\n",
    "            strides = layer.get('strides')\n",
    "            activation = layer.get('activation')\n",
    "\n",
    "            if filters not in filter_options:\n",
    "                print(f\"Invalid filters value in Conv2D layer: {filters}\")\n",
    "                return False\n",
    "            if strides not in stride_options:\n",
    "                print(f\"Invalid strides value in Conv2D layer: {strides}\")\n",
    "                return False\n",
    "            if activation not in activation_options:\n",
    "                print(f\"Invalid activation value in Conv2D layer: {activation}\")\n",
    "                return False\n",
    "        \n",
    "        elif layer_type == 'Dense':\n",
    "            units = layer.get('units')\n",
    "            activation = layer.get('activation')\n",
    "\n",
    "            if units not in neuron_options:\n",
    "                print(f\"Invalid units value in Dense layer: {units}\")\n",
    "                return False\n",
    "            if activation not in activation_options:\n",
    "                print(f\"Invalid activation value in Dense layer: {activation}\")\n",
    "                return False\n",
    "\n",
    "        elif layer_type == 'Dropout':\n",
    "            rate = layer.get('rate')\n",
    "            if rate not in dropout_options:\n",
    "                print(f\"Invalid dropout rate value: {rate}\")\n",
    "                return False\n",
    "        \n",
    "        elif layer_type == 'MaxPooling':\n",
    "            strides = layer.get('strides')\n",
    "            if strides not in stride_options:\n",
    "                print(f\"Invalid strides value in MaxPooling layer: {strides}\")\n",
    "                return False\n",
    "        \n",
    "        elif layer_type == 'Flatten':\n",
    "            # No se necesitan validaciones adicionales para Flatten\n",
    "            pass\n",
    "\n",
    "        elif layer_type == 'BatchNorm':\n",
    "            # No se necesitan validaciones adicionales para BatchNorm\n",
    "            pass\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# Función para verificar y construir el modelo\n",
    "def run_verification_and_build(model):\n",
    "    if validate_model_layers(model):\n",
    "        print(\"Model is valid. Running verification and building the model:\")\n",
    "        # Verificación del modelo\n",
    "        if verify_model_architecture(model):\n",
    "            print(\"Model verification passed.\")\n",
    "        else:\n",
    "            print(\"Model verification failed.\")\n",
    "        \n",
    "        # Construcción del modelo en TensorFlow desde el diccionario decodificado\n",
    "        decoded_model_dict = decode_model_architecture(encode_model_architecture(model))\n",
    "        tf_model = build_tf_model_from_dict(decoded_model_dict)\n",
    "\n",
    "        # Mostrar la estructura del modelo de TensorFlow\n",
    "        try:\n",
    "            tf_model.summary()\n",
    "        except Exception as e:\n",
    "            print(f\"Error building model: {e}\")\n",
    "    else:\n",
    "        print(\"Model is invalid. Skipping verification and build.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifications:\n",
      "\n",
      "Model 1: CNN_LF\n",
      "Model is valid. Running verification and building the model:\n",
      "Binary Encoding: 00001000011000010101000100000110000101011011000000011011001110\n",
      "Gray Code Encoding: 00001100010100010111000110000101000101111111100000010111101001\n",
      "Modelo original y decodificado son iguales.\n",
      "Model verification passed.\n",
      "Binary Encoding: 00001000011000010101000100000110000101011011000000011011001110\n",
      "Gray Code Encoding: 00001100010100010111000110000101000101111111100000010111101001\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 28, 28, 30)        840       \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 28, 28, 30)        0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 28, 28, 30)       120       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 30)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 14, 14, 16)        4336      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 14, 14, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 7, 7, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206,577\n",
      "Trainable params: 206,485\n",
      "Non-trainable params: 92\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 2: Reduced\n",
      "Model is valid. Running verification and building the model:\n",
      "Binary Encoding: 001000100010010001100100110110010011001110\n",
      "Gray Code Encoding: 001000110010010001010100111111011011101001\n",
      "Modelo original y decodificado son iguales.\n",
      "Model verification passed.\n",
      "Binary Encoding: 001000100010010001100100110110010011001110\n",
      "Gray Code Encoding: 001000110010010001010100111111011011101001\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_30 (Bat  (None, 28, 28, 3)        12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 28, 28, 16)        448       \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 28, 28, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 28, 28, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 28, 28, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 32)                200736    \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,485\n",
      "Trainable params: 202,431\n",
      "Non-trainable params: 54\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 3: Spectro CNN\n",
      "Model is valid. Running verification and building the model:\n",
      "Binary Encoding: 000000010010101000000010011011000000011111000100011111001110\n",
      "Gray Code Encoding: 000000010010111000000010011111100000010001100110010001101001\n",
      "Modelo original y decodificado son iguales.\n",
      "Model verification passed.\n",
      "Binary Encoding: 000000010010101000000010011011000000011111000100011111001110\n",
      "Gray Code Encoding: 000000010010111000000010011111100000010001100110010001101001\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 14, 14, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 256)               1605888   \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,649,313\n",
      "Trainable params: 1,649,185\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 4: Simple Conv2D\n",
      "Invalid units value in Dense layer: 10\n",
      "Model is invalid. Skipping verification and build.\n",
      "\n",
      "Model 5: Dense Only\n",
      "Model is valid. Running verification and building the model:\n",
      "Binary Encoding: 101100000010001001000010\n",
      "Gray Code Encoding: 111110000011001101100011\n",
      "Modelo original y decodificado son iguales.\n",
      "Model verification passed.\n",
      "Binary Encoding: 101100000010001001000010\n",
      "Gray Code Encoding: 111110000011001101100011\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_27 (Flatten)        (None, 2352)              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 256)               602368    \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,288\n",
      "Trainable params: 668,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 6: Small CNN\n",
      "Model is valid. Running verification and building the model:\n",
      "Binary Encoding: 0001100001100010110110010001001110\n",
      "Gray Code Encoding: 0001010001010011111111011001101001\n",
      "Modelo original y decodificado son iguales.\n",
      "Model verification passed.\n",
      "Binary Encoding: 0001100001100010110110010001001110\n",
      "Gray Code Encoding: 0001010001010011111111011001101001\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 28, 28, 8)         224       \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 28, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 14, 14, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 32)                50208     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,465\n",
      "Trainable params: 50,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model 7: Deep CNN\n",
      "Invalid units value in Dense layer: 10\n",
      "Model is invalid. Skipping verification and build.\n",
      "\n",
      "Model 8: Dense with Dropout\n",
      "Model is valid. Running verification and building the model:\n",
      "Binary Encoding: 1011000100011111001011\n",
      "Gray Code Encoding: 1111100110010001101110\n",
      "Modelo original y decodificado son iguales.\n",
      "Model verification passed.\n",
      "Binary Encoding: 1011000100011111001011\n",
      "Gray Code Encoding: 1111100110010001101110\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_29 (Flatten)        (None, 2352)              0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 128)               301184    \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,312\n",
      "Trainable params: 305,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Model with DepthwiseConv2D\n",
      "Model is valid. Running verification and building the model:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'DepthwiseConv2D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m run_verification_and_build(model_dense_dropout)  \u001b[38;5;66;03m# Ejemplo 8\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel with DepthwiseConv2D\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mrun_verification_and_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_with_depthwise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel with GlobalAveragePooling2D\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m run_verification_and_build(model_with_global_avg_pooling)\n",
      "Cell \u001b[1;32mIn[21], line 71\u001b[0m, in \u001b[0;36mrun_verification_and_build\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is valid. Running verification and building the model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Verificación del modelo\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mverify_model_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel verification passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[19], line 79\u001b[0m, in \u001b[0;36mverify_model_architecture\u001b[1;34m(original_model)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_model_architecture\u001b[39m(original_model):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# Codificar el modelo original\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     encoded_model \u001b[38;5;241m=\u001b[39m \u001b[43mencode_model_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# Decodificar el modelo desde el Gray code\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     decoded_model \u001b[38;5;241m=\u001b[39m decode_model_architecture(encoded_model)\n",
      "Cell \u001b[1;32mIn[19], line 53\u001b[0m, in \u001b[0;36mencode_model_architecture\u001b[1;34m(model_dict)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Codificar cada capa individualmente\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 53\u001b[0m     binary_encoding \u001b[38;5;241m=\u001b[39m \u001b[43mencode_layer_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     encoded_layers_bin\u001b[38;5;241m.\u001b[39mappend(binary_encoding)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Convertir a Gray code\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 41\u001b[0m, in \u001b[0;36mencode_layer_params\u001b[1;34m(layer_type, filters, strides, dropout, neurons, activation)\u001b[0m\n\u001b[0;32m     39\u001b[0m     strides_binary \u001b[38;5;241m=\u001b[39m stride_options\u001b[38;5;241m.\u001b[39mget(strides, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m     activation_binary \u001b[38;5;241m=\u001b[39m activation_options\u001b[38;5;241m.\u001b[39mget(activation, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlayer_type_options\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDepthwiseConv2D\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m filters_binary \u001b[38;5;241m+\u001b[39m strides_binary \u001b[38;5;241m+\u001b[39m activation_binary\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobalAveragePooling2D\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_type_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobalAveragePooling2D\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DepthwiseConv2D'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verificación de los modelos\n",
    "print(\"Verifications:\")\n",
    "\n",
    "print(\"\\nModel 1: CNN_LF\")\n",
    "run_verification_and_build(model_CNN_LF)  # Ejemplo 1\n",
    "\n",
    "print(\"\\nModel 2: Reduced\")\n",
    "run_verification_and_build(model_reduced)  # Ejemplo 2\n",
    "\n",
    "print(\"\\nModel 3: Spectro CNN\")\n",
    "run_verification_and_build(model_spectro_CNN)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 4: Simple Conv2D\")\n",
    "run_verification_and_build(model_simple_conv)  # Ejemplo 4\n",
    "\n",
    "print(\"\\nModel 5: Dense Only\")\n",
    "run_verification_and_build(model_dense_only)  # Ejemplo 5\n",
    "\n",
    "print(\"\\nModel 6: Small CNN\")\n",
    "run_verification_and_build(model_small_CNN)  # Ejemplo 6\n",
    "\n",
    "print(\"\\nModel 7: Deep CNN\")\n",
    "run_verification_and_build(model_deep_CNN)  # Ejemplo 7\n",
    "\n",
    "print(\"\\nModel 8: Dense with Dropout\")\n",
    "run_verification_and_build(model_dense_dropout)  # Ejemplo 8\n",
    "\n",
    "print(\"\\nModel with DepthwiseConv2D\")\n",
    "run_verification_and_build(model_with_depthwise)\n",
    "\n",
    "print(\"\\nModel with GlobalAveragePooling2D\")\n",
    "run_verification_and_build(model_with_global_avg_pooling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
