{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout, DepthwiseConv2D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary encoding of Conv2D: 000000000\n",
      "Decoded Conv2D: {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}\n",
      "\n",
      "Binary encoding of Dropout: 001101000\n",
      "Decoded Dropout: {'type': 'Dropout', 'rate': 0.3}\n",
      "\n",
      "Binary encoding of Dense: 010001000\n",
      "Decoded Dense: {'type': 'Dense', 'units': 128, 'activation': 'relu'}\n",
      "\n",
      "Binary encoding of Repetition: 101000111\n",
      "Decoded Repetition: {'type': 'Repetition', 'repetition_layers': 3, 'repetition_count': 5}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para convertir binario a Gray code\n",
    "def binary_to_gray(binary_str):\n",
    "    return binary_str[0] + ''.join(str(int(binary_str[i-1]) ^ int(binary_str[i])) for i in range(1, len(binary_str)))\n",
    "\n",
    "# Función para convertir Gray code a binario\n",
    "def gray_to_binary(gray_str):\n",
    "    binary_str = gray_str[0]\n",
    "    for i in range(1, len(gray_str)):\n",
    "        binary_str += str(int(binary_str[i - 1]) ^ int(gray_str[i]))\n",
    "    return binary_str\n",
    "\n",
    "# Diccionarios para codificación/decodificación\n",
    "layer_type_options = {\n",
    "    'Conv2D': '0000', \n",
    "    'BatchNorm': '0001', \n",
    "    'MaxPooling': '0010', \n",
    "    'Dropout': '0011', \n",
    "    'Dense': '0100', \n",
    "    'Flatten': '0101',\n",
    "    'DepthwiseConv2D': '0110',  # Mantenemos DepthwiseConv2D\n",
    "    'DontCare': '0111',  # Capa \"don't care\"\n",
    "    'Repetition': '1***'  # Capa \"Repetition\"\n",
    "}\n",
    "filter_options = {32: '00', 30: '01', 16: '10', 8: '11'}\n",
    "stride_options = {1: '0', 2: '1'}\n",
    "dropout_options = {0.2: '00', 0.3: '01', 0.4: '10', 0.5: '11'}\n",
    "neuron_options = {256: '00', 128: '01', 32: '10', 1: '11'}\n",
    "activation_options = {'relu': '00', 'leaky_relu': '01', 'sigmoid': '10', 'tanh': '11'}\n",
    "\n",
    "def encode_layer_params(layer_type, filters=None, strides=None, dropout=None, neurons=None, activation=None, repetition_layers=None, repetition_count=None):\n",
    "    # Si es una capa de repetición\n",
    "    if repetition_layers is not None and repetition_count is not None:\n",
    "        repetition_layers_gray = binary_to_gray(f'{repetition_layers:03b}')  # 3 bits en Gray Code\n",
    "        repetition_count_gray = binary_to_gray(f'{repetition_count:05b}')    # 5 bits en Gray Code\n",
    "        binary_representation = '1' + repetition_layers_gray + repetition_count_gray\n",
    "        return binary_representation\n",
    "\n",
    "    # Capa normal\n",
    "    binary_representation = layer_type_options.get(layer_type, '0000')\n",
    "    \n",
    "    if layer_type == 'Conv2D':\n",
    "        binary_representation += filter_options.get(filters, '00')\n",
    "        binary_representation += stride_options.get(strides, '0')\n",
    "        binary_representation += activation_options.get(activation, '00')\n",
    "    \n",
    "    elif layer_type == 'DepthwiseConv2D':\n",
    "        binary_representation += filter_options.get(filters, '00')\n",
    "        binary_representation += stride_options.get(strides, '0')\n",
    "        binary_representation += activation_options.get(activation, '00')\n",
    "\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        binary_representation += stride_options.get(strides, '0')\n",
    "    \n",
    "    elif layer_type == 'Dropout':\n",
    "        binary_representation += dropout_options.get(dropout, '00')\n",
    "    \n",
    "    elif layer_type == 'Dense':\n",
    "        binary_representation += neuron_options.get(neurons, '00')\n",
    "        binary_representation += activation_options.get(activation, '00')\n",
    "    \n",
    "    elif layer_type == 'BatchNorm':\n",
    "        # BatchNorm no tiene parámetros adicionales\n",
    "        binary_representation += '0000'  # Sin parámetros adicionales\n",
    "\n",
    "    elif layer_type == 'Flatten':\n",
    "        # Flatten no tiene parámetros adicionales\n",
    "        binary_representation += '0000'  # Sin parámetros adicionales\n",
    "\n",
    "    # Si no es una capa que requiere muchos parámetros, rellenamos a 9 bits\n",
    "    binary_representation = binary_representation.ljust(9, '0')  # Asegurarse de llenar hasta 9 bits\n",
    "    return binary_representation\n",
    "\n",
    "\n",
    "# Función para decodificar parámetros de las capas\n",
    "def decode_layer_params(encoded_binary):\n",
    "    if len(encoded_binary) < 9:  # Ahora verificamos si el string tiene al menos 9 bits\n",
    "        print(f\"Error: The encoded layer binary {encoded_binary} is too short!\")\n",
    "        return {'type': 'DontCare'}  # Usar una capa \"DontCare\" como valor por defecto\n",
    "    \n",
    "    if encoded_binary[0] == '1':  # Es una capa de repetición\n",
    "        repetition_layers = gray_to_binary(encoded_binary[1:4])\n",
    "        repetition_count = gray_to_binary(encoded_binary[4:])\n",
    "        return {\n",
    "            'type': 'Repetition',\n",
    "            'repetition_layers': int(repetition_layers, 2),\n",
    "            'repetition_count': int(repetition_count, 2)\n",
    "        }\n",
    "    \n",
    "    # Si no es repetición, procesamos normalmente\n",
    "    layer_type = encoded_binary[1:4]\n",
    "    \n",
    "    if layer_type == '000':  # Conv2D\n",
    "        filters = decode_value(encoded_binary[4:6], filter_options, 32)\n",
    "        strides = decode_value(encoded_binary[6], stride_options, 1)\n",
    "        activation = decode_value(encoded_binary[7:], activation_options, 'relu')\n",
    "        return {\n",
    "            'type': 'Conv2D',\n",
    "            'filters': filters,\n",
    "            'strides': strides,\n",
    "            'activation': activation\n",
    "        }\n",
    "    elif layer_type == '001':  # BatchNorm\n",
    "        return {'type': 'BatchNorm'}\n",
    "    \n",
    "    elif layer_type == '010':  # MaxPooling\n",
    "        strides = decode_value(encoded_binary[4], stride_options, 1)\n",
    "        return {'type': 'MaxPooling', 'strides': strides}\n",
    "    \n",
    "    elif layer_type == '011':  # Dropout\n",
    "        rate = decode_value(encoded_binary[4:6], dropout_options, 0.2)\n",
    "        return {'type': 'Dropout', 'rate': rate}\n",
    "    \n",
    "    elif layer_type == '100':  # Dense\n",
    "        neurons = decode_value(encoded_binary[4:6], neuron_options, 256)\n",
    "        activation = decode_value(encoded_binary[6:], activation_options, 'relu')\n",
    "        return {'type': 'Dense', 'units': neurons, 'activation': activation}\n",
    "    \n",
    "    elif layer_type == '101':  # Flatten\n",
    "        return {'type': 'Flatten'}\n",
    "    \n",
    "    elif layer_type == '110':  # DepthwiseConv2D\n",
    "        filters = decode_value(encoded_binary[4:6], filter_options, 32)\n",
    "        strides = decode_value(encoded_binary[6], stride_options, 1)\n",
    "        activation = decode_value(encoded_binary[7:], activation_options, 'relu')\n",
    "        return {\n",
    "            'type': 'DepthwiseConv2D',\n",
    "            'filters': filters,\n",
    "            'strides': strides,\n",
    "            'activation': activation\n",
    "        }\n",
    "    \n",
    "    elif layer_type == '111':  # Don't care (relleno)\n",
    "        return {'type': \"DontCare\"}  # Se omite\n",
    "\n",
    "    return None\n",
    "\n",
    "# Función auxiliar para decodificar valores en función de los diccionarios\n",
    "def decode_value(bits, options_dict, default_value):\n",
    "    # Buscar los bits en los valores del diccionario y devolver la clave correspondiente\n",
    "    for key, value in options_dict.items():\n",
    "        if value == bits:\n",
    "            return key\n",
    "    # Si no se encuentra, devolver el valor por defecto\n",
    "    return default_value\n",
    "\n",
    "# Ejemplo de codificación y decodificación\n",
    "# Codificación y decodificación de Conv2D\n",
    "binary_conv2d = encode_layer_params('Conv2D', filters=32, strides=1, activation='relu')\n",
    "decoded_conv2d = decode_layer_params(binary_conv2d)\n",
    "print(f\"\\nBinary encoding of Conv2D: {binary_conv2d}\")\n",
    "print(f\"Decoded Conv2D: {decoded_conv2d}\")\n",
    "\n",
    "# Codificación y decodificación de Dropout\n",
    "binary_dropout = encode_layer_params('Dropout', dropout=0.3)\n",
    "decoded_dropout = decode_layer_params(binary_dropout)\n",
    "print(f\"\\nBinary encoding of Dropout: {binary_dropout}\")\n",
    "print(f\"Decoded Dropout: {decoded_dropout}\")\n",
    "\n",
    "# Codificación y decodificación de Dense\n",
    "binary_dense = encode_layer_params('Dense', neurons=128, activation='relu')\n",
    "decoded_dense = decode_layer_params(binary_dense)\n",
    "print(f\"\\nBinary encoding of Dense: {binary_dense}\")\n",
    "print(f\"Decoded Dense: {decoded_dense}\")\n",
    "\n",
    "# Codificación y decodificación de una capa de repetición\n",
    "binary_repetition = encode_layer_params(None, repetition_layers=3, repetition_count=5)\n",
    "decoded_repetition = decode_layer_params(binary_repetition)\n",
    "print(f\"\\nBinary encoding of Repetition: {binary_repetition}\")\n",
    "print(f\"Decoded Repetition: {decoded_repetition}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Encoding of Building Blocks for Neural Network Architectures\n",
    "\n",
    "This module implements the **binary encoding** of various building blocks that make up the architecture of a neural network. Each building block (layers like Conv2D, MaxPooling, Dense, etc.) is represented in binary format based on its key parameters (number of filters, kernel size, number of neurons, activations, etc.). This encoding is useful for optimization processes like **NSGA-III** and later conversion to **Gray code**.\n",
    "\n",
    "### Function `encode_layer_params`\n",
    "\n",
    "This function generates the binary representation of the parameters of a given layer, depending on the type of layer and its specific parameters.\n",
    "\n",
    "### Function Parameters\n",
    "\n",
    "- `layer_type`: (str) The type of layer. It can be one of the following:\n",
    "  - `Conv2D`\n",
    "  - `BatchNorm`\n",
    "  - `MaxPooling`\n",
    "  - `Dropout`\n",
    "  - `Dense`\n",
    "  - `Flatten`\n",
    "  \n",
    "- `filters`: (int) [Optional] Number of filters for `Conv2D` layers. Valid options: `32`, `30`, `16`, `8`.\n",
    "\n",
    "- `kernel_size`: (tuple) [Optional] Kernel size for `Conv2D`. Currently, only `(3, 3)` is supported.\n",
    "\n",
    "- `strides`: (int) [Optional] Stride used in `Conv2D` or `MaxPooling`. Valid options: `1` and `2`.\n",
    "\n",
    "- `padding`: (str) [Optional] Padding type in `Conv2D`. Currently, only `'same'` is supported.\n",
    "\n",
    "- `dropout`: (float) [Optional] Dropout rate for `Dropout` layers. Valid options: `0.2`, `0.3`, `0.5`.\n",
    "\n",
    "- `neurons`: (int) [Optional] Number of neurons in `Dense` layers. Valid options: `256`, `128`, `32`.\n",
    "\n",
    "- `activation`: (str) [Optional] Activation function for `Conv2D` or `Dense` layers. Valid options: `'ReLU'`, `'LeakyReLU'`, `'Sigmoid'`.\n",
    "\n",
    "### Return\n",
    "\n",
    "- `binary_representation`: (str) A string of bits representing the layer parameters in binary format.\n",
    "\n",
    "## Layer Type Encoding\n",
    "\n",
    "Each layer type is represented by a specific sequence of bits. The layer types and their corresponding encodings are:\n",
    "\n",
    "- **Conv2D**: `'000'`\n",
    "- **BatchNorm**: `'001'`\n",
    "- **MaxPooling**: `'010'`\n",
    "- **Dropout**: `'011'`\n",
    "- **Dense**: `'100'`\n",
    "- **Flatten**: `'101'`\n",
    "\n",
    "## Parameters Encoded by Layer Type\n",
    "\n",
    "### Conv2D\n",
    "The `Conv2D` layer includes the following encoded parameters:\n",
    "\n",
    "- **Number of filters**:\n",
    "  - `32`: `'00'`\n",
    "  - `30`: `'01'`\n",
    "  - `16`: `'10'`\n",
    "  - `8`: `'11'`\n",
    "\n",
    "- **Kernel size**:\n",
    "  - `(3, 3)`: `'0'` (only this size is supported for now)\n",
    "\n",
    "- **Stride**:\n",
    "  - `1`: `'0'`\n",
    "  - `2`: `'1'`\n",
    "\n",
    "- **Padding**:\n",
    "  - `'same'`: `'0'`\n",
    "\n",
    "- **Activation function**:\n",
    "  - `ReLU`: `'00'`\n",
    "  - `LeakyReLU`: `'01'`\n",
    "\n",
    "### BatchNorm\n",
    "The `BatchNorm` layer has no additional parameters, only its layer type encoding (`'001'`).\n",
    "\n",
    "### MaxPooling\n",
    "The `MaxPooling` layer has a single encoded parameter:\n",
    "\n",
    "- **Stride**:\n",
    "  - `1`: `'0'`\n",
    "  - `2`: `'1'`\n",
    "\n",
    "### Dropout\n",
    "The `Dropout` layer has the following encoded dropout rates:\n",
    "\n",
    "- **Dropout Rate**:\n",
    "  - `0.2`: `'00'`\n",
    "  - `0.3`: `'01'`\n",
    "  - `0.5`: `'10'`\n",
    "\n",
    "### Dense\n",
    "The `Dense` layer has the following encoded parameters:\n",
    "\n",
    "- **Number of neurons**:\n",
    "  - `256`: `'00'`\n",
    "  - `128`: `'01'`\n",
    "  - `32`: `'10'`\n",
    "\n",
    "- **Activation function**:\n",
    "  - `ReLU`: `'00'`\n",
    "  - `LeakyReLU`: `'01'`\n",
    "  - `Sigmoid`: `'10'`\n",
    "\n",
    "### Flatten\n",
    "The `Flatten` layer has no additional parameters, only its layer type encoding (`'101'`).\n",
    "\n",
    "## Gray Code Conversion\n",
    "\n",
    "In addition to binary encoding, this module supports **Gray code** conversion for efficient optimization, where only one bit changes between consecutive values.\n",
    "\n",
    "### Function `binary_to_gray`\n",
    "\n",
    "This function converts a binary string to Gray code using the following logic:\n",
    "- The first bit in Gray code is the same as the first bit in binary.\n",
    "- For each subsequent bit, the Gray code bit is the XOR of the current binary bit and the previous binary bit.\n",
    "\n",
    "### Function Parameters\n",
    "\n",
    "- `binary_str`: (str) A string representing a binary number.\n",
    "\n",
    "### Return\n",
    "\n",
    "- `gray_str`: (str) A string representing the corresponding Gray code.\n",
    "\n",
    "### Function `gray_to_binary`\n",
    "\n",
    "This function converts a Gray code string back to its binary equivalent using the following logic:\n",
    "- The first bit of the binary string is the same as the first bit of the Gray code.\n",
    "- For each subsequent bit, the binary bit is the XOR of the previous binary bit and the current Gray code bit.\n",
    "\n",
    "### Function Parameters\n",
    "\n",
    "- `gray_str`: (str) A string representing a Gray code number.\n",
    "\n",
    "### Return\n",
    "\n",
    "- `binary_str`: (str) A string representing the corresponding binary number.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Binary Encoding: 010100000000000000000100000001010000010100000010000000001111000010011100011100000011100000011100000011100000\n",
      "Encoded Model: 010100000000000000000100000001010000010100000010000000001111000010011100011100000011100000011100000011100000 (Length: 108)\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'DontCare'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'DontCare'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Flatten'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Función para eliminar campos adicionales como 'padding' y 'kernel_size'\n",
    "def clean_decoded_model(model_dict):\n",
    "    cleaned_layers = []\n",
    "    \n",
    "    for layer in model_dict['layers']:\n",
    "        # Eliminar las capas 'DontCare' o de repetición\n",
    "        if layer['type'] == 'DontCare' or layer['type'] == 'Repetition':\n",
    "            continue  # No incluir la capa 'DontCare' o 'Repetition'\n",
    "        \n",
    "        # Remover 'kernel_size' y 'padding' si están presentes\n",
    "        if 'kernel_size' in layer:\n",
    "            del layer['kernel_size']\n",
    "        if 'padding' in layer:\n",
    "            del layer['padding']\n",
    "        \n",
    "        cleaned_layers.append(layer)\n",
    "    \n",
    "    return {'layers': cleaned_layers}\n",
    "\n",
    "\n",
    "def fixArch(model_dict):\n",
    "    \"\"\"\n",
    "    Corrige y valida la arquitectura del modelo, asegurando que el orden de las capas\n",
    "    sea coherente y las capas Flatten no aparezcan antes de capas convolucionales o MaxPooling.\n",
    "    También se aseguran las capas Flatten antes de Dense.\n",
    "    \"\"\"\n",
    "    fixed_layers = []\n",
    "    input_is_flattened = False  \n",
    "    conv_or_pool_found = False  \n",
    "\n",
    "    for layer in model_dict['layers']:\n",
    "        # Si encontramos una capa de repetición\n",
    "        if layer['type'] == 'Repetition':\n",
    "            fixed_layers.extend(fixed_layers[-layer['repetition_layers']:] * layer['repetition_count'])\n",
    "            continue  # Saltar a la siguiente capa después de aplicar la repetición\n",
    "\n",
    "        # Si encontramos una capa Flatten después de Conv2D, DepthwiseConv2D o MaxPooling\n",
    "        if layer['type'] == 'Flatten':\n",
    "            if conv_or_pool_found:\n",
    "                input_is_flattened = True\n",
    "            else:\n",
    "                print(f\"Invalid placement: Replacing Flatten with DontCare.\")\n",
    "                fixed_layers.append({'type': 'DontCare'})\n",
    "                continue\n",
    "        \n",
    "        if input_is_flattened and layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling']:\n",
    "            print(f\"Invalid placement: Replacing {layer['type']} with DontCare after Flatten.\")\n",
    "            layer = {'type': 'DontCare'}\n",
    "        \n",
    "        if layer['type'] == 'Dense' and not input_is_flattened:\n",
    "            print(f\"Inserting Flatten before Dense layer.\")\n",
    "            fixed_layers.append({'type': 'Flatten'})\n",
    "            input_is_flattened = True \n",
    "        \n",
    "        if layer['type'] in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling']:\n",
    "            conv_or_pool_found = True\n",
    "\n",
    "        fixed_layers.append(layer)\n",
    "\n",
    "    model_dict['layers'] = fixed_layers\n",
    "    return model_dict\n",
    "\n",
    "\n",
    "def decode_model_architecture(encoded_string_binary, gene_length=9):\n",
    "    model_dict = {'layers': []}\n",
    "    \n",
    "    index = 0\n",
    "    while index < len(encoded_string_binary):\n",
    "        # Extraer los próximos 9 bits de la codificación binaria\n",
    "        binary_code_for_layer = encoded_string_binary[index:index+gene_length]\n",
    "        \n",
    "        # Decodificar una capa completa usando decode_layer_params\n",
    "        decoded_layer = decode_layer_params(binary_code_for_layer)\n",
    "        \n",
    "        # Añadir la capa decodificada al modelo\n",
    "        model_dict['layers'].append(decoded_layer)\n",
    "        \n",
    "        # Avanzar el índice por el tamaño del gen (9 bits)\n",
    "        index += gene_length\n",
    "    \n",
    "    return fixArch(model_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encode_model_architecture(model_dict, max_alleles=108):\n",
    "    encoded_layers_bin = []\n",
    "    total_alleles = 0\n",
    "    \n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Repetition':  # Codificar repetición de capas\n",
    "            binary_encoding = encode_layer_params(\n",
    "                layer_type='Repetition',\n",
    "                repetition_layers=layer.get('repetition_layers'),\n",
    "                repetition_count=layer.get('repetition_count')\n",
    "            )\n",
    "        else:\n",
    "            binary_encoding = encode_layer_params(\n",
    "                layer_type=layer['type'],\n",
    "                filters=layer.get('filters'),\n",
    "                strides=layer.get('strides'),\n",
    "                dropout=layer.get('rate'),\n",
    "                neurons=layer.get('units'),\n",
    "                activation=layer.get('activation', '').lower()\n",
    "            )\n",
    "        \n",
    "        if len(binary_encoding) != 9:  # Asegúrate de que cada capa esté correctamente codificada en 9 bits\n",
    "            print(f\"Warning: Layer {layer['type']} is not encoded in 9 bits: {binary_encoding}\")\n",
    "        \n",
    "        total_alleles += len(binary_encoding)\n",
    "        encoded_layers_bin.append(binary_encoding)\n",
    "    \n",
    "    # Verificar la longitud final y si necesita relleno\n",
    "    while total_alleles < max_alleles:\n",
    "        dont_care_encoding = encode_layer_params('DontCare')\n",
    "        encoded_layers_bin.append(dont_care_encoding)\n",
    "        total_alleles += len(dont_care_encoding)\n",
    "\n",
    "    final_encoding_bin = ''.join(encoded_layers_bin[:max_alleles])\n",
    "    print(f\"Final Binary Encoding: {final_encoding_bin}\")\n",
    "    \n",
    "    return final_encoding_bin\n",
    "\n",
    "\n",
    "def verify_model_architecture(original_model):\n",
    "    encoded_model = encode_model_architecture(original_model)\n",
    "    print(f\"Encoded Model: {encoded_model} (Length: {len(encoded_model)})\")\n",
    "    \n",
    "    decoded_model = decode_model_architecture(encoded_model, gene_length=9)\n",
    "    print(\"\\nDecoded Model:\")\n",
    "    print(decoded_model)\n",
    "    \n",
    "    fixed_model = fixArch(decoded_model)\n",
    "    print(\"\\nFixed Model:\")\n",
    "    print(fixed_model)\n",
    "    \n",
    "    decoded_model_cleaned = clean_decoded_model(fixed_model)\n",
    "    \n",
    "    if original_model == decoded_model_cleaned:\n",
    "        print(\"Modelo original y decodificado son iguales.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Original Model:\")\n",
    "        print(original_model)\n",
    "        print(\"\\nDecoded Model (cleaned):\")\n",
    "        print(decoded_model_cleaned)\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "model_example = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Verificar el modelo\n",
    "print(verify_model_architecture(model_example))\n",
    "\n",
    "# Construcción del modelo en TensorFlow desde el diccionario decodificado\n",
    "\n",
    "class DontCareLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(DontCareLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Devuelve los inputs sin ninguna modificación (identidad)\n",
    "        return inputs\n",
    "\n",
    "def build_tf_model_from_dict(model_dict, input_shape=(28, 28, 3)):\n",
    "    model = Sequential()\n",
    "    previous_layers = []  # Lista para mantener las capas anteriores para repetirlas\n",
    "    for layer in model_dict['layers']:\n",
    "        if layer['type'] == 'Conv2D':\n",
    "            conv_layer = Conv2D(filters=layer['filters'], \n",
    "                                kernel_size=(3, 3), \n",
    "                                strides=layer['strides'], \n",
    "                                padding='same', \n",
    "                                activation=layer['activation'])\n",
    "            model.add(conv_layer)\n",
    "            previous_layers.append(conv_layer)\n",
    "\n",
    "        elif layer['type'] == 'DepthwiseConv2D':\n",
    "            depthwise_layer = DepthwiseConv2D(kernel_size=(3, 3), \n",
    "                                              strides=layer['strides'], \n",
    "                                              padding='same', \n",
    "                                              activation=layer['activation'])\n",
    "            model.add(depthwise_layer)\n",
    "            previous_layers.append(depthwise_layer)\n",
    "\n",
    "        elif layer['type'] == 'BatchNorm':\n",
    "            batch_norm_layer = BatchNormalization()\n",
    "            model.add(batch_norm_layer)\n",
    "            previous_layers.append(batch_norm_layer)\n",
    "\n",
    "        elif layer['type'] == 'MaxPooling':\n",
    "            max_pool_layer = MaxPooling2D(pool_size=(2, 2), \n",
    "                                          strides=layer['strides'], \n",
    "                                          padding='same')\n",
    "            model.add(max_pool_layer)\n",
    "            previous_layers.append(max_pool_layer)\n",
    "\n",
    "        elif layer['type'] == 'Flatten':\n",
    "            flatten_layer = Flatten()\n",
    "            model.add(flatten_layer)\n",
    "            previous_layers.append(flatten_layer)\n",
    "\n",
    "        elif layer['type'] == 'Dense':\n",
    "            dense_layer = Dense(units=layer['units'], \n",
    "                                activation=layer['activation'])\n",
    "            model.add(dense_layer)\n",
    "            previous_layers.append(dense_layer)\n",
    "\n",
    "        elif layer['type'] == 'Dropout':\n",
    "            dropout_layer = Dropout(rate=layer['rate'])\n",
    "            model.add(dropout_layer)\n",
    "            previous_layers.append(dropout_layer)\n",
    "\n",
    "        elif layer['type'] == 'Repetition':\n",
    "            # Repetir las últimas 'repetition_layers' capas 'repetition_count' veces\n",
    "            if len(previous_layers) >= layer['repetition_layers']:\n",
    "                layers_to_repeat = previous_layers[-layer['repetition_layers']:]\n",
    "                for _ in range(layer['repetition_count']):\n",
    "                    for repeated_layer in layers_to_repeat:\n",
    "                        # Clonamos la capa repetida usando `type` y los mismos parámetros\n",
    "                        if isinstance(repeated_layer, Conv2D):\n",
    "                            model.add(Conv2D(repeated_layer.filters, \n",
    "                                             kernel_size=(3, 3), \n",
    "                                             strides=repeated_layer.strides, \n",
    "                                             padding='same', \n",
    "                                             activation=repeated_layer.activation))\n",
    "                        elif isinstance(repeated_layer, DepthwiseConv2D):\n",
    "                            model.add(DepthwiseConv2D(kernel_size=(3, 3), \n",
    "                                                      strides=repeated_layer.strides, \n",
    "                                                      padding='same', \n",
    "                                                      activation=repeated_layer.activation))\n",
    "                        elif isinstance(repeated_layer, BatchNormalization):\n",
    "                            model.add(BatchNormalization())\n",
    "                        elif isinstance(repeated_layer, MaxPooling2D):\n",
    "                            model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                                                   strides=repeated_layer.strides, \n",
    "                                                   padding='same'))\n",
    "                        elif isinstance(repeated_layer, Flatten):\n",
    "                            model.add(Flatten())\n",
    "                        elif isinstance(repeated_layer, Dense):\n",
    "                            model.add(Dense(repeated_layer.units, \n",
    "                                            activation=repeated_layer.activation))\n",
    "                        elif isinstance(repeated_layer, Dropout):\n",
    "                            model.add(Dropout(repeated_layer.rate))\n",
    "            else:\n",
    "                print(f\"Error: No hay suficientes capas para repetir {layer['repetition_layers']} veces.\")\n",
    "                continue\n",
    "\n",
    "        elif layer['type'] == 'DontCare':\n",
    "            # Capa DontCare se omite\n",
    "            continue\n",
    "\n",
    "    model.build(input_shape=(None,) + input_shape)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo 1: build_CNN_LF_model\n",
    "model_CNN_LF = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 30, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},  # Revisar 'filters'\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.3},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 2: build_reduced_model\n",
    "model_reduced = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 3: build_Spectro_CNN_model\n",
    "model_spectro_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2}, \n",
    "         \n",
    "         \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "         {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "         {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        \n",
    "    {\"type\":\"Flatten\"},\n",
    "    {\"type\":\"Dense\",\"units\":256,\"activation\":\"relu\"},   \n",
    "    {\"type\":\"Dropout\",\"rate\":0.5},\n",
    "                \n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo corregido: build_Spectro_CNN_model con capas de repetición\n",
    "model_spectro_CNN_with_repetition = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"leaky_relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2}, \n",
    "        # Aquí indicamos que las siguientes 10 capas (5 Conv2D + 5 BatchNorm) se repiten 10 veces\n",
    "        {\"type\": \"Repetition\", \"repetition_layers\": 3, \"repetition_count\": 31},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Ejemplo 4: Simple Conv2D model\n",
    "model_simple_conv = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 5: Simple Dense model\n",
    "model_dense_only = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 6: Small CNN model with Dropout\n",
    "model_small_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 8, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.2},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 7: Deep CNN model\n",
    "model_deep_CNN = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 10, \"activation\": \"sigmoid\"}  # Revisar 'units'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ejemplo 8: Basic Dense with Dropout\n",
    "model_dense_dropout = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "model_with_depthwise = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"DepthwiseConv2D\", \"filters\": 16, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"MaxPooling\", \"strides\": 2},\n",
    "        {\"type\": \"Dense\", \"units\": 128, \"activation\": \"sigmoid\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"tanh\"}\n",
    "    ]\n",
    "}\n",
    "model_with_global_avg_pooling = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"BatchNorm\"},\n",
    "        {\"type\": \"GlobalAveragePooling2D\"},\n",
    "        {\"type\": \"Dense\", \"units\": 32, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dense\", \"units\": 1, \"activation\": \"sigmoid\"}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para validar si los valores del modelo son válidos\n",
    "def validate_model_layers(model):\n",
    "    # Verificar que el número de capas no exceda 12\n",
    "    max_layers = 12\n",
    "    if len(model['layers']) > max_layers:\n",
    "        print(f\"Invalid model: Exceeds maximum allowed layers ({max_layers})\")\n",
    "        return False\n",
    "    \n",
    "    consecutive_repetition_count = 0  # Contador de repeticiones consecutivas\n",
    "\n",
    "    for i, layer in enumerate(model['layers']):\n",
    "        layer_type = layer['type']\n",
    "        \n",
    "        if layer_type == 'Conv2D':\n",
    "            filters = layer.get('filters')\n",
    "            strides = layer.get('strides')\n",
    "            activation = layer.get('activation')\n",
    "\n",
    "            if filters not in filter_options:\n",
    "                print(f\"Invalid filters value in Conv2D layer: {filters}\")\n",
    "                return False\n",
    "            if strides not in stride_options:\n",
    "                print(f\"Invalid strides value in Conv2D layer: {strides}\")\n",
    "                return False\n",
    "            if activation not in activation_options:\n",
    "                print(f\"Invalid activation value in Conv2D layer: {activation}\")\n",
    "                return False\n",
    "        \n",
    "        elif layer_type == 'Dense':\n",
    "            units = layer.get('units')\n",
    "            activation = layer.get('activation')\n",
    "\n",
    "            if units not in neuron_options:\n",
    "                print(f\"Invalid units value in Dense layer: {units}\")\n",
    "                return False\n",
    "            if activation not in activation_options:\n",
    "                print(f\"Invalid activation value in Dense layer: {activation}\")\n",
    "                return False\n",
    "\n",
    "        elif layer_type == 'Dropout':\n",
    "            rate = layer.get('rate')\n",
    "            if rate not in dropout_options:\n",
    "                print(f\"Invalid dropout rate value: {rate}\")\n",
    "                return False\n",
    "        \n",
    "        elif layer_type == 'MaxPooling':\n",
    "            strides = layer.get('strides')\n",
    "            if strides not in stride_options:\n",
    "                print(f\"Invalid strides value in MaxPooling layer: {strides}\")\n",
    "                return False\n",
    "        \n",
    "        elif layer_type == 'Flatten':\n",
    "            # No se necesitan validaciones adicionales para Flatten\n",
    "            pass\n",
    "\n",
    "        elif layer_type == 'BatchNorm':\n",
    "            # No se necesitan validaciones adicionales para BatchNorm\n",
    "            pass\n",
    "\n",
    "        elif layer_type == 'DepthwiseConv2D':\n",
    "            filters = layer.get('filters')\n",
    "            strides = layer.get('strides')\n",
    "            activation = layer.get('activation')\n",
    "\n",
    "            if filters not in filter_options:\n",
    "                print(f\"Invalid filters value in DepthwiseConv2D layer: {filters}\")\n",
    "                return False\n",
    "            if strides not in stride_options:\n",
    "                print(f\"Invalid strides value in DepthwiseConv2D layer: {strides}\")\n",
    "                return False\n",
    "            if activation not in activation_options:\n",
    "                print(f\"Invalid activation value in DepthwiseConv2D layer: {activation}\")\n",
    "                return False\n",
    "\n",
    "        elif layer_type == 'Repetition':\n",
    "            # Validamos las capas de repetición\n",
    "            repetition_layers = layer.get('repetition_layers')\n",
    "            repetition_count = layer.get('repetition_count')\n",
    "\n",
    "            if not (1 <= repetition_layers <= 7):  # Codificamos 3 bits para capas a repetir\n",
    "                print(f\"Invalid repetition_layers value: {repetition_layers}\")\n",
    "                return False\n",
    "            if not (1 <= repetition_count <= 31):  # Usamos 5 bits para el número de repeticiones\n",
    "                print(f\"Invalid repetition_count value: {repetition_count}\")\n",
    "                return False\n",
    "\n",
    "            # Verificar si hay repeticiones consecutivas\n",
    "            consecutive_repetition_count += 1\n",
    "            if consecutive_repetition_count > 1:\n",
    "                print(f\"Invalid: Consecutive Repetition layers at Gen {i+1}.\")\n",
    "                return False\n",
    "\n",
    "            # Verificar si el rango de repetición incluye otras capas de repetición\n",
    "            start_index = max(0, i - repetition_layers)\n",
    "            for j in range(start_index, i):\n",
    "                if model['layers'][j]['type'] == 'Repetition':\n",
    "                    print(f\"Invalid: Repetition at Gen {i+1} includes another Repetition layer.\")\n",
    "                    return False\n",
    "        else:\n",
    "            consecutive_repetition_count = 0  # Reiniciar si no es capa de repetición\n",
    "\n",
    "        # Verificar si el tipo de capa es válido\n",
    "        if layer_type not in layer_type_options:\n",
    "            print(f\"Invalid layer type: {layer_type}\")\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Función para verificar y construir el modelo\n",
    "def run_verification_and_build(model):\n",
    "    if validate_model_layers(model):\n",
    "        print(\"\\nModel is valid. Running verification and building the model:\")\n",
    "        \n",
    "        # Verificación del modelo\n",
    "        if verify_model_architecture(model):\n",
    "            print(\"Model verification passed.\")\n",
    "        else:\n",
    "            print(\"Model verification failed.\")\n",
    "        \n",
    "        # Codificar y decodificar el modelo utilizando el nuevo esquema de 9 bits\n",
    "        encoded_model = encode_model_architecture(model)\n",
    "        if(len(encoded_model) > 108):\n",
    "            print(\"Model is NOT correctly encoded.\")\n",
    "            return(\"Model is NOT correctly encoded.\")\n",
    "            \n",
    "        decoded_model_dict = decode_model_architecture(encoded_model, gene_length=9)  # Cambiado a 9 bits\n",
    "        \n",
    "        # Construcción del modelo en TensorFlow desde el diccionario decodificado\n",
    "        tf_model = build_tf_model_from_dict(decoded_model_dict)\n",
    "        \n",
    "        # Mostrar la estructura del modelo de TensorFlow\n",
    "        try:\n",
    "            tf_model.summary()\n",
    "        except Exception as e:\n",
    "            print(f\"Error building model: {e}\")\n",
    "    else:\n",
    "        print(\"Model is invalid. Skipping verification and build.\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifications:\n",
      "\n",
      "Model 1: CNN_LF\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 000001000001100000000100000001010000000010000001100000000100000001010000010100000010000000001101000010011100\n",
      "Encoded Model: 000001000001100000000100000001010000000010000001100000000100000001010000010100000010000000001101000010011100 (Length: 108)\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 30, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 30, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 30, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 30, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.3}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 000001000001100000000100000001010000000010000001100000000100000001010000010100000010000000001101000010011100\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 30)        840       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 28, 28, 30)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 30)       120       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 30)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 16)        4336      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 206,577\n",
      "Trainable params: 206,485\n",
      "Non-trainable params: 92\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model 2: Reduced\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 000100000000010001000100000000011001000100000010100000010010010010011100011100000011100000011100000011100000\n",
      "Encoded Model: 000100000000010001000100000000011001000100000010100000010010010010011100011100000011100000011100000011100000 (Length: 108)\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'leaky_relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 000100000000010001000100000000011001000100000010100000010010010010011100011100000011100000011100000011100000\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_2 (Batc  (None, 28, 28, 3)        12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 16)        448       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 8)         1160      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                200736    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 202,485\n",
      "Trainable params: 202,431\n",
      "Non-trainable params: 54\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model 3: Spectro CNN\n",
      "Invalid model: Exceeds maximum allowed layers (12)\n",
      "Model is invalid. Skipping verification and build.\n",
      "\n",
      "\n",
      "\n",
      "Model 3.5 Spectro CNN with repetition\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 000000001000100000001010000101010000010100000010000000001111000010011100011100000011100000011100000011100000\n",
      "Encoded Model: 000000001000100000001010000101010000010100000010000000001111000010011100011100000011100000011100000011100000 (Length: 108)\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Repetition', 'repetition_layers': 3, 'repetition_count': 31}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'leaky_relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 000000001000100000001010000101010000010100000010000000001111000010011100011100000011100000011100000011100000\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 7, 7, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 4, 4, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 2, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 2, 2, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 1, 1, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 1, 1, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 300,385\n",
      "Trainable params: 298,337\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model 4: Simple Conv2D\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 000010000010100000010001000010011100011100000011100000011100000011100000011100000011100000011100000011100000\n",
      "Encoded Model: 000010000010100000010001000010011100011100000011100000011100000011100000011100000011100000011100000011100000 (Length: 108)\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 000010000010100000010001000010011100011100000011100000011100000011100000011100000011100000011100000011100000\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 28, 28, 16)        448       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,606,337\n",
      "Trainable params: 1,606,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model 5: Dense Only\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 010100000010000000010001000010000100011100000011100000011100000011100000011100000011100000011100000011100000\n",
      "Encoded Model: 010100000010000000010001000010000100011100000011100000011100000011100000011100000011100000011100000011100000 (Length: 108)\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "Inserting Flatten before Dense layer.\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "Inserting Flatten before Dense layer.\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Flatten'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 010100000010000000010001000010000100011100000011100000011100000011100000011100000011100000011100000011100000\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "Inserting Flatten before Dense layer.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 2352)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               602368    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 668,288\n",
      "Trainable params: 668,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model 6: Small CNN\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 000011000001100000001010000010100000010010000010011100011100000011100000011100000011100000011100000011100000\n",
      "Encoded Model: 000011000001100000001010000010100000010010000010011100011100000011100000011100000011100000011100000011100000 (Length: 108)\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'sigmoid'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 8, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.2}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 000011000001100000001010000010100000010010000010011100011100000011100000011100000011100000011100000011100000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_37 (Conv2D)          (None, 28, 28, 8)         224       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28, 28, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 14, 14, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                50208     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,465\n",
      "Trainable params: 50,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model 7: Deep CNN\n",
      "Invalid units value in Dense layer: 10\n",
      "Model is invalid. Skipping verification and build.\n",
      "\n",
      "\n",
      "\n",
      "Model 8: Dense with Dropout\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 010100000010001000001111000010010110011100000011100000011100000011100000011100000011100000011100000011100000\n",
      "Encoded Model: 010100000010001000001111000010010110011100000011100000011100000011100000011100000011100000011100000011100000 (Length: 108)\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "Inserting Flatten before Dense layer.\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "Inserting Flatten before Dense layer.\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 32, 'activation': 'tanh'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Dense', 'units': 32, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 010100000010001000001111000010010110011100000011100000011100000011100000011100000011100000011100000011100000\n",
      "Invalid placement: Replacing Flatten with DontCare.\n",
      "Inserting Flatten before Dense layer.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 2352)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               301184    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,312\n",
      "Trainable params: 305,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model with DepthwiseConv2D\n",
      "\n",
      "Model is valid. Running verification and building the model:\n",
      "Final Binary Encoding: 011010000000100000001010000010001100010011110011100000011100000011100000011100000011100000011100000011100000\n",
      "Encoded Model: 011010000000100000001010000010001100010011110011100000011100000011100000011100000011100000011100000011100000 (Length: 108)\n",
      "Inserting Flatten before Dense layer.\n",
      "\n",
      "Decoded Model:\n",
      "{'layers': [{'type': 'DepthwiseConv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "\n",
      "Fixed Model:\n",
      "{'layers': [{'type': 'DepthwiseConv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}, {'type': 'DontCare'}]}\n",
      "Original Model:\n",
      "{'layers': [{'type': 'DepthwiseConv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Dense', 'units': 128, 'activation': 'sigmoid'}, {'type': 'Dense', 'units': 1, 'activation': 'tanh'}]}\n",
      "\n",
      "Decoded Model (cleaned):\n",
      "{'layers': [{'type': 'DepthwiseConv2D', 'filters': 16, 'strides': 1, 'activation': 'relu'}, {'type': 'BatchNorm'}, {'type': 'MaxPooling', 'strides': 2}, {'type': 'Flatten'}, {'type': 'Dense', 'units': 128, 'activation': 'relu'}, {'type': 'Dense', 'units': 1, 'activation': 'relu'}]}\n",
      "Model verification failed.\n",
      "Final Binary Encoding: 011010000000100000001010000010001100010011110011100000011100000011100000011100000011100000011100000011100000\n",
      "Inserting Flatten before Dense layer.\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " depthwise_conv2d (Depthwise  (None, 28, 28, 3)        30        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 28, 28, 3)        12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 14, 14, 3)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 588)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               75392     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,563\n",
      "Trainable params: 75,557\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "Model with GlobalAveragePooling2D\n",
      "Invalid layer type: GlobalAveragePooling2D\n",
      "Model is invalid. Skipping verification and build.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verificación de los modelos\n",
    "print(\"Verifications:\")\n",
    "\n",
    "print(\"\\nModel 1: CNN_LF\")\n",
    "run_verification_and_build(model_CNN_LF)  # Ejemplo 1\n",
    "\n",
    "print(\"\\nModel 2: Reduced\")\n",
    "run_verification_and_build(model_reduced)  # Ejemplo 2\n",
    "\n",
    "print(\"\\nModel 3: Spectro CNN\")\n",
    "run_verification_and_build(model_spectro_CNN)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 3.5 Spectro CNN with repetition\")\n",
    "run_verification_and_build(model_spectro_CNN_with_repetition)  # Ejemplo 3\n",
    "\n",
    "print(\"\\nModel 4: Simple Conv2D\")\n",
    "run_verification_and_build(model_simple_conv)  # Ejemplo 4\n",
    "\n",
    "print(\"\\nModel 5: Dense Only\")\n",
    "run_verification_and_build(model_dense_only)  # Ejemplo 5\n",
    "\n",
    "print(\"\\nModel 6: Small CNN\")\n",
    "run_verification_and_build(model_small_CNN)  # Ejemplo 6\n",
    "\n",
    "print(\"\\nModel 7: Deep CNN\")\n",
    "run_verification_and_build(model_deep_CNN)  # Ejemplo 7\n",
    "\n",
    "print(\"\\nModel 8: Dense with Dropout\")\n",
    "run_verification_and_build(model_dense_dropout)  # Ejemplo 8\n",
    "\n",
    "print(\"\\nModel with DepthwiseConv2D\")\n",
    "run_verification_and_build(model_with_depthwise)\n",
    "\n",
    "print(\"\\nModel with GlobalAveragePooling2D\")\n",
    "run_verification_and_build(model_with_global_avg_pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing random generated architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid first 3 layers at position 2: Flatten is not allowed.\n",
      "Model is invalid. Repairing model...\n",
      "Repairing invalid layer at position 2. Replacing Flatten with Conv2D.\n",
      "Model has been repaired.\n",
      "\n",
      "Repaired Model:\n",
      "{'layers': [{'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Dropout', 'rate': 0.5}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'}, {'type': 'Dense', 'units': 256, 'activation': 'relu'}]}\n"
     ]
    }
   ],
   "source": [
    "# Función de validación según las reglas de construcción de la red\n",
    "def validate_model_architecture(model_dict):\n",
    "    \"\"\"\n",
    "    Valida que el modelo siga las reglas:\n",
    "    1. Las primeras 3 capas deben ser Conv2D, DepthwiseConv2D, MaxPooling, BatchNorm o Dropout.\n",
    "    2. Después de Flatten, solo se permiten capas Dense, BatchNorm, Flatten o Dropout.\n",
    "    \"\"\"\n",
    "    conv_count = 0\n",
    "    input_is_flattened = False  # Bandera para verificar si las entradas están aplanadas\n",
    "\n",
    "    for i, layer in enumerate(model_dict['layers']):\n",
    "        layer_type = layer['type']\n",
    "\n",
    "        # Regla 1: Las primeras 3 capas deben ser de ciertos tipos\n",
    "        if i < 3:\n",
    "            if layer_type not in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling', 'BatchNorm', 'Dropout']:\n",
    "                print(f\"Invalid first 3 layers at position {i}: {layer_type} is not allowed.\")\n",
    "                return False  # Si las primeras capas no son válidas, retornamos False\n",
    "        # Regla 2: Después de Flatten, solo ciertos tipos de capas están permitidos\n",
    "        if input_is_flattened:\n",
    "            if layer_type not in ['Dense', 'BatchNorm', 'Flatten', 'Dropout']:\n",
    "                print(f\"Invalid layer after Flatten at position {i}: {layer_type} is not allowed.\")\n",
    "                return False\n",
    "\n",
    "        # Detectar si hay un Flatten para aplicar la segunda regla\n",
    "        if layer_type == 'Flatten':\n",
    "            input_is_flattened = True\n",
    "    \n",
    "    return True  # Si pasa todas las validaciones, es válido\n",
    "\n",
    "# Función de reparación del modelo\n",
    "def repair_model_architecture(model_dict):\n",
    "    \"\"\"\n",
    "    Repara el modelo si no cumple con las reglas de construcción:\n",
    "    1. Asegura que las primeras 3 capas sean de los tipos permitidos.\n",
    "    2. Asegura que después de Flatten, solo existan capas Dense, BatchNorm, Flatten o Dropout.\n",
    "    \"\"\"\n",
    "    conv_count = 0\n",
    "    input_is_flattened = False  # Bandera para verificar si las entradas están aplanadas\n",
    "\n",
    "    # Regla 1: Corregir las primeras 3 capas si no son válidas\n",
    "    for i in range(min(3, len(model_dict['layers']))):\n",
    "        layer_type = model_dict['layers'][i]['type']\n",
    "        if layer_type not in ['Conv2D', 'DepthwiseConv2D', 'MaxPooling', 'BatchNorm', 'Dropout']:\n",
    "            print(f\"Repairing invalid layer at position {i}. Replacing {layer_type} with Conv2D.\")\n",
    "            model_dict['layers'][i] = {\n",
    "                'type': 'Conv2D', 'filters': 32, 'strides': 1, 'activation': 'relu'\n",
    "            }  # Reemplazamos por una capa Conv2D básica\n",
    "\n",
    "    # Regla 2: Reemplazar capas inválidas después de Flatten\n",
    "    for i in range(3, len(model_dict['layers'])):\n",
    "        layer_type = model_dict['layers'][i]['type']\n",
    "\n",
    "        # Si encontramos Flatten, aplicamos las restricciones\n",
    "        if layer_type == 'Flatten':\n",
    "            input_is_flattened = True\n",
    "        elif input_is_flattened and layer_type not in ['Dense', 'BatchNorm', 'Flatten', 'Dropout']:\n",
    "            print(f\"Repairing invalid layer after Flatten at position {i}. Replacing {layer_type} with Dense.\")\n",
    "            model_dict['layers'][i] = {\n",
    "                'type': 'Dense', 'units': 128, 'activation': 'relu'\n",
    "            }  # Reemplazamos por una capa Dense básica\n",
    "\n",
    "    return model_dict  # Devolver el modelo reparado\n",
    "\n",
    "# Función para ejecutar validación y reparación\n",
    "def validate_and_repair_model(model_dict):\n",
    "    if validate_model_architecture(model_dict):\n",
    "        print(\"Model is valid.\")\n",
    "    else:\n",
    "        print(\"Model is invalid. Repairing model...\")\n",
    "        repaired_model = repair_model_architecture(model_dict)\n",
    "        print(\"Model has been repaired.\")\n",
    "        return repaired_model  # Devuelve el modelo reparado\n",
    "\n",
    "# Ejemplo de uso\n",
    "model_example = {\n",
    "    \"layers\": [\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},\n",
    "        {\"type\": \"Dropout\", \"rate\": 0.5},\n",
    "        {\"type\": \"Flatten\"},\n",
    "        {\"type\": \"Conv2D\", \"filters\": 32, \"strides\": 1, \"activation\": \"relu\"},  # Capa inválida después de Flatten\n",
    "        {\"type\": \"Dense\", \"units\": 256, \"activation\": \"relu\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Validar y reparar si es necesario\n",
    "repaired_model = validate_and_repair_model(model_example)\n",
    "print(\"\\nRepaired Model:\")\n",
    "print(repaired_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Construyendo modelo TensorFlow 1:   0%|          | 0/1 [00:00<?, ?model/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Binary Model 1: 000110001 001001110 111001001 111100100 010110111 100100111 110100001 000100010 000101100 001010001 100100000 000011110\n",
      "Arquitectura del Modelo (genes en binario):\n",
      "Gen 1: BatchNorm 000110001\n",
      "Gen 2: MaxPooling 001001110\n",
      "Gen 3: Repetition 111001001\n",
      "Gen 4: Repetition 111100100\n",
      "Gen 5: Flatten 010110111\n",
      "Gen 6: Repetition 100100111\n",
      "Gen 7: Repetition 110100001\n",
      "Gen 8: BatchNorm 000100010\n",
      "Gen 9: BatchNorm 000101100\n",
      "Gen 10: MaxPooling 001010001\n",
      "Gen 11: Repetition 100100000\n",
      "Gen 12: Conv2D 000011110\n",
      "\n",
      "\n",
      "Invalid: Penultimate layer must be Flatten. Replacing.\n",
      "Invalid: Last layer must be Dense with 1 unit. Replacing.\n",
      "Invalid: Consecutive Repetition layers at positions 3 and 4. Replacing gene at position 4 with DontCare.\n",
      "Invalid: Consecutive Repetition layers at positions 6 and 7. Replacing gene at position 7 with DontCare.\n",
      "Invalid: Gene 3 is invalid in initial position. Replacing with Conv2D.\n",
      "Repaired Binary Model 1: 000110001 001001110 000000000 011100000 010110111 100100111 011100000 000100010 000101100 001010001 010100000 010000001\n",
      "Arquitectura del Modelo (genes en binario):\n",
      "Gen 1: BatchNorm 000110001\n",
      "Gen 2: MaxPooling 001001110\n",
      "Gen 3: Conv2D 000000000\n",
      "Gen 4: DontCare 011100000\n",
      "Gen 5: Flatten 010110111\n",
      "Gen 6: Repetition 100100111\n",
      "Gen 7: DontCare 011100000\n",
      "Gen 8: BatchNorm 000100010\n",
      "Gen 9: BatchNorm 000101100\n",
      "Gen 10: MaxPooling 001010001\n",
      "Gen 11: Flatten 010100000\n",
      "Gen 12: Dense 010000001\n",
      "\n",
      "\n",
      "Arquitectura Decodificada (Agrupada):\n",
      "BatchNorm(000110001)\n",
      "MaxPooling(001001110)\n",
      "Conv2D(000000000)\n",
      "DontCare(011100000)\n",
      "Flatten(010110111)\n",
      "[Flatten(010110111)] x 1\n",
      "DontCare(011100000)\n",
      "BatchNorm(000100010)\n",
      "BatchNorm(000101100)\n",
      "MaxPooling(001010001)\n",
      "Flatten(010100000)\n",
      "Dense(010000001)\n",
      "\n",
      "\n",
      "\n",
      "Invalid placement: Replacing MaxPooling with DontCare after Flatten.\n",
      "\n",
      "Model 1 Summary:\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_38 (Bat  (None, 28, 28, 3)        12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 28, 28, 3)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 28, 28, 32)        896       \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 25088)            100352    \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 25088)            100352    \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               6422784   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,624,396\n",
      "Trainable params: 6,524,038\n",
      "Non-trainable params: 100,358\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progreso general: 100%|██████████| 1/1 [00:00<00:00, 13.83model/s]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x2cee18e9780>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Función para generar un string binario aleatorio de 108 alelos\n",
    "def generate_random_binary_model():\n",
    "    return ''.join(random.choice(['0', '1']) for _ in range(108))\n",
    "\n",
    "# Función para imprimir el modelo en binario, con una capa por línea antes de decodificar\n",
    "def print_model_layers_in_binary(binary_model, title=\"Arquitectura del Modelo (genes en binario):\"):\n",
    "    print(title)\n",
    "    for index in range(0, len(binary_model), 9):\n",
    "        gene = binary_model[index:index+9]\n",
    "        layer_type = \"Unknown\"\n",
    "        if gene[0] == '1':\n",
    "            layer_type = \"Repetition\"\n",
    "        else:\n",
    "            binary_layer_type = gene[1:4]\n",
    "            layer_type = {\n",
    "                '000': 'Conv2D',\n",
    "                '001': 'BatchNorm',\n",
    "                '010': 'MaxPooling',\n",
    "                '011': 'Dropout',\n",
    "                '100': 'Dense',\n",
    "                '101': 'Flatten',\n",
    "                '110': 'DepthwiseConv2D',\n",
    "                '111': 'DontCare'\n",
    "            }.get(binary_layer_type, 'Unknown')\n",
    "        print(f\"Gen {index//9 + 1}: {layer_type} {gene}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Función para imprimir la arquitectura del modelo con repetición agrupada\n",
    "def print_decoded_architecture_grouped(genes):\n",
    "    decoded_layers = []\n",
    "    for gene in genes:\n",
    "        layer_type = \"Unknown\"\n",
    "        params = gene[4:]\n",
    "        if gene[0] == '1':\n",
    "            layer_type = \"Repetition\"\n",
    "            params = gene[1:4]\n",
    "        else:\n",
    "            binary_layer_type = gene[1:4]\n",
    "            layer_type = {\n",
    "                '000': 'Conv2D',\n",
    "                '001': 'BatchNorm',\n",
    "                '010': 'MaxPooling',\n",
    "                '011': 'Dropout',\n",
    "                '100': 'Dense',\n",
    "                '101': 'Flatten',\n",
    "                '110': 'DepthwiseConv2D',\n",
    "                '111': 'DontCare'\n",
    "            }.get(binary_layer_type, 'Unknown')\n",
    "        decoded_layers.append((layer_type, gene, params))\n",
    "\n",
    "    architecture_str = \"\"\n",
    "    i = 0\n",
    "    while i < len(decoded_layers):\n",
    "        layer_type, gene, params = decoded_layers[i]\n",
    "        if layer_type == \"Repetition\":\n",
    "            repetition_count = int(gene[1:4], 2)\n",
    "            if repetition_count == 0:\n",
    "                architecture_str += f\"Invalid Repetition({gene})\\n\"\n",
    "            else:\n",
    "                repeated_block = []\n",
    "                for j in range(repetition_count):\n",
    "                    if i - (j + 1) >= 0:\n",
    "                        repeated_block.insert(0, decoded_layers[i - (j + 1)])\n",
    "                architecture_str += f\"[\"\n",
    "                for layer_info in repeated_block:\n",
    "                    layer, g, p = layer_info\n",
    "                    architecture_str += f\"{layer}({g}) \"\n",
    "                architecture_str = architecture_str.strip() + f\"] x {repetition_count}\\n\"\n",
    "        else:\n",
    "            architecture_str += f\"{layer_type}({gene})\\n\"\n",
    "        i += 1\n",
    "\n",
    "    print(\"Arquitectura Decodificada (Agrupada):\")\n",
    "    print(architecture_str)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Función para asegurar que el primer gen no sea Repetition\n",
    "def repair_first_gene(genes):\n",
    "    repair_log = []\n",
    "    if genes[0][0] == '1':  # Si es Repetition, reemplazar con Conv2D\n",
    "        print(f\"Invalid: First gene cannot be Repetition. Replacing with Conv2D.\")\n",
    "        genes[0] = '000000000'  # Conv2D por defecto\n",
    "        repair_log.append(f\"Gen 1: Replaced Repetition with Conv2D.\")\n",
    "    return genes, repair_log\n",
    "\n",
    "def repair_ending_genes(genes):\n",
    "    repair_log = []\n",
    "    \n",
    "    # La penúltima capa debe ser Flatten\n",
    "    if genes[-2][0] == '1' or genes[-2][1:4] != '101':  # Verificamos si la penúltima capa es Flatten\n",
    "        print(\"Invalid: Penultimate layer must be Flatten. Replacing.\")\n",
    "        genes[-2] = '010100000'  # Flatten por defecto\n",
    "        repair_log.append(\"Penultimate layer replaced with Flatten.\")\n",
    "    \n",
    "    # La última capa debe ser Dense con 1 neurona\n",
    "    if genes[-1][0] == '1' or genes[-1][1:4] != '100' or genes[-1][4:] != '00001':  # Verificamos si la última es Dense con 1 neurona\n",
    "        print(\"Invalid: Last layer must be Dense with 1 unit. Replacing.\")\n",
    "        genes[-1] = '010000001'  # Dense con 1 neurona\n",
    "        repair_log.append(\"Last layer replaced with Dense (units=1).\")\n",
    "    \n",
    "    return genes, repair_log\n",
    "\n",
    "\n",
    "# Función para reparar el cromosoma\n",
    "def repair_chromosome(binary_model):\n",
    "    genes = [binary_model[i:i+9] for i in range(0, len(binary_model), 9)]\n",
    "    repair_log = []\n",
    "\n",
    "    # Reparar el primer gen\n",
    "    genes, first_gene_log = repair_first_gene(genes)\n",
    "    repair_log.extend(first_gene_log)\n",
    "\n",
    "    # Reparar los genes finales\n",
    "    genes, ending_genes_log = repair_ending_genes(genes)\n",
    "    repair_log.extend(ending_genes_log)\n",
    "\n",
    "    # Evitar repeticiones consecutivas de capas de tipo Repetition\n",
    "    for i in range(1, len(genes)):\n",
    "        if genes[i][0] == '1' and genes[i-1][0] == '1':\n",
    "            print(f\"Invalid: Consecutive Repetition layers at positions {i} and {i+1}. Replacing gene at position {i+1} with DontCare.\")\n",
    "            genes[i] = '011100000'  # DontCare\n",
    "            repair_log.append(f\"Gen {i+1}: Replaced Repetition with DontCare due to consecutive Repetition layers.\")\n",
    "\n",
    "    # Asegurar que las primeras 3 capas sean válidas\n",
    "    valid_initial_layer_types = ['000', '001', '010', '110']  # Conv2D, BatchNorm, MaxPooling, DepthwiseConv2D\n",
    "    for i in [0, 1, 2]:  # Primeros 3 genes\n",
    "        if genes[i][0] == '1' or genes[i][1:4] not in valid_initial_layer_types:\n",
    "            print(f\"Invalid: Gene {i+1} is invalid in initial position. Replacing with Conv2D.\")\n",
    "            genes[i] = '000000000'  # Conv2D por defecto\n",
    "            repair_log.append(f\"Gen {i+1}: Replaced invalid layer with Conv2D.\")\n",
    "\n",
    "    # Asegurar que Dense siempre esté precedido por Flatten\n",
    "    i = 1\n",
    "    while i < len(genes) - 2:\n",
    "        current_gene = genes[i]\n",
    "        prev_gene = genes[i - 1]\n",
    "        current_layer_type = current_gene[1:4] if current_gene[0] == '0' else 'Repetition'\n",
    "        prev_layer_type = prev_gene[1:4] if prev_gene[0] == '0' else 'Repetition'\n",
    "\n",
    "        if current_layer_type == '100':  # Dense\n",
    "            if prev_layer_type != '101':  # No está precedido por Flatten\n",
    "                print(f\"Invalid: Dense layer at position {i+1} not preceded by Flatten. Inserting Flatten layer.\")\n",
    "                # Insertar Flatten antes de la capa actual\n",
    "                flatten_gene = '010100000'  # Flatten por defecto\n",
    "                genes.insert(i, flatten_gene)\n",
    "                repair_log.append(f\"Gen {i+1}: Inserted Flatten layer before Dense.\")\n",
    "                i += 1  # Incrementar para evitar loop infinito\n",
    "        elif prev_layer_type == '101' and current_layer_type in ['000', '001', '010', '110']:\n",
    "            # Evitar que Flatten sea seguido por capas convolucionales\n",
    "            print(f\"Invalid: Flatten layer at position {i} followed by convolutional layer. Replacing layer at position {i+1} with DontCare.\")\n",
    "            genes[i] = '011100000'  # Reemplazar con DontCare\n",
    "            repair_log.append(f\"Gen {i+1}: Replaced invalid layer with DontCare after Flatten.\")\n",
    "        i += 1\n",
    "\n",
    "    # Reparar capas de Repetition que causan conflictos\n",
    "    for i in range(len(genes)):\n",
    "        if genes[i][0] == '1':  # Es una capa de Repetition\n",
    "            repetition_count = int(genes[i][1:4], 2)\n",
    "            if repetition_count == 0:\n",
    "                print(f\"Invalid: Repetition count is zero at position {i+1}. Replacing with DontCare.\")\n",
    "                genes[i] = '011100000'  # DontCare\n",
    "                repair_log.append(f\"Gen {i+1}: Replaced Repetition with DontCare due to zero repetition count.\")\n",
    "                continue\n",
    "            start_index = i - repetition_count\n",
    "            if start_index < 0:\n",
    "                print(f\"Invalid: Repetition at position {i+1} refers to non-existent layers. Adjusting repetition count.\")\n",
    "                adjusted_count = i\n",
    "                if adjusted_count == 0:\n",
    "                    genes[i] = '011100000'  # DontCare\n",
    "                    repair_log.append(f\"Gen {i+1}: Replaced Repetition with DontCare due to invalid repetition count.\")\n",
    "                else:\n",
    "                    # Ajustar el conteo de repetición en el gen\n",
    "                    genes[i] = '1' + format(adjusted_count, '03b') + genes[i][4:]\n",
    "                    repair_log.append(f\"Gen {i+1}: Adjusted repetition count to {adjusted_count}.\")\n",
    "\n",
    "    # Asegurar que el cromosoma tenga 12 genes\n",
    "    while len(genes) > 12:\n",
    "        genes.pop()\n",
    "        repair_log.append(\"Removed extra gene to maintain chromosome length of 12.\")\n",
    "    while len(genes) < 12:\n",
    "        genes.append('011100000')  # Añadir DontCare\n",
    "        repair_log.append(\"Added DontCare gene to maintain chromosome length of 12.\")\n",
    "\n",
    "    repaired_binary_model = ''.join(genes)\n",
    "    return repaired_binary_model, repair_log\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Función auxiliar para agregar capas al modelo según el tipo de capa\n",
    "def add_layer_to_model(model, layer_info):\n",
    "    layer_type = layer_info['type']\n",
    "    params = layer_info.get('params', '0000000')\n",
    "    if layer_type == 'Conv2D':\n",
    "        filters = int(params[:3], 2) + 1  # Al menos 1 filtro\n",
    "        kernel_size = int(params[3:5], 2) + 1  # Tamaño de kernel mínimo 1\n",
    "        model.add(layers.Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), activation='relu', padding='same'))\n",
    "    elif layer_type == 'BatchNorm':\n",
    "        model.add(layers.BatchNormalization())\n",
    "    elif layer_type == 'MaxPooling':\n",
    "        pool_size = int(params[:2], 2) + 2  # Tamaño de pooling mínimo 2\n",
    "        model.add(layers.MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "    elif layer_type == 'Dropout':\n",
    "        rate = int(params[:3], 2) / 10.0  # Dropout rate entre 0.0 y 0.7\n",
    "        model.add(layers.Dropout(rate=rate))\n",
    "    elif layer_type == 'Dense':\n",
    "        units = int(params[:5], 2) + 1  # Al menos 1 unidad\n",
    "        model.add(layers.Dense(units=units, activation='relu'))\n",
    "    elif layer_type == 'Flatten':\n",
    "        model.add(layers.Flatten())\n",
    "    elif layer_type == 'DepthwiseConv2D':\n",
    "        kernel_size = int(params[:3], 2) + 1  # Tamaño de kernel mínimo 1\n",
    "        model.add(layers.DepthwiseConv2D(kernel_size=(kernel_size, kernel_size), activation='relu', padding='same'))\n",
    "    elif layer_type == 'DontCare':\n",
    "        pass  # No hacer nada\n",
    "    else:\n",
    "        pass  # Capa desconocida o no soportada\n",
    "\n",
    "# Función para generar, validar, reparar y construir modelos de TensorFlow\n",
    "def generate_and_print_tf_models(num_models=5):\n",
    "    generated_tf_models = []\n",
    "\n",
    "    with tqdm(total=num_models, desc=\"Progreso general\", unit=\"model\") as pbar:\n",
    "        for i in range(num_models):\n",
    "            pbar.set_description(f\"Generando modelo {i + 1}\")\n",
    "            random_model_binary = generate_random_binary_model()\n",
    "            print(f\"\\nGenerated Binary Model {i + 1}: {' '.join([random_model_binary[j:j+9] for j in range(0, len(random_model_binary), 9)])}\")\n",
    "            print_model_layers_in_binary(random_model_binary)\n",
    "\n",
    "            pbar.set_description(f\"Reparando modelo {i + 1}\")\n",
    "            repaired_model_binary, repair_log = repair_chromosome(random_model_binary)\n",
    "            print(f\"Repaired Binary Model {i + 1}: {' '.join([repaired_model_binary[j:j+9] for j in range(0, len(repaired_model_binary), 9)])}\")\n",
    "            \n",
    "            print_model_layers_in_binary(repaired_model_binary)\n",
    "            print_decoded_architecture_grouped([repaired_model_binary[j:j+9] for j in range(0, len(repaired_model_binary), 9)])\n",
    "            \n",
    "            # Construir y mostrar el resumen del modelo de TensorFlow\n",
    "            pbar.set_description(f\"Construyendo modelo TensorFlow {i + 1}\")\n",
    "            try:\n",
    "                decoded_model = decode_model_architecture(repaired_model_binary, gene_length=9)  # Decodificar el modelo reparado\n",
    "                tf_model = build_tf_model_from_dict(decoded_model)\n",
    "                generated_tf_models.append(tf_model)\n",
    "                print(f\"\\nModel {i + 1} Summary:\")\n",
    "                tf_model.summary()\n",
    "                print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error building TensorFlow model for Model {i + 1}: {e}\")\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_description(f\"Progreso general\")\n",
    "\n",
    "    return generated_tf_models\n",
    "\n",
    "# Llamada a la función para generar e imprimir modelos de TensorFlow\n",
    "generate_and_print_tf_models(num_models=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Función para generar mutaciones en una arquitectura conocida\n",
    "def mutate_architecture(binary_model, mutation_rate=0.1):\n",
    "    mutated_model = list(binary_model)  # Convertimos el string a lista para mutarlo\n",
    "    for i in range(len(mutated_model)):\n",
    "        if random.random() < mutation_rate:  # Decidir si mutar este bit\n",
    "            # Mutar el bit (0 -> 1, 1 -> 0)\n",
    "            mutated_model[i] = '1' if mutated_model[i] == '0' else '0'\n",
    "    return ''.join(mutated_model)\n",
    "\n",
    "# Función para realizar crossover entre dos modelos\n",
    "def crossover(parent1, parent2):\n",
    "    # Elegir un punto de corte al azar\n",
    "    crossover_point = random.randint(1, len(parent1) - 1)\n",
    "    \n",
    "    # Generar hijos mezclando los padres\n",
    "    child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "    child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
    "    \n",
    "    return child1, child2\n",
    "\n",
    "# Función para generar la población\n",
    "def generate_population(known_architectures, population_size=100, mutation_rate=0.1):\n",
    "    population = []\n",
    "\n",
    "    # Paso 1: Añadir las arquitecturas conocidas a la población\n",
    "    population.extend(known_architectures)\n",
    "\n",
    "    # Paso 2: Generar el resto de la población\n",
    "    while len(population) < population_size:\n",
    "        # Seleccionar dos padres al azar de la población actual\n",
    "        parent1 = random.choice(population)\n",
    "        parent2 = random.choice(population)\n",
    "        \n",
    "        # Realizar crossover para generar nuevos hijos\n",
    "        child1, child2 = crossover(parent1, parent2)\n",
    "        \n",
    "        # Aplicar mutaciones a los hijos\n",
    "        child1 = mutate_architecture(child1, mutation_rate)\n",
    "        child2 = mutate_architecture(child2, mutation_rate)\n",
    "        \n",
    "        # Añadir los hijos a la población\n",
    "        population.append(child1)\n",
    "        population.append(child2)\n",
    "\n",
    "    # Asegurarse de que la población tiene el tamaño exacto\n",
    "    return population[:population_size]\n",
    "\n",
    "# Ejemplo de arquitecturas conocidas (en binario)\n",
    "known_architectures = [\n",
    "    '0000100001100000001000000101000000010000011000000010000001010000101000001000000001101000100111001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000',  # Ejemplo 1\n",
    "    '0010000000010001001000000001100100100000101000001001001010011100111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000111000001110000011100000',  # Ejemplo 2\n",
    "    '0000000100100000000000010101000000000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000100000001001000000000000110100000100000000111100010011100'  # Ejemplo 3\n",
    "]\n",
    "\n",
    "# Generar una población de 100 individuos\n",
    "population = generate_population(known_architectures, population_size=100)\n",
    "\n",
    "# Imprimir algunos individuos generados\n",
    "for i, individual in enumerate(population):\n",
    "    print(f\"Individuo {i+1}: {individual}\")\n",
    "    decoded_chromosome = decode_model_architecture(individual)  # Decodificar y mostrar la arquitectura\n",
    "    print(decoded_chromosome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
