{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\herna\\anaconda3\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\herna\\anaconda3\\lib\\site-packages (from soundfile) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\herna\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\herna\\anaconda3\\lib\\site-packages (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\herna\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\herna\\anaconda3\\lib\\site-packages (from scipy) (1.20.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile\n",
    "!pip install numpy\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech segments in 300_AUDIO: 0\n",
      "Speech segments in preprocessed_300_AUDIO: 0\n",
      "Speech segments in 301_AUDIO: 0\n",
      "Speech segments in preprocessed_301_AUDIO: 0\n",
      "Speech segments in 302_AUDIO: 0\n",
      "Speech segments in preprocessed_302_AUDIO: 0\n",
      "Speech segments in 303_AUDIO: 0\n",
      "Speech segments in preprocessed_303_AUDIO: 0\n",
      "Speech segments in 304_AUDIO: 0\n",
      "Speech segments in preprocessed_304_AUDIO: 0\n",
      "Speech segments in 305_AUDIO: 0\n",
      "Speech segments in preprocessed_305_AUDIO: 0\n",
      "Speech segments in 306_AUDIO: 0\n",
      "Speech segments in preprocessed_306_AUDIO: 0\n",
      "Speech segments in 307_AUDIO: 0\n",
      "Speech segments in preprocessed_307_AUDIO: 0\n",
      "Speech segments in 308_AUDIO: 0\n",
      "Speech segments in preprocessed_308_AUDIO: 0\n",
      "Speech segments in 309_AUDIO: 0\n",
      "Speech segments in preprocessed_309_AUDIO: 0\n",
      "Speech segments in 310_AUDIO: 0\n",
      "Speech segments in preprocessed_310_AUDIO: 0\n",
      "Speech segments in 311_AUDIO: 0\n",
      "Speech segments in preprocessed_311_AUDIO: 0\n",
      "Speech segments in 312_AUDIO: 0\n",
      "Speech segments in preprocessed_312_AUDIO: 0\n",
      "Speech segments in 313_AUDIO: 0\n",
      "Speech segments in preprocessed_313_AUDIO: 0\n",
      "Speech segments in 314_AUDIO: 0\n",
      "Speech segments in preprocessed_314_AUDIO: 0\n",
      "Speech segments in 315_AUDIO: 0\n",
      "Speech segments in preprocessed_315_AUDIO: 0\n",
      "Speech segments in 316_AUDIO: 0\n",
      "Speech segments in preprocessed_316_AUDIO: 0\n",
      "Speech segments in 317_AUDIO: 0\n",
      "Speech segments in preprocessed_317_AUDIO: 0\n",
      "Speech segments in 318_AUDIO: 0\n",
      "Speech segments in preprocessed_318_AUDIO: 0\n",
      "Speech segments in 319_AUDIO: 0\n",
      "Speech segments in preprocessed_319_AUDIO: 0\n",
      "Speech segments in 320_AUDIO: 0\n",
      "Speech segments in preprocessed_320_AUDIO: 0\n",
      "Speech segments in 321_AUDIO: 0\n",
      "Speech segments in preprocessed_321_AUDIO: 0\n",
      "Speech segments in 322_AUDIO: 0\n",
      "Speech segments in preprocessed_322_AUDIO: 0\n",
      "Speech segments in 323_AUDIO: 0\n",
      "Speech segments in preprocessed_323_AUDIO: 0\n",
      "Speech segments in 324_AUDIO: 0\n",
      "Speech segments in preprocessed_324_AUDIO: 0\n",
      "Speech segments in 325_AUDIO: 0\n",
      "Speech segments in preprocessed_325_AUDIO: 0\n",
      "Speech segments in 326_AUDIO: 0\n",
      "Speech segments in preprocessed_326_AUDIO: 0\n",
      "Speech segments in 327_AUDIO: 0\n",
      "Speech segments in preprocessed_327_AUDIO: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/2335916186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;31m# Save the joined speech\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mfinal_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'preprocessed_{audio_file_name}.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoined_speech\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\herna\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(file, data, samplerate, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    343\u001b[0m     with SoundFile(file, 'w', samplerate, channels,\n\u001b[0;32m    344\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\herna\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\herna\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m             \u001b[1;31m# be sure to flush data to disk before closing the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_close\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\herna\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \"\"\"\n\u001b[0;32m   1178\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_if_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1179\u001b[1;33m         \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_write_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def pre_emphasis(signal, alpha=0.1):\n",
    "    pre_emphasized_signal = lfilter([1, -alpha], [1], signal)\n",
    "    return pre_emphasized_signal\n",
    "\n",
    "def hamming(window_length):\n",
    "    window = 0.54 - 0.46 * np.cos(2 * np.pi * np.arange(window_length) / (window_length - 1))\n",
    "    return window\n",
    "\n",
    "# Parameters for digitization and endpoint detection\n",
    "lowcut = 300.0\n",
    "highcut = 3400.0\n",
    "fs = 8000\n",
    "n_bits = 16\n",
    "high_threshold = 500  # Adjust based on your audio characteristics\n",
    "low_threshold = 400   # Adjust based on your audio characteristics\n",
    "\n",
    "# Path to the directory containing folders with .wav files\n",
    "root_path = \"d:\\Sistema\\Escritorio\\Escritorio\\Tesis\\DAIC-WOZ\\data\"\n",
    "\n",
    "# Process each folder and .wav file\n",
    "for folder_name in os.listdir(root_path):\n",
    "    folder_path = os.path.join(root_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Find all .wav files in the current folder\n",
    "        for wav_file_path in glob.glob(os.path.join(folder_path, '*.wav')):\n",
    "            # Read the audio signal using soundfile (for efficiency)\n",
    "            audio_signal, original_fs = sf.read(wav_file_path)\n",
    "\n",
    "            # Pre-filtering\n",
    "            filtered_signal = butter_bandpass_filter(audio_signal, lowcut, highcut, original_fs)\n",
    "\n",
    "            # Sampling (downsampling if necessary)\n",
    "            if original_fs > fs:\n",
    "                sampled_signal = filtered_signal[::int(original_fs / fs)]\n",
    "            else:\n",
    "                sampled_signal = filtered_signal\n",
    "\n",
    "            # Pre-emphasis\n",
    "            pre_emphasized_signal = pre_emphasis(sampled_signal)  # Apply pre-emphasis\n",
    "\n",
    "            # Initialize variables for endpoint detection\n",
    "            in_speech_segment = False\n",
    "            speech_segments = []\n",
    "\n",
    "            # Window framing with endpoint detection\n",
    "            window_length = 25  # Example window length (adjust as needed)\n",
    "            hamming_window = hamming(window_length)\n",
    "            framed_signal = np.zeros((len(pre_emphasized_signal) // window_length, window_length))  # Pre-allocate array\n",
    "\n",
    "            for i in range(0, len(pre_emphasized_signal) - window_length + 1, window_length):\n",
    "                start = i\n",
    "                end = i + window_length\n",
    "\n",
    "                # Calculate short-time energy\n",
    "                windowed_frame = pre_emphasized_signal[start:end] * hamming_window\n",
    "                energy = np.sum(windowed_frame**2)\n",
    "\n",
    "                # Endpoint detection logic\n",
    "                if energy > high_threshold and not in_speech_segment:\n",
    "                    in_speech_segment = True\n",
    "                    speech_segment_start = start\n",
    "                elif in_speech_segment and energy < low_threshold:\n",
    "                    in_speech_segment = False\n",
    "                    speech_segments.append([speech_segment_start, end])\n",
    "\n",
    "                # Framing (only for speech segments)\n",
    "                if in_speech_segment:\n",
    "                    framed_signal[i // window_length] = windowed_frame\n",
    "\n",
    "             # Quantization and coding\n",
    "            quantized_signal = np.zeros_like(framed_signal, dtype=np.int16)\n",
    "            for i, (segment_start, segment_end) in enumerate(speech_segments):\n",
    "                quantized_signal[i] = np.int16(pre_emphasized_signal[segment_start:segment_end] * (2**(n_bits - 1) - 1))\n",
    "\n",
    "            # Join the processed speech segments\n",
    "            joined_speech = np.concatenate(quantized_signal)\n",
    "\n",
    "            # Extract the audio file name without extension\n",
    "            audio_file_name = os.path.splitext(os.path.basename(wav_file_path))[0]\n",
    "            print(f'Speech segments in {audio_file_name}: {len(speech_segments)}')\n",
    "\n",
    "            # Save the joined speech\n",
    "            final_path = os.path.join(folder_path, f'preprocessed_{audio_file_name}.wav')\n",
    "            sf.write(final_path, joined_speech, fs)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
