{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Global imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, LeakyReLU, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import tensorflow_addons as tfa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, LeakyReLU, Flatten, Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import librosa\n",
    "# #print(tf.config.list_physical_devices('GPU'))\n",
    "# # Desactivar GPU y forzar uso de CPU\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         #tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#         pass\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "\n",
    "# #tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # TensorFlow 2.x\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The path to the pickle file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded data dictionary.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as file:\n",
    "        data_dict_loaded = pickle.load(file)\n",
    "    return data_dict_loaded\n",
    "\n",
    "filename = \"../Data/D3TEC.pkl\"\n",
    "data_dict_loaded = load_data(filename)\n",
    "# data_dict_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dict_loaded[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, LeakyReLU, Flatten, Dense, Input, MaxPooling2D, Dropout, Resizing, MaxPool2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import gc\n",
    "import psutil\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "# Deshabilitar XLA compilación\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=0'\n",
    "\n",
    "# Ruta base para los archivos de espectrogramas\n",
    "base_path = \"F:\\\\Github\\\\Improving-deep-neural-networks-to-identify-mental-disorders-using-Neural-Architecture-Search\\\\D3T3C\"\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = tf.reduce_sum(tf.cast((y_pred < 0.5) & (y_true == 0), tf.float32))\n",
    "    possible_negatives = tf.reduce_sum(tf.cast(y_true == 0, tf.float32))\n",
    "    specificity = true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n",
    "    return specificity\n",
    "\n",
    "def log_memory_usage(stage):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    print(f\"[{stage}] Memory usage: {memory_info.rss / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "class KFoldCNNTester:\n",
    "    def __init__(self, data_dict, filename, batch_size=1, use_dummy_data=False, loading_method='tf_data', model_type='SpectroCNN', num_channels=3, recording_device='sm', num_folds=5, use_gender='All', reset_saves=False, image_size=(792, 293), max_segment_length=5):\n",
    "        self.data_dict = data_dict\n",
    "        self.filename = filename\n",
    "        self.batch_size = batch_size\n",
    "        self.mean_acc_per_fold = []\n",
    "        self.mean_loss_per_fold = []\n",
    "        self.mean_precision_per_fold = []\n",
    "        self.mean_recall_per_fold = []\n",
    "        self.mean_auc_per_fold = []\n",
    "        self.mean_specificity_per_fold = []\n",
    "        self.mean_f1_per_fold = []  # Para guardar los F1 Scores\n",
    "        self.kfold_list = []\n",
    "        self.state_file = f'{self.filename}_state.json'\n",
    "        self.keys = list(data_dict.keys())  # Lista de keys del diccionario\n",
    "        self.use_dummy_data = use_dummy_data\n",
    "        self.loading_method = loading_method  # Método de carga de datos\n",
    "        self.model_type = model_type  # Flag para elegir el modelo a utilizar\n",
    "        self.num_channels = num_channels  # Número de canales para las imágenes\n",
    "        self.recording_device = recording_device  # Tipo de dispositivo de grabación\n",
    "        self.num_folds = num_folds  # Número de K-folds a correr\n",
    "        self.use_gender = use_gender  # Género a utilizar en el K-fold\n",
    "        self.reset_saves = reset_saves  # Flag para reiniciar los guardados\n",
    "        self.image_size = image_size  # Tamaño de las imágenes generadas\n",
    "        self.max_segment_length = max_segment_length  # Máxima longitud de los segmentos de audio en segundos\n",
    "\n",
    "        if self.reset_saves and os.path.exists(self.state_file):\n",
    "            os.remove(self.state_file)\n",
    "\n",
    "    def save_state(self, fold_no, epoch_no, checkpoint_list, metrics_per_fold):\n",
    "        state = self.load_state() or {}\n",
    "        state.setdefault('model_type', {}).setdefault(self.model_type, {}).setdefault(self.use_gender, {})[str(self.num_folds)] = {\n",
    "            'epoch': epoch_no,\n",
    "            'checkpoints': checkpoint_list,\n",
    "            'fold_no': fold_no,\n",
    "            'metrics_per_fold': metrics_per_fold\n",
    "        }\n",
    "        with open(self.state_file, 'w') as f:\n",
    "            json.dump(state, f)\n",
    "\n",
    "    def load_state(self):\n",
    "        if os.path.exists(self.state_file):\n",
    "            with open(self.state_file, 'r') as f:\n",
    "                state = json.load(f)\n",
    "            return state\n",
    "        return None\n",
    "\n",
    "    def try_load_weights(self, model):\n",
    "        state = self.load_state()\n",
    "        if state is not None:\n",
    "            if str(self.num_folds) not in state['model_type'][self.model_type][self.use_gender]:\n",
    "                return state, 1, 0, []\n",
    "            last_checkpoint_dict = state['model_type'][self.model_type][self.use_gender][str(self.num_folds)]\n",
    "            checkpoints = last_checkpoint_dict['checkpoints']\n",
    "            for checkpoint in reversed(checkpoints):\n",
    "                try:\n",
    "                    path = \"./\" + checkpoint['path']\n",
    "                    model.load_weights(path)\n",
    "                    print('trying to load weights from checkpoint:', path)\n",
    "                    return state, checkpoint['fold_no'], checkpoint['epoch_no'], checkpoints\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading checkpoint {checkpoint['path']}: {e}\")\n",
    "        return state, 1, 0, []\n",
    "\n",
    "    def run_kfold_test(self):\n",
    "        model = self.define_model()\n",
    "        \n",
    "        state, fold_no, start_epoch, checkpoint_list = self.try_load_weights(model)\n",
    "        print(f\"Starting from fold {fold_no} out of {self.num_folds}, epoch {start_epoch}\")\n",
    "        if state is None or str(self.num_folds) not in state['model_type'][self.model_type][self.use_gender]:\n",
    "            fold_no, start_epoch = 1, 0\n",
    "            checkpoint_list = []\n",
    "            metrics_per_fold = {\n",
    "                \"acc_per_fold\": [],\n",
    "                \"loss_per_fold\": [],\n",
    "                \"precision_per_fold\": [],\n",
    "                \"recall_per_fold\": [],\n",
    "                \"auc_per_fold\": [],\n",
    "                \"specificity_per_fold\": [],\n",
    "                \"f1_per_fold\": []  # Para guardar los F1 Scores\n",
    "            }\n",
    "        else:\n",
    "            last_checkpoint_dict = state['model_type'][self.model_type][self.use_gender][str(self.num_folds)]\n",
    "            metrics_per_fold = last_checkpoint_dict['metrics_per_fold']\n",
    "            checkpoint_list = last_checkpoint_dict['checkpoints']\n",
    "\n",
    "            # If all folds are completed, just calculate and display the means\n",
    "            if len(metrics_per_fold[\"acc_per_fold\"]) >= self.num_folds:\n",
    "                self.calculate_means(metrics_per_fold)\n",
    "                return\n",
    "\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.makedirs('checkpoints')\n",
    "\n",
    "        no_epochs = 100\n",
    "        verbosity = 2\n",
    "        skf = StratifiedKFold(n_splits=self.num_folds, shuffle=True)\n",
    "\n",
    "        y_array = np.array([self.data_dict[key]['PHQ-Binary'] for key in self.keys])\n",
    "\n",
    "        for train_indices, test_indices in skf.split(self.keys, y_array):\n",
    "            if fold_no > self.num_folds:\n",
    "                break\n",
    "\n",
    "            # Filtrar por género si es necesario\n",
    "            if self.use_gender != 'All':\n",
    "                train_indices = [i for i in train_indices if self.data_dict[self.keys[i]]['Gender'] == self.use_gender]\n",
    "                test_indices = [i for i in test_indices if self.data_dict[self.keys[i]]['Gender'] == self.use_gender]\n",
    "\n",
    "            # Obtener las keys correspondientes a los índices\n",
    "            train_keys = [self.keys[i] for i in train_indices]\n",
    "            test_keys = [self.keys[i] for i in test_indices]\n",
    "\n",
    "            checkpoint_filepath = f'checkpoints/{self.filename}_{self.model_type}_{self.use_gender}_{self.recording_device}_checkpoint_{self.num_folds}_fold_{fold_no}_epoch_{{epoch}}.h5'\n",
    "\n",
    "            self.try_load_weights(model)\n",
    "\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} of {self.num_folds} folds...')\n",
    "\n",
    "            checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True,\n",
    "                                                  monitor='loss', mode='min', save_best_only=False, period=10)\n",
    "\n",
    "            callback = EarlyStopping(monitor='loss', patience=3, min_delta=0.0001)\n",
    "\n",
    "            if self.loading_method == 'tf_data':\n",
    "                train_dataset = self.create_dataset(train_keys)\n",
    "                for epoch in range(start_epoch, no_epochs):\n",
    "                    steps_per_epoch = np.ceil(len(train_keys) / self.batch_size).astype(int)\n",
    "                    print(f\"Training epoch {epoch+1}/100, steps per epoch: {steps_per_epoch}\")\n",
    "                    model.fit(train_dataset, epochs=1, verbose=verbosity, callbacks=[checkpoint_callback], steps_per_epoch=steps_per_epoch)\n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        model.save_weights(checkpoint_filepath.format(epoch=epoch + 1))\n",
    "                        checkpoint_list.append({'fold_no': fold_no, 'epoch_no': epoch + 1, 'path': checkpoint_filepath.format(epoch=epoch + 1)})\n",
    "                    self.save_state(fold_no, epoch + 1, checkpoint_list, metrics_per_fold)\n",
    "                    log_memory_usage(f\"Epoch {epoch+1} End\")\n",
    "                    start_epoch = 0\n",
    "            elif self.loading_method == 'batch':\n",
    "                steps_per_epoch = np.ceil(len(train_keys) / self.batch_size).astype(int)\n",
    "                for epoch in range(start_epoch, no_epochs):\n",
    "                    print(f\"Training epoch {epoch+1}/100, steps per epoch: {steps_per_epoch}\")\n",
    "                    for i in tqdm(range(0, len(train_keys), self.batch_size), desc=f\"Training fold {fold_no}, epoch {epoch+1}\"):\n",
    "                        batch_keys = train_keys[i:i + self.batch_size]\n",
    "                        X_train, y_train = self.generate_batch_data(batch_keys)\n",
    "                        model.fit(X_train, y_train, batch_size=self.batch_size, epochs=1, verbose=verbosity, callbacks=[checkpoint_callback])\n",
    "                        del X_train, y_train\n",
    "                        gc.collect()\n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        model.save_weights(checkpoint_filepath.format(epoch=epoch + 1))\n",
    "                        checkpoint_list.append({'fold_no': fold_no, 'epoch_no': epoch + 1, 'path': checkpoint_filepath.format(epoch=epoch + 1)})\n",
    "                    self.save_state(fold_no, epoch + 1, checkpoint_list, metrics_per_fold)\n",
    "                    log_memory_usage(f\"Epoch {epoch+1} End\")\n",
    "                    start_epoch = 0\n",
    "            else:  # normal loading method\n",
    "                steps_per_epoch = np.ceil(len(train_keys) / self.batch_size).astype(int)\n",
    "                for epoch in range(start_epoch, no_epochs):\n",
    "                    print(f\"Training epoch {epoch+1}/100, steps per epoch: {steps_per_epoch}\")\n",
    "                    for i in tqdm(range(0, len(train_keys), self.batch_size), desc=f\"Training fold {fold_no}, epoch {epoch+1}\"):\n",
    "                        batch_keys = train_keys[i:i + self.batch_size]\n",
    "                        X_train, y_train = self.generate_normal_data(batch_keys)\n",
    "                        model.fit(X_train, y_train, batch_size=self.batch_size, epochs=1, verbose=verbosity, callbacks=[checkpoint_callback])\n",
    "                        del X_train, y_train\n",
    "                        gc.collect()\n",
    "                    if (epoch + 1) % 10 == 0:\n",
    "                        model.save_weights(checkpoint_filepath.format(epoch=epoch + 1))\n",
    "                        checkpoint_list.append({'fold_no': fold_no, 'epoch_no': epoch + 1, 'path': checkpoint_filepath.format(epoch=epoch + 1)})\n",
    "                    self.save_state(fold_no, epoch + 1, checkpoint_list, metrics_per_fold)\n",
    "                    log_memory_usage(f\"Epoch {epoch+1} End\")\n",
    "                    start_epoch = 0\n",
    "\n",
    "            start_epoch = 0\n",
    "\n",
    "            if self.loading_method == 'tf_data':\n",
    "                test_dataset = self.create_dataset(test_keys)\n",
    "                steps_per_epoch = np.ceil(len(test_keys) / self.batch_size).astype(int)\n",
    "                print(f\"Evaluating fold {fold_no}, steps per epoch: {steps_per_epoch}\")\n",
    "                scores = model.evaluate(test_dataset, verbose=0, steps=steps_per_epoch)\n",
    "                y_pred = model.predict(test_dataset, steps=steps_per_epoch)\n",
    "                y_true = [self.data_dict[key]['PHQ-Binary'] for key in test_keys]\n",
    "            elif self.loading_method == 'batch':\n",
    "                scores = []\n",
    "                y_pred = []\n",
    "                y_true = []\n",
    "                for i in tqdm(range(0, len(test_keys), self.batch_size), desc=f\"Evaluating fold {fold_no}\"):\n",
    "                    batch_keys = test_keys[i:i + self.batch_size]\n",
    "                    X_test, y_test = self.generate_batch_data(batch_keys)\n",
    "                    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "                    y_pred.extend(model.predict(X_test).flatten())\n",
    "                    y_true.extend(y_test)\n",
    "                    scores.append(score)\n",
    "                    del X_test, y_test\n",
    "                    gc.collect()\n",
    "                scores = np.mean(scores, axis=0)\n",
    "            else:  # normal loading method\n",
    "                scores = []\n",
    "                y_pred = []\n",
    "                y_true = []\n",
    "                for i in tqdm(range(0, len(test_keys), self.batch_size), desc=f\"Evaluating fold {fold_no}\"):\n",
    "                    batch_keys = test_keys[i:i + self.batch_size]\n",
    "                    X_test, y_test = self.generate_normal_data(batch_keys)\n",
    "                    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "                    y_pred.extend(model.predict(X_test).flatten())\n",
    "                    y_true.extend(y_test)\n",
    "                    scores.append(score)\n",
    "                    del X_test, y_test\n",
    "                    gc.collect()\n",
    "                scores = np.mean(scores, axis=0)\n",
    "\n",
    "            metrics_per_fold[\"acc_per_fold\"].append(scores[1] * 100)\n",
    "            metrics_per_fold[\"loss_per_fold\"].append(scores[0])\n",
    "            metrics_per_fold[\"precision_per_fold\"].append(scores[2])\n",
    "            metrics_per_fold[\"recall_per_fold\"].append(scores[3])\n",
    "            metrics_per_fold[\"auc_per_fold\"].append(scores[4])\n",
    "            metrics_per_fold[\"specificity_per_fold\"].append(scores[5])\n",
    "\n",
    "            # Calcular F1 Score\n",
    "            y_pred_labels = np.where(np.array(y_pred) > 0.5, 1, 0)\n",
    "            f1_score = tfa.metrics.F1Score(num_classes=1, threshold=0.5)(y_true, y_pred_labels)\n",
    "            metrics_per_fold[\"f1_per_fold\"].append(f1_score)\n",
    "\n",
    "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%; {model.metrics_names[2]}: {scores[2]}; {model.metrics_names[3]}: {scores[3]}; {model.metrics_names[4]}: {scores[4]}; {model.metrics_names[5]}: {scores[5]}; F1: {f1_score}')\n",
    "\n",
    "            # Print confusion matrix\n",
    "            cm = confusion_matrix(y_true, y_pred_labels)\n",
    "            print(f'Confusion Matrix for fold {fold_no}:\\n{cm}')\n",
    "\n",
    "            if scores[1] * 100 > 60:\n",
    "                self.save_model_and_data(model, fold_no, scores, train_keys)\n",
    "\n",
    "            self.save_state(fold_no + 1, 0, checkpoint_list, metrics_per_fold)\n",
    "            fold_no += 1\n",
    "\n",
    "        if metrics_per_fold[\"acc_per_fold\"]:\n",
    "            self.calculate_means(metrics_per_fold)\n",
    "\n",
    "    def generate_batch_data(self, batch_keys):\n",
    "        if self.use_dummy_data:\n",
    "            X = np.random.rand(self.batch_size, *self.image_size, self.num_channels)\n",
    "            y = np.random.randint(0, 2, self.batch_size)\n",
    "        else:\n",
    "            X = []\n",
    "            y = []\n",
    "            for key in batch_keys:\n",
    "                info = self.data_dict[key]\n",
    "                for audio_type, audios in info['audios'].items():\n",
    "                    for question_number, audio_data in audios.items():\n",
    "                        if isinstance(question_number, int) and audio_type == self.recording_device:\n",
    "                            audio_path = base_path + audio_data['file_path'].replace('..', \"\")\n",
    "                            spectrogram_images = self.generate_spectrogram_image(audio_path)\n",
    "                            for img in spectrogram_images:\n",
    "                                X.append(img)\n",
    "                                y.append(info['PHQ-Binary'])\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            X = X / 255.0\n",
    "        return X, y\n",
    "\n",
    "    def generate_normal_data(self, keys):\n",
    "        X = []\n",
    "        y = []\n",
    "        for key in keys:\n",
    "            info = self.data_dict[key]\n",
    "            for audio_type, audios in info['audios'].items():\n",
    "                for question_number, audio_data in audios.items():\n",
    "                    if isinstance(question_number, int) and audio_type == self.recording_device:\n",
    "                        audio_path = base_path + audio_data['file_path'].replace('..', \"\")\n",
    "                        spectrogram_images = self.generate_spectrogram_image(audio_path)\n",
    "                        for img in spectrogram_images:\n",
    "                            X.append(img)\n",
    "                            y.append(info['PHQ-Binary'])\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        X = X / 255.0\n",
    "        return X, y\n",
    "\n",
    "    def generate_spectrogram_image(self, audio_path):\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        num_segments = int(np.ceil(waveform.shape[1] / (sample_rate * self.max_segment_length)))\n",
    "        print(f\"Audio will be split into {num_segments} segments of {self.max_segment_length} seconds each.\")\n",
    "        print(waveform)\n",
    "        spectrogram_images = []\n",
    "        for i in range(num_segments):\n",
    "            start_sample = i * sample_rate * self.max_segment_length\n",
    "            end_sample = (i + 1) * sample_rate * self.max_segment_length\n",
    "            segment_waveform = waveform[:, start_sample:end_sample]\n",
    "            print('segment waveform:', segment_waveform)\n",
    "            spectrogram = torchaudio.transforms.MelSpectrogram()(segment_waveform)\n",
    "            spectrogram = torchaudio.transforms.AmplitudeToDB()(spectrogram)\n",
    "            print('spectrogram')\n",
    "            print(spectrogram)\n",
    "            fig = plt.figure(figsize=(self.image_size[1] / 100, self.image_size[0] / 100), dpi=100)\n",
    "            plt.imshow(spectrogram.log2()[0, :, :].numpy(), cmap='viridis')\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout(pad=0)\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png')\n",
    "            plt.close(fig)\n",
    "            buf.seek(0)\n",
    "            img = Image.open(buf)\n",
    "            img = img.convert('RGB')  # Asegúrate de que tenga 3 canales\n",
    "            img = img.resize((self.image_size[1], self.image_size[0]))\n",
    "            img_array = np.array(img)\n",
    "            spectrogram_images.append(img_array)\n",
    "        print(spectrogram_images)\n",
    "        return spectrogram_images\n",
    "\n",
    "    def define_model(self):\n",
    "        if self.model_type == 'SpectroCNN':\n",
    "            return self.define_complete_model()\n",
    "        elif self.model_type == 'LuisFelipe':\n",
    "            return self.define_luisfelipe_model()\n",
    "        elif self.model_type == 'reduced':\n",
    "            return self.define_reduced_model()\n",
    "\n",
    "    def define_reduced_model(self):\n",
    "        model = Sequential([\n",
    "            BatchNormalization(name='batch_normalization_9'),\n",
    "            Conv2D(16, kernel_size=(3, 3), padding='same', input_shape=(*self.image_size, self.num_channels), name='conv2d_6'),\n",
    "            LeakyReLU(alpha=0.01, name='leaky_re_lu_9'),\n",
    "            BatchNormalization(name='batch_normalization_10'),\n",
    "            Conv2D(8, (3, 3), padding='same', name='conv2d_7'),\n",
    "            LeakyReLU(alpha=0.01, name='leaky_re_lu_10'),\n",
    "            BatchNormalization(name='batch_normalization_11'),\n",
    "            Flatten(name='flatten_6'),\n",
    "            Dense(32, name='dense_6'),\n",
    "            LeakyReLU(alpha=0.01, name='leaky_re_lu_11'),\n",
    "            Dense(1, activation='sigmoid', name='dense_7')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), specificity, tfa.metrics.F1Score(num_classes=1, threshold=0.5)])\n",
    "        return model\n",
    "\n",
    "    def define_complete_model(self):\n",
    "        input_shape = (*self.image_size, self.num_channels)\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        x = Conv2D(32, kernel_size=(3, 3), padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.01)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "        for _ in range(31):\n",
    "            x = Conv2D(32, kernel_size=(3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "        outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), specificity, tfa.metrics.F1Score(num_classes=1, threshold=0.5)])\n",
    "        return model\n",
    "\n",
    "    def define_luisfelipe_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Resizing(self.image_size[1], self.image_size[0], input_shape=(self.image_size[0], self.image_size[1], self.num_channels)))\n",
    "        model.add(Conv2D(30, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        model.add(Conv2D(15, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(units=256, activation=\"relu\"))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), specificity, tfa.metrics.F1Score(num_classes=1, threshold=0.5)])\n",
    "        return model\n",
    "\n",
    "    def save_model_and_data(self, model, fold_no, scores, train_keys):\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        folder_path = f'{self.filename}_{self.model_type}_{self.use_gender}_{self.recording_device}_{current_time}/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        subfolder_path = folder_path + f'{self.num_folds}-fold_{fold_no}-{scores[1]*100}/'\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            os.makedirs(subfolder_path)\n",
    "\n",
    "        model.save(subfolder_path + f'fold-{fold_no}.h5')\n",
    "\n",
    "    def calculate_means(self, metrics_per_fold):\n",
    "        mean_acc = sum(metrics_per_fold[\"acc_per_fold\"]) / len(metrics_per_fold[\"acc_per_fold\"]) if metrics_per_fold[\"acc_per_fold\"] else 0\n",
    "        mean_loss = sum(metrics_per_fold[\"loss_per_fold\"]) / len(metrics_per_fold[\"loss_per_fold\"]) if metrics_per_fold[\"loss_per_fold\"] else 0\n",
    "        mean_precision = sum(metrics_per_fold[\"precision_per_fold\"]) / len(metrics_per_fold[\"precision_per_fold\"]) if metrics_per_fold[\"precision_per_fold\"] else 0\n",
    "        mean_recall = sum(metrics_per_fold[\"recall_per_fold\"]) / len(metrics_per_fold[\"recall_per_fold\"]) if metrics_per_fold[\"recall_per_fold\"] else 0\n",
    "        mean_auc = sum(metrics_per_fold[\"auc_per_fold\"]) / len(metrics_per_fold[\"auc_per_fold\"]) if metrics_per_fold[\"auc_per_fold\"] else 0\n",
    "        mean_specificity = sum(metrics_per_fold[\"specificity_per_fold\"]) / len(metrics_per_fold[\"specificity_per_fold\"]) if metrics_per_fold[\"specificity_per_fold\"] else 0\n",
    "        mean_f1 = sum(metrics_per_fold[\"f1_per_fold\"]) / len(metrics_per_fold[\"f1_per_fold\"]) if metrics_per_fold[\"f1_per_fold\"] else 0\n",
    "        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        folder_path = f'./results/{self.filename}_{self.model_type}_{self.use_gender}_{self.recording_device}_{current_time}_{self.num_folds}_mean/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        with open(folder_path + 'score.txt', 'a+') as file:\n",
    "            file.write(f'accuracy: {mean_acc}. loss: {mean_loss}. precision: {mean_precision}. recall: {mean_recall}. auc: {mean_auc}. specificity: {mean_specificity}. F1: {mean_f1}')\n",
    "\n",
    "    def create_dataset(self, keys):\n",
    "        def data_generator():\n",
    "            if self.use_dummy_data:\n",
    "                for _ in range(len(keys)):\n",
    "                    dummy_spectrogram = np.random.rand(*self.image_size, self.num_channels).astype(np.float32)  # Datos dummy ligeros\n",
    "                    dummy_label = np.random.randint(0, 2, dtype=np.int32)  # Etiqueta dummy corregida\n",
    "                    yield dummy_spectrogram, dummy_label\n",
    "            else:\n",
    "                for key in keys:\n",
    "                    info = self.data_dict[key]\n",
    "                    for audio_type, audios in info['audios'].items():\n",
    "                        for question_number, audio_data in audios.items():\n",
    "                            if isinstance(question_number, int) and audio_type == self.recording_device:\n",
    "                                audio_path = base_path + audio_data['file_path'].replace('..', \"\")\n",
    "                                spectrogram_images = self.generate_spectrogram_image(audio_path)\n",
    "                                for img in spectrogram_images:\n",
    "                                    yield img, info['PHQ-Binary']\n",
    "\n",
    "        output_signature = (\n",
    "            tf.TensorSpec(shape=(*self.image_size, self.num_channels), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "        )\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            data_generator,\n",
    "            output_signature=output_signature\n",
    "        )\n",
    "        return dataset.cache().shuffle(buffer_size=1000).batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio will be split into 5 segments of 5 seconds each.\n",
      "tensor([[ 0.0000e+00, -2.1458e-06, -3.8147e-06,  ..., -4.6492e-06,\n",
      "         -3.0994e-06, -1.6689e-06]])\n",
      "segment waveform: tensor([[ 0.0000e+00, -2.1458e-06, -3.8147e-06,  ..., -4.3347e-03,\n",
      "         -4.2188e-03, -4.0830e-03]])\n",
      "segment waveform: tensor([[-0.0039, -0.0037, -0.0036,  ..., -0.0013, -0.0014, -0.0015]])\n",
      "segment waveform: tensor([[-0.0017, -0.0017, -0.0018,  ...,  0.0018,  0.0019,  0.0018]])\n",
      "segment waveform: tensor([[ 0.0017,  0.0015,  0.0012,  ..., -0.0274, -0.0281, -0.0284]])\n",
      "segment waveform: tensor([[-2.8777e-02, -2.9261e-02, -2.9814e-02,  ..., -4.6492e-06,\n",
      "         -3.0994e-06, -1.6689e-06]])\n",
      "[array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "\n",
    "#from KFoldCNNTesterDoc import KFoldCNNTester\n",
    "#from tensorflow.keras.layers import MaxPool2D\n",
    "# Ejemplo de uso\n",
    "\n",
    "tester = KFoldCNNTester(data_dict_loaded, 'results', batch_size=1, loading_method='normal', num_folds=5, model_type='LuisFelipe', image_size=(293, 792), max_segment_length=5)\n",
    "spectrograms = tester.generate_spectrogram_image(\"F:\\\\Github\\\\Improving-deep-neural-networks-to-identify-mental-disorders-using-Neural-Architecture-Search\\\\D3T3C\\\\D3TEC Dataset\\\\SM-27\\\\153.wav\")\n",
    "# Mostrar el primer espectrograma generado\n",
    "if spectrograms:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.imshow(spectrograms[0])\n",
    "    plt.axis('off')  # Ocultar los ejes\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from fold 1 out of 5, epoch 0\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 of 5 folds...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Training epoch 1/100, steps per epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training fold 1, epoch 1:   0%|          | 0/49 [00:00<?, ?it/s]c:\\Users\\herna\\anaconda3\\envs\\tf\\lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tester.run_kfold_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = KFoldCNNTester(data_dict_loaded, 'results', batch_size=1, use_tf_data=True, num_folds = 10, model_type='LuisFelipe') #32 needs supervision as it stops more\n",
    "\n",
    "# Run the K-Fold test\n",
    "tester.run_kfold_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self, data_dict, filename, batch_size=1, use_dummy_data=False, use_tf_data=True, model_type='SpectroCNN', num_channels=3, recording_device='sm', num_folds_range=[5, 8, 10], use_gender='All'):\n",
    "tester = KFoldCNNTester(data_dict_loaded, 'results', batch_size=1, use_tf_data=True, model_type='SpectroCNN', num_folds=5, use_gender='Female') #32 needs supervision as it stops more\n",
    "\n",
    "# Run the K-Fold test\n",
    "tester.run_kfold_test()# self, data_dict, filename, batch_size=1, use_dummy_data=False, use_tf_data=True, model_type='SpectroCNN', num_channels=3, recording_device='sm', num_folds_range=[5, 8, 10], use_gender='All'):\n",
    "\n",
    "\n",
    "tester = KFoldCNNTester(data_dict_loaded, 'results', batch_size=1, use_tf_data=True, model_type='SpectroCNN', num_folds=10, use_gender='Female') #32 needs supervision as it stops more\n",
    "\n",
    "# Run the K-Fold test\n",
    "tester.run_kfold_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self, data_dict, filename, batch_size=1, use_dummy_data=False, use_tf_data=True, model_type='SpectroCNN', num_channels=3, recording_device='sm', num_folds_range=[5, 8, 10], use_gender='All'):\n",
    "tester = KFoldCNNTester(data_dict_loaded, 'results', batch_size=1, use_tf_data=True, model_type='SpectroCNN', num_folds=5, use_gender='Male') #32 needs supervision as it stops more\n",
    "\n",
    "# Run the K-Fold test\n",
    "tester.run_kfold_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self, data_dict, filename, batch_size=1, use_dummy_data=False, use_tf_data=True, model_type='SpectroCNN', num_channels=3, recording_device='sm', num_folds_range=[5, 8, 10], use_gender='All'):\n",
    "tester = KFoldCNNTester(data_dict_loaded, 'results', batch_size=1, use_tf_data=True, model_type='SpectroCNN', num_folds=10, use_gender='Male') #32 needs supervision as it stops more\n",
    "\n",
    "# Run the K-Fold test\n",
    "tester.run_kfold_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
